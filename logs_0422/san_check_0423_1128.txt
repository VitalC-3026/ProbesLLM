2024-04-23 15:29:26.598237: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-23 15:29:27.638696: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Epoch 0/100: Training Loss: 0.002913155130573086
Epoch 1/100: Training Loss: 0.003493953834880482
Epoch 2/100: Training Loss: 0.0022822566382534855
Epoch 3/100: Training Loss: 0.0018257467479972573
Epoch 4/100: Training Loss: 0.00188190078401899
Epoch 5/100: Training Loss: 0.0014516243359425686
Epoch 6/100: Training Loss: 0.0013362959131494269
Epoch 7/100: Training Loss: 0.0013513599450771625
Epoch 8/100: Training Loss: 0.0012659322131763804
Epoch 9/100: Training Loss: 0.0011289466719527344
Epoch 10/100: Training Loss: 0.0007137891712722245
Epoch 11/100: Training Loss: 0.0007544313068990107
Epoch 12/100: Training Loss: 0.002026130477865259
Epoch 13/100: Training Loss: 0.0008907963137526612
Epoch 14/100: Training Loss: 0.0013560938251602067
Epoch 15/100: Training Loss: 0.0017444674785320575
Epoch 16/100: Training Loss: 0.0013076603621036023
Epoch 17/100: Training Loss: 0.001379206151395411
Epoch 18/100: Training Loss: 0.0012485033773875736
Epoch 19/100: Training Loss: 0.0010088067371528465
Epoch 20/100: Training Loss: 0.0007580813619640324
Epoch 21/100: Training Loss: 0.001357918748488793
Epoch 22/100: Training Loss: 0.0011348635791898606
Epoch 23/100: Training Loss: 0.0014495782918863363
Epoch 24/100: Training Loss: 0.000775795664403822
Epoch 25/100: Training Loss: 0.0016598418042376324
Epoch 26/100: Training Loss: 0.0011355823778605961
Epoch 27/100: Training Loss: 0.0011288734165938584
Epoch 28/100: Training Loss: 0.0013369901196939962
Epoch 29/100: Training Loss: 0.0010505852165755693
Epoch 30/100: Training Loss: 0.0013003630654795186
Epoch 31/100: Training Loss: 0.0008092229287107507
Epoch 32/100: Training Loss: 0.0004959013703819755
Epoch 33/100: Training Loss: 0.0010749431965234395
Epoch 34/100: Training Loss: 0.0005127872516225268
Epoch 35/100: Training Loss: 0.0007215859694080753
Epoch 36/100: Training Loss: 0.0005039268961319557
Epoch 37/100: Training Loss: 0.0008656325248571542
Epoch 38/100: Training Loss: 0.0009647073237212388
Epoch 39/100: Training Loss: 0.00040595955052575867
Epoch 40/100: Training Loss: 0.001101763723613499
Epoch 41/100: Training Loss: 0.0014466750663477224
Epoch 42/100: Training Loss: 0.0009804503484205766
Epoch 43/100: Training Loss: 0.0007985148813341047
Epoch 44/100: Training Loss: 0.0009068124569379366
Epoch 45/100: Training Loss: 0.0009155542283625036
Epoch 46/100: Training Loss: 0.0007367041352745536
Epoch 47/100: Training Loss: 0.0007788448275386037
Epoch 48/100: Training Loss: 0.0006148909459580908
Epoch 49/100: Training Loss: 0.000353903333832334
Epoch 50/100: Training Loss: 0.00027712160994956543
Epoch 51/100: Training Loss: 0.0004637214270505038
Epoch 52/100: Training Loss: 0.0006925829953247017
Epoch 53/100: Training Loss: 0.0006745539970331259
Epoch 54/100: Training Loss: 0.0005317444984729474
Epoch 55/100: Training Loss: 0.0006296903520197301
Epoch 56/100: Training Loss: 0.0009180002070807077
Epoch 57/100: Training Loss: 0.0006813339732743643
Epoch 58/100: Training Loss: 0.0008053484183925015
Epoch 59/100: Training Loss: 0.0006036649008730908
Epoch 60/100: Training Loss: 0.0007885900306534933
Epoch 61/100: Training Loss: 0.0007473065198718252
Epoch 62/100: Training Loss: 0.0009749362935553064
Epoch 63/100: Training Loss: 0.000761663476070324
Epoch 64/100: Training Loss: 0.0011716718440289264
Epoch 65/100: Training Loss: 0.0012717141763313668
Epoch 66/100: Training Loss: 0.00117233770710605
Epoch 67/100: Training Loss: 0.001175770288580781
Epoch 68/100: Training Loss: 0.001180779996451798
Epoch 69/100: Training Loss: 0.0010605296054920117
Epoch 70/100: Training Loss: 0.0011915088325113684
Epoch 71/100: Training Loss: 0.0011271669731273517
Epoch 72/100: Training Loss: 0.001109151990263612
Epoch 73/100: Training Loss: 0.001099504790939651
Epoch 74/100: Training Loss: 0.0008204432425799069
Epoch 75/100: Training Loss: 0.0010743514224365875
Epoch 76/100: Training Loss: 0.0010931286570075509
Epoch 77/100: Training Loss: 0.0011078493370042814
Epoch 78/100: Training Loss: 0.001057367433201183
Epoch 79/100: Training Loss: 0.0010437051524649133
Epoch 80/100: Training Loss: 0.0010844503457729633
Epoch 81/100: Training Loss: 0.0007467989425559144
Epoch 82/100: Training Loss: 0.0009342980134737242
Epoch 83/100: Training Loss: 0.0007955576781626348
Epoch 84/100: Training Loss: 0.0006604115967150335
Epoch 85/100: Training Loss: 0.0008696362480416998
Epoch 86/100: Training Loss: 0.0008515599932703939
Epoch 87/100: Training Loss: 0.0009010190313512629
Epoch 88/100: Training Loss: 0.0009714794325661826
Epoch 89/100: Training Loss: 0.0006997229440228923
Epoch 90/100: Training Loss: 0.000920741395516829
Epoch 91/100: Training Loss: 0.0007494076357021199
Epoch 92/100: Training Loss: 4.3836487392028726e-05
Epoch 93/100: Training Loss: 0.0011129221924535044
Epoch 94/100: Training Loss: 6.988388649025163e-05
Epoch 95/100: Training Loss: 0.0006831139847115203
Epoch 96/100: Training Loss: 0.0010195666259818978
Epoch 97/100: Training Loss: 0.0005962059318602501
Epoch 98/100: Training Loss: 0.00033213940637928625
Epoch 99/100: Training Loss: 0.00038291229964136246
Epoch 0/100: Training Loss: 0.0029100298464715063
Epoch 1/100: Training Loss: 0.0017215669988752244
Epoch 2/100: Training Loss: 0.0019128597699678862
Epoch 3/100: Training Loss: 0.0028392639193501506
Epoch 4/100: Training Loss: 0.0017700741341064026
Epoch 5/100: Training Loss: 0.0017398210255416123
Epoch 6/100: Training Loss: 0.0017834341192578937
Epoch 7/100: Training Loss: 0.0015459765087474477
Epoch 8/100: Training Loss: 0.0019285783067449823
Epoch 9/100: Training Loss: 0.001444071218684003
Epoch 10/100: Training Loss: 0.0025001939360078398
Epoch 11/100: Training Loss: 0.002140307759905195
Epoch 12/100: Training Loss: 0.0018070329736162732
Epoch 13/100: Training Loss: 0.0016021925461042177
Epoch 14/100: Training Loss: 0.0013692097647206767
Epoch 15/100: Training Loss: 0.001912500058020745
Epoch 16/100: Training Loss: 0.0017454775271715818
Epoch 17/100: Training Loss: 0.0017404310353152403
Epoch 18/100: Training Loss: 0.0017405213801177232
Epoch 19/100: Training Loss: 0.0007906299787801463
Epoch 20/100: Training Loss: 0.001742276799428713
Epoch 21/100: Training Loss: 0.0012957483946860254
Epoch 22/100: Training Loss: 0.0011540766987767253
Epoch 23/100: Training Loss: 0.0009184006627623017
Epoch 24/100: Training Loss: 0.0009519633921709927
Epoch 25/100: Training Loss: 0.000846022179910353
Epoch 26/100: Training Loss: 0.0007040900262919339
Epoch 27/100: Training Loss: 0.0015988804243661308
Epoch 28/100: Training Loss: 0.0010360775294003786
Epoch 29/100: Training Loss: 0.0005031949677667417
Epoch 30/100: Training Loss: 0.0013536306527944712
Epoch 31/100: Training Loss: 0.0009211015242796678
Epoch 32/100: Training Loss: 0.0008638799711540862
Epoch 33/100: Training Loss: 0.0010081034648668516
Epoch 34/100: Training Loss: 0.0008296660714216165
Epoch 35/100: Training Loss: 0.0008361917379852775
Epoch 36/100: Training Loss: 0.00045162152785521286
Epoch 37/100: Training Loss: 0.0008979658563653906
Epoch 38/100: Training Loss: 0.0008719008077274669
Epoch 39/100: Training Loss: 0.0007637023821577325
Epoch 40/100: Training Loss: 0.0008443287619344004
Epoch 41/100: Training Loss: 0.0007629635763335062
Epoch 42/100: Training Loss: 0.001018292107782164
Epoch 43/100: Training Loss: 0.0005961553929569004
Epoch 44/100: Training Loss: 0.00020179312702242312
Epoch 45/100: Training Loss: 0.0009529585396493231
Epoch 46/100: Training Loss: 0.0008242794579559273
Epoch 47/100: Training Loss: 0.0007731838972418458
Epoch 48/100: Training Loss: 0.0012824332172220404
Epoch 49/100: Training Loss: 0.0005311654893668382
Epoch 50/100: Training Loss: 0.0006341279282436504
Epoch 51/100: Training Loss: 0.0008819595083490118
Epoch 52/100: Training Loss: 0.0006935729847087727
Epoch 53/100: Training Loss: 0.000775720012354684
Epoch 54/100: Training Loss: 0.0013212063512602053
Epoch 55/100: Training Loss: 0.001067559410642077
Epoch 56/100: Training Loss: 0.001540524767828988
Epoch 57/100: Training Loss: 0.0007455315102230419
Epoch 58/100: Training Loss: 0.00011758086877269344
Epoch 59/100: Training Loss: 0.0002665892503895126
Epoch 60/100: Training Loss: 0.00046592966451511515
Epoch 61/100: Training Loss: 0.0009497349912470037
Epoch 62/100: Training Loss: 0.0006277844101398975
Epoch 63/100: Training Loss: 0.0009889588072583392
Epoch 64/100: Training Loss: 0.0007855767136687165
Epoch 65/100: Training Loss: 0.0008284431862664389
Epoch 66/100: Training Loss: 0.0007544988831440052
Epoch 67/100: Training Loss: 0.0005848409829439816
Epoch 68/100: Training Loss: 0.0005143176946606669
Epoch 69/100: Training Loss: 0.0008442227344412904
Epoch 70/100: Training Loss: 0.0007052998859565575
Epoch 71/100: Training Loss: 0.00048111181159119507
Epoch 72/100: Training Loss: 0.0005421029937850845
Epoch 73/100: Training Loss: 0.0005576377148394818
Epoch 74/100: Training Loss: 0.0002801557416682477
Epoch 75/100: Training Loss: 0.0006130265293421445
Epoch 76/100: Training Loss: 0.00012391575097620903
Epoch 77/100: Training Loss: 8.437235455412965e-05
Epoch 78/100: Training Loss: 0.0003534558561298397
Epoch 79/100: Training Loss: 0.00033258844714064697
Epoch 80/100: Training Loss: 0.0005932251786018585
Epoch 81/100: Training Loss: 0.000259375316904975
Epoch 82/100: Training Loss: 0.00032129688383816004
Epoch 83/100: Training Loss: 0.000780635519878014
Epoch 84/100: Training Loss: 0.0005048414939766997
Epoch 85/100: Training Loss: 0.0004692881569995747
Epoch 86/100: Training Loss: 0.0005934167054149654
Epoch 87/100: Training Loss: 0.0002769942206519467
Epoch 88/100: Training Loss: 0.000177125023169951
Epoch 89/100: Training Loss: 7.677734731794238e-05
Epoch 90/100: Training Loss: 0.0004339035782780681
Epoch 91/100: Training Loss: 0.00047339556308893056
Epoch 92/100: Training Loss: 0.0006787577396506196
Epoch 93/100: Training Loss: 0.0005601902941723804
Epoch 94/100: Training Loss: 0.000330731585309222
Epoch 95/100: Training Loss: 0.0004151574225275667
Epoch 96/100: Training Loss: 0.0005518907121011427
Epoch 97/100: Training Loss: 0.0005505520042839583
Epoch 98/100: Training Loss: 0.0011814653456627905
Epoch 99/100: Training Loss: 0.00022536401565258319
Epoch 0/100: Training Loss: 0.002763057088518476
Epoch 1/100: Training Loss: 0.0025160935792055998
Epoch 2/100: Training Loss: 0.0023680612757489396
Epoch 3/100: Training Loss: 0.00274954559086086
Epoch 4/100: Training Loss: 0.0023026758140617318
Epoch 5/100: Training Loss: 0.0024234083565798674
Epoch 6/100: Training Loss: 0.0017338917180374786
Epoch 7/100: Training Loss: 0.001580782078362845
Epoch 8/100: Training Loss: 0.002844685024314827
Epoch 9/100: Training Loss: 0.0016277667942580644
Epoch 10/100: Training Loss: 0.001501819783157402
Epoch 11/100: Training Loss: 0.001672923148095191
Epoch 12/100: Training Loss: 0.0015888147420816488
Epoch 13/100: Training Loss: 0.0005913989006222544
Epoch 14/100: Training Loss: 0.001595884978354394
Epoch 15/100: Training Loss: 0.0011051925537469503
Epoch 16/100: Training Loss: 0.0010491477234380229
Epoch 17/100: Training Loss: 0.0013415219483675657
Epoch 18/100: Training Loss: 0.0012271282347765837
Epoch 19/100: Training Loss: 0.0017034347865964982
Epoch 20/100: Training Loss: 0.0011255454558592576
Epoch 21/100: Training Loss: 0.0011837725247536505
Epoch 22/100: Training Loss: 0.0010639805268574428
Epoch 23/100: Training Loss: 0.0009256457532202448
Epoch 24/100: Training Loss: 0.001273986447107542
Epoch 25/100: Training Loss: 0.0011834491799761365
Epoch 26/100: Training Loss: 0.0009045528990405423
Epoch 27/100: Training Loss: 0.001315579026729077
Epoch 28/100: Training Loss: 0.0011179692053294682
Epoch 29/100: Training Loss: 0.0011420768874508519
Epoch 30/100: Training Loss: 0.0012075140342845782
Epoch 31/100: Training Loss: 0.0010871864282167875
Epoch 32/100: Training Loss: 0.0011502065650233022
Epoch 33/100: Training Loss: 0.0009595232826846463
Epoch 34/100: Training Loss: 0.0011988438509560966
Epoch 35/100: Training Loss: 0.0011310636788815051
Epoch 36/100: Training Loss: 0.0010750200990196708
Epoch 37/100: Training Loss: 0.0008334051687400658
Epoch 38/100: Training Loss: 0.0009147435218304187
Epoch 39/100: Training Loss: 0.0009020675312389027
Epoch 40/100: Training Loss: 0.0008407458141967134
Epoch 41/100: Training Loss: 0.0008689268277241633
Epoch 42/100: Training Loss: 0.0008947784667248492
Epoch 43/100: Training Loss: 0.0006625975866417785
Epoch 44/100: Training Loss: 0.0011104133787688676
Epoch 45/100: Training Loss: 0.0010316028044773983
Epoch 46/100: Training Loss: 0.0008885997992295485
Epoch 47/100: Training Loss: 0.0009283334850431322
Epoch 48/100: Training Loss: 0.001319455412717966
Epoch 49/100: Training Loss: 0.0011286196800378652
Epoch 50/100: Training Loss: 0.0008584404220947853
Epoch 51/100: Training Loss: 0.000981805416253897
Epoch 52/100: Training Loss: 0.0007972015992744819
Epoch 53/100: Training Loss: 0.000690870508030578
Epoch 54/100: Training Loss: 0.0006065952194320572
Epoch 55/100: Training Loss: 0.0006865190042482389
Epoch 56/100: Training Loss: 0.0005997016088112251
Epoch 57/100: Training Loss: 0.000864905077260691
Epoch 58/100: Training Loss: 0.00058288757617657
Epoch 59/100: Training Loss: 0.0004551726933959481
Epoch 60/100: Training Loss: 0.0003507955038880968
Epoch 61/100: Training Loss: 0.0008042731901982447
Epoch 62/100: Training Loss: 0.00018685486923147748
Epoch 63/100: Training Loss: 0.0006342440635174304
Epoch 64/100: Training Loss: 0.0016258899773751105
Epoch 65/100: Training Loss: 0.00028501672448811834
Epoch 66/100: Training Loss: 0.0005956335397033425
Epoch 67/100: Training Loss: 0.0009508545582111066
Epoch 68/100: Training Loss: 0.0014199604104448865
Epoch 69/100: Training Loss: 0.00032250200222422196
Epoch 70/100: Training Loss: 0.00030019280168560003
Epoch 71/100: Training Loss: 0.0002687818572654591
Epoch 72/100: Training Loss: 0.0001091754155142324
Epoch 73/100: Training Loss: 0.0005346974813854778
Epoch 74/100: Training Loss: 0.00044014799844968567
Epoch 75/100: Training Loss: 0.0006308504543104372
Epoch 76/100: Training Loss: 0.00010527247055010362
Epoch 77/100: Training Loss: 0.0004483774512797802
Epoch 78/100: Training Loss: 0.00012227952792927935
Epoch 79/100: Training Loss: 0.00045605180980442286
Epoch 80/100: Training Loss: 0.0003734772595075461
Epoch 81/100: Training Loss: 0.00026814212332238683
Epoch 82/100: Training Loss: 0.00013800201143001343
Epoch 83/100: Training Loss: 0.0003872565091489912
Epoch 84/100: Training Loss: 0.0004290204521242555
Epoch 85/100: Training Loss: 0.00022584168644218178
Epoch 86/100: Training Loss: 0.00022644018168215986
Epoch 87/100: Training Loss: 0.00029276907965019867
Epoch 88/100: Training Loss: 0.00030799892607268753
Epoch 89/100: Training Loss: 0.0002617522084212803
Epoch 90/100: Training Loss: 0.0003836637141404452
Epoch 91/100: Training Loss: 0.00024416386247514847
Epoch 92/100: Training Loss: 0.000834481959993189
Epoch 93/100: Training Loss: 0.0008176215566121615
Epoch 94/100: Training Loss: 0.0002627578804959784
Epoch 95/100: Training Loss: 0.00028869465410292567
Epoch 96/100: Training Loss: 0.00044886382309706894
Epoch 97/100: Training Loss: 0.0002089528874917464
Epoch 98/100: Training Loss: 0.00010532496327703649
Epoch 99/100: Training Loss: 0.000355263403454027
Epoch 0/100: Training Loss: 0.002070175358122843
Epoch 1/100: Training Loss: 0.0015109050676135197
Epoch 2/100: Training Loss: 0.0007515841740772036
Epoch 3/100: Training Loss: 0.0020594796154396666
Epoch 4/100: Training Loss: 0.0009641236871298105
Epoch 5/100: Training Loss: 0.0010802120518830657
Epoch 6/100: Training Loss: 0.0006211162801900525
Epoch 7/100: Training Loss: 0.000715455531708302
Epoch 8/100: Training Loss: 0.0008025976594971733
Epoch 9/100: Training Loss: 0.0008197563923209723
Epoch 10/100: Training Loss: 0.0017219311986232829
Epoch 11/100: Training Loss: 0.00137433638236274
Epoch 12/100: Training Loss: 0.0014162128505531264
Epoch 13/100: Training Loss: 0.00134406910717853
Epoch 14/100: Training Loss: 0.0010098562650153974
Epoch 15/100: Training Loss: 0.0007249399836809357
Epoch 16/100: Training Loss: 0.0009390947643233223
Epoch 17/100: Training Loss: 0.0006701853012014752
Epoch 18/100: Training Loss: 0.000523678729870568
Epoch 19/100: Training Loss: 0.0003225819144877919
Epoch 20/100: Training Loss: 0.0003591909136143199
Epoch 21/100: Training Loss: 0.0003785028413760882
Epoch 22/100: Training Loss: 0.0004987112400721918
Epoch 23/100: Training Loss: 0.0004385323520818371
Epoch 24/100: Training Loss: 0.0004967831852245916
Epoch 25/100: Training Loss: 0.0005680157637303592
Epoch 26/100: Training Loss: 0.0007133209632218249
Epoch 27/100: Training Loss: 0.0006201832663793505
Epoch 28/100: Training Loss: 0.0002462320669662733
Epoch 29/100: Training Loss: 0.0002076994467732365
Epoch 30/100: Training Loss: 0.00023079421256948834
Epoch 31/100: Training Loss: 0.00015896539335236227
Epoch 32/100: Training Loss: 0.00014340999804757123
Epoch 33/100: Training Loss: 4.895995342475505e-05
Epoch 34/100: Training Loss: 7.543638005761281e-05
Epoch 35/100: Training Loss: 1.7844683324998142e-06
Epoch 36/100: Training Loss: 0.00013251199267027568
Epoch 37/100: Training Loss: 3.280947727659729e-05
Epoch 38/100: Training Loss: 3.1922391810071615e-06
Epoch 39/100: Training Loss: 0.00034094862411358605
Epoch 40/100: Training Loss: 0.00029422991846236716
Epoch 41/100: Training Loss: 0.00025176707129536964
Epoch 42/100: Training Loss: 0.0004560095400898003
Epoch 43/100: Training Loss: 2.976492093018959e-05
Epoch 44/100: Training Loss: 0.00019520656005736508
Epoch 45/100: Training Loss: 0.00012763157669751923
Epoch 46/100: Training Loss: 0.00016650077572629495
Epoch 47/100: Training Loss: 0.00029535571033237904
Epoch 48/100: Training Loss: 0.00019164551392289027
Epoch 49/100: Training Loss: 0.00018202825420838924
Epoch 50/100: Training Loss: 0.00014289948472216086
Epoch 51/100: Training Loss: 0.0007195432493291749
Epoch 52/100: Training Loss: 0.0008809905659201686
Epoch 53/100: Training Loss: 5.6011564429689405e-06
Epoch 54/100: Training Loss: 1.5178631042684515e-05
Epoch 55/100: Training Loss: 0.00014326297478076138
Epoch 56/100: Training Loss: 7.655619546496795e-05
Epoch 57/100: Training Loss: 4.067625336211883e-05
Epoch 58/100: Training Loss: 0.00011896073498243204
Epoch 59/100: Training Loss: 4.106772309340582e-05
Epoch 60/100: Training Loss: 1.576029555586401e-06
Epoch 61/100: Training Loss: 0.00013096187195163562
Epoch 62/100: Training Loss: 0.00013530333212182565
Epoch 63/100: Training Loss: 9.147192642915468e-05
Epoch 64/100: Training Loss: 0.00019869329464947518
Epoch 65/100: Training Loss: 4.221912347740191e-05
Epoch 66/100: Training Loss: 2.37309448192456e-05
Epoch 67/100: Training Loss: 0.0001053738584913359
Epoch 68/100: Training Loss: 3.956483985565923e-06
Epoch 69/100: Training Loss: 0.0013480724001223325
Epoch 70/100: Training Loss: 3.105985640656729e-05
Epoch 71/100: Training Loss: 3.7227909400647768e-06
Epoch 72/100: Training Loss: 5.070278935271538e-05
Epoch 73/100: Training Loss: 3.1464018978955555e-05
Epoch 74/100: Training Loss: 1.0744463566667829e-05
Epoch 75/100: Training Loss: 3.163115709928647e-06
Epoch 76/100: Training Loss: 2.046284962879734e-06
Epoch 77/100: Training Loss: 1.2752075788159312e-05
Epoch 78/100: Training Loss: 6.044933149602515e-05
Epoch 79/100: Training Loss: 0.00011080024661096327
Epoch 80/100: Training Loss: 0.00011411990307591445
Epoch 81/100: Training Loss: 7.71511963174387e-05
Epoch 82/100: Training Loss: 0.00014599485814205707
Epoch 83/100: Training Loss: 4.036483451998307e-07
Epoch 84/100: Training Loss: 3.713264881398963e-06
Epoch 85/100: Training Loss: 2.369308020016807e-06
Epoch 86/100: Training Loss: 1.2953385555019681e-06
Epoch 87/100: Training Loss: 2.410297104917421e-06
Epoch 88/100: Training Loss: 4.43379144738514e-06
Epoch 89/100: Training Loss: 0.001174979506094763
Epoch 90/100: Training Loss: 2.408312759333593e-05
Epoch 91/100: Training Loss: 1.1448027777479836e-05
Epoch 92/100: Training Loss: 0.00015600102216553835
Epoch 93/100: Training Loss: 0.00010446643034007652
Epoch 94/100: Training Loss: 7.4296008418399864e-06
Epoch 95/100: Training Loss: 3.111876398782057e-05
Epoch 96/100: Training Loss: 1.1453534829276013e-06
Epoch 97/100: Training Loss: 3.9762525927801075e-05
Epoch 98/100: Training Loss: 5.833680335820818e-06
Epoch 99/100: Training Loss: 5.584709029187637e-07
Epoch 0/100: Training Loss: 0.0019481483778339222
Epoch 1/100: Training Loss: 0.0012922133404784408
Epoch 2/100: Training Loss: 0.0009033540092362948
Epoch 3/100: Training Loss: 0.0010290639532124339
Epoch 4/100: Training Loss: 0.0010132845376898175
Epoch 5/100: Training Loss: 0.001177200967548815
Epoch 6/100: Training Loss: 0.0008094006338002492
Epoch 7/100: Training Loss: 0.0006296749860962476
Epoch 8/100: Training Loss: 0.0007841350293598292
Epoch 9/100: Training Loss: 0.0007792057618041711
Epoch 10/100: Training Loss: 0.0008290326851277263
Epoch 11/100: Training Loss: 0.00040611300183220143
Epoch 12/100: Training Loss: 0.0006202160855012437
Epoch 13/100: Training Loss: 0.0007449707096339735
Epoch 14/100: Training Loss: 0.0005527258924911359
Epoch 15/100: Training Loss: 0.0011910474373519055
Epoch 16/100: Training Loss: 0.0017744485585967455
Epoch 17/100: Training Loss: 0.0009062557132697545
Epoch 18/100: Training Loss: 0.0008467404754615269
Epoch 19/100: Training Loss: 0.0006409395326134618
Epoch 20/100: Training Loss: 0.0005807278255012138
Epoch 21/100: Training Loss: 0.00042194598840058215
Epoch 22/100: Training Loss: 0.0014119777211382344
Epoch 23/100: Training Loss: 0.000299977949974727
Epoch 24/100: Training Loss: 0.0001813886241495975
Epoch 25/100: Training Loss: 0.00022496861274257028
Epoch 26/100: Training Loss: 0.00025706379417261464
Epoch 27/100: Training Loss: 6.420563540758531e-05
Epoch 28/100: Training Loss: 0.00017241961065611226
Epoch 29/100: Training Loss: 0.00022407024641709825
Epoch 30/100: Training Loss: 0.0002674319855640271
Epoch 31/100: Training Loss: 0.00014206747655853903
Epoch 32/100: Training Loss: 0.00016079893324272765
Epoch 33/100: Training Loss: 0.0003188885748386383
Epoch 34/100: Training Loss: 0.00017265439536308218
Epoch 35/100: Training Loss: 0.0005409993185587456
Epoch 36/100: Training Loss: 0.00017469358041973933
Epoch 37/100: Training Loss: 0.0002158269331864784
Epoch 38/100: Training Loss: 0.00012270452603240685
Epoch 39/100: Training Loss: 2.38984800372387e-05
Epoch 40/100: Training Loss: 6.432410763816599e-05
Epoch 41/100: Training Loss: 0.0001860799987806133
Epoch 42/100: Training Loss: 0.00023939682205030522
Epoch 43/100: Training Loss: 0.0002230640980729296
Epoch 44/100: Training Loss: 0.000331038597719801
Epoch 45/100: Training Loss: 0.00018845794528174253
Epoch 46/100: Training Loss: 0.0001707610337097952
Epoch 47/100: Training Loss: 0.00022860876987316857
Epoch 48/100: Training Loss: 0.00029099298401112937
Epoch 49/100: Training Loss: 0.00016750212461670482
Epoch 50/100: Training Loss: 2.7711280375901908e-05
Epoch 51/100: Training Loss: 8.168681724671205e-05
Epoch 52/100: Training Loss: 2.1032641921763772e-05
Epoch 53/100: Training Loss: 2.8417305735174132e-05
Epoch 54/100: Training Loss: 3.362287041599765e-05
Epoch 55/100: Training Loss: 0.00018795297418269642
Epoch 56/100: Training Loss: 2.651043133410208e-05
Epoch 57/100: Training Loss: 2.5606574204984618e-05
Epoch 58/100: Training Loss: 0.00013080266721409524
Epoch 59/100: Training Loss: 7.771724760760925e-06
Epoch 60/100: Training Loss: 0.00016552457825903512
Epoch 61/100: Training Loss: 8.204499933800084e-05
Epoch 62/100: Training Loss: 0.00022228247274650386
Epoch 63/100: Training Loss: 5.877616192482732e-05
Epoch 64/100: Training Loss: 1.724367029964924e-05
Epoch 65/100: Training Loss: 0.0015407641606828186
Epoch 66/100: Training Loss: 0.0001839308719510681
Epoch 67/100: Training Loss: 0.0002199279978597091
Epoch 68/100: Training Loss: 0.00028902875042400477
Epoch 69/100: Training Loss: 0.00017529209515799773
Epoch 70/100: Training Loss: 0.0001665383485928635
Epoch 71/100: Training Loss: 0.00017945116465808425
Epoch 72/100: Training Loss: 0.0001492454253274239
Epoch 73/100: Training Loss: 9.79409558824235e-05
Epoch 74/100: Training Loss: 0.0004024738274468966
Epoch 75/100: Training Loss: 3.640823840432189e-06
Epoch 76/100: Training Loss: 0.00013637475303711336
Epoch 77/100: Training Loss: 0.00012520475575894665
Epoch 78/100: Training Loss: 7.275475954716922e-05
Epoch 79/100: Training Loss: 5.2451521752436465e-05
Epoch 80/100: Training Loss: 2.7390699719358806e-05
Epoch 81/100: Training Loss: 8.980572177954246e-06
Epoch 82/100: Training Loss: 3.292592116660136e-05
Epoch 83/100: Training Loss: 2.8775444617094987e-06
Epoch 84/100: Training Loss: 5.8262637513546855e-05
Epoch 85/100: Training Loss: 1.526378135145442e-05
Epoch 86/100: Training Loss: 1.7451172397454825e-05
Epoch 87/100: Training Loss: 5.041231955487304e-05
Epoch 88/100: Training Loss: 9.779936199767824e-06
Epoch 89/100: Training Loss: 8.475864477501325e-05
Epoch 90/100: Training Loss: 0.00016842224846588322
Epoch 91/100: Training Loss: 1.2537097398397382e-05
Epoch 92/100: Training Loss: 0.0001928468286259774
Epoch 93/100: Training Loss: 5.498069104241447e-05
Epoch 94/100: Training Loss: 1.944968351191538e-05
Epoch 95/100: Training Loss: 0.0001233130853417461
Epoch 96/100: Training Loss: 7.881557260371425e-05
Epoch 97/100: Training Loss: 2.986486669789794e-05
Epoch 98/100: Training Loss: 1.9293701443306966e-07
Epoch 99/100: Training Loss: 1.4661542929857512e-06
Epoch 0/100: Training Loss: 0.0019660166070505154
Epoch 1/100: Training Loss: 0.0012439913544918131
Epoch 2/100: Training Loss: 0.0005680068961681764
Epoch 3/100: Training Loss: 0.00179292417011378
Epoch 4/100: Training Loss: 0.0012106819569698871
Epoch 5/100: Training Loss: 0.001139024283988344
Epoch 6/100: Training Loss: 0.0006758384635112037
Epoch 7/100: Training Loss: 0.0005496445517598486
Epoch 8/100: Training Loss: 0.00023001697531507058
Epoch 9/100: Training Loss: 0.0005561206146983282
Epoch 10/100: Training Loss: 0.000299409580376982
Epoch 11/100: Training Loss: 0.0004354050280126326
Epoch 12/100: Training Loss: 0.0002818620460896404
Epoch 13/100: Training Loss: 0.002101271978916566
Epoch 14/100: Training Loss: 0.0007771815807541456
Epoch 15/100: Training Loss: 0.0018355083977517905
Epoch 16/100: Training Loss: 0.001477633517212663
Epoch 17/100: Training Loss: 0.0010859271500008238
Epoch 18/100: Training Loss: 0.0008412618761413668
Epoch 19/100: Training Loss: 0.0008056424329617272
Epoch 20/100: Training Loss: 0.00033870622789932905
Epoch 21/100: Training Loss: 0.000260635844768922
Epoch 22/100: Training Loss: 0.0003514988290751639
Epoch 23/100: Training Loss: 0.0003053741815265702
Epoch 24/100: Training Loss: 0.0004218183686396827
Epoch 25/100: Training Loss: 0.00026921555399894714
Epoch 26/100: Training Loss: 0.0002750152824846513
Epoch 27/100: Training Loss: 0.00014293033835346714
Epoch 28/100: Training Loss: 0.00014315080469005679
Epoch 29/100: Training Loss: 3.9397004671806205e-05
Epoch 30/100: Training Loss: 0.000132828482363853
Epoch 31/100: Training Loss: 8.412621961049507e-05
Epoch 32/100: Training Loss: 4.341200485459866e-05
Epoch 33/100: Training Loss: 0.0001088150325545504
Epoch 34/100: Training Loss: 3.161079655944204e-05
Epoch 35/100: Training Loss: 0.00011357331385641741
Epoch 36/100: Training Loss: 6.438416366014013e-05
Epoch 37/100: Training Loss: 1.305630116329237e-05
Epoch 38/100: Training Loss: 0.0002275089864716208
Epoch 39/100: Training Loss: 2.4555596677255044e-05
Epoch 40/100: Training Loss: 1.2340511201075249e-05
Epoch 41/100: Training Loss: 0.0001234547606457962
Epoch 42/100: Training Loss: 0.00013429338992373345
Epoch 43/100: Training Loss: 0.00018457324455486485
Epoch 44/100: Training Loss: 0.0001747065275176171
Epoch 45/100: Training Loss: 0.00027878516199398624
Epoch 46/100: Training Loss: 0.0001756613902701922
Epoch 47/100: Training Loss: 0.00019852211413207962
Epoch 48/100: Training Loss: 5.630274057571142e-05
Epoch 49/100: Training Loss: 0.00030527714114247657
Epoch 50/100: Training Loss: 0.0003597145568739417
Epoch 51/100: Training Loss: 0.00026642524300177407
Epoch 52/100: Training Loss: 0.00013859469466414188
Epoch 53/100: Training Loss: 1.707449241147085e-05
Epoch 54/100: Training Loss: 9.076098448659745e-05
Epoch 55/100: Training Loss: 1.1765845891293939e-05
Epoch 56/100: Training Loss: 2.6861408888219507e-06
Epoch 57/100: Training Loss: 1.035661270921947e-05
Epoch 58/100: Training Loss: 0.00020775564609129736
Epoch 59/100: Training Loss: 0.0003456223778929447
Epoch 60/100: Training Loss: 1.891113766269084e-05
Epoch 61/100: Training Loss: 4.014293477510565e-06
Epoch 62/100: Training Loss: 3.27778158800825e-06
Epoch 63/100: Training Loss: 5.585602856029762e-06
Epoch 64/100: Training Loss: 1.042924783523966e-06
Epoch 65/100: Training Loss: 6.726225895201502e-06
Epoch 66/100: Training Loss: 5.3135756020394205e-06
Epoch 67/100: Training Loss: 7.53032009294428e-05
Epoch 68/100: Training Loss: 4.598701249899491e-06
Epoch 69/100: Training Loss: 5.510142015898886e-05
Epoch 70/100: Training Loss: 1.3767918743238858e-05
Epoch 71/100: Training Loss: 0.00013052896122259597
Epoch 72/100: Training Loss: 8.499167539590708e-05
Epoch 73/100: Training Loss: 0.00019816389204534285
Epoch 74/100: Training Loss: 6.871727906578889e-06
Epoch 75/100: Training Loss: 3.2037333728162786e-05
Epoch 76/100: Training Loss: 0.0013002759657023144
Epoch 77/100: Training Loss: 8.105792882252324e-05
Epoch 78/100: Training Loss: 0.00010887230603607155
Epoch 79/100: Training Loss: 8.018877631498992e-05
Epoch 80/100: Training Loss: 4.039719369422439e-05
Epoch 81/100: Training Loss: 2.622052718616702e-05
Epoch 82/100: Training Loss: 8.113838680819866e-06
Epoch 83/100: Training Loss: 9.152321737728144e-07
Epoch 84/100: Training Loss: 2.4547998970545876e-06
Epoch 85/100: Training Loss: 0.00035562016572688985
Epoch 86/100: Training Loss: 0.00013300263397167066
Epoch 87/100: Training Loss: 1.1153225615574905e-05
Epoch 88/100: Training Loss: 3.263813177797875e-06
Epoch 89/100: Training Loss: 3.846455436839831e-06
Epoch 90/100: Training Loss: 1.8840320008389788e-05
Epoch 91/100: Training Loss: 2.8934506870851927e-06
Epoch 92/100: Training Loss: 5.884275648834332e-06
Epoch 93/100: Training Loss: 0.001081119560025221
Epoch 94/100: Training Loss: 1.2607287981210311e-05
Epoch 95/100: Training Loss: 3.420495345297218e-06
Epoch 96/100: Training Loss: 8.806105748824547e-05
Epoch 97/100: Training Loss: 4.673964326824147e-05
Epoch 98/100: Training Loss: 2.1218072603016727e-06
Epoch 99/100: Training Loss: 0.001712318395544415
Epoch 0/100: Training Loss: 0.0021905187517404557
Epoch 1/100: Training Loss: 0.0019268060103058815
Epoch 2/100: Training Loss: 0.0015884455293416976
Epoch 3/100: Training Loss: 0.0012578642927110195
Epoch 4/100: Training Loss: 0.0012384189292788505
Epoch 5/100: Training Loss: 0.0008205154910683632
Epoch 6/100: Training Loss: 0.0013293636962771415
Epoch 7/100: Training Loss: 0.0004731412511318922
Epoch 8/100: Training Loss: 0.001129975914955139
Epoch 9/100: Training Loss: 0.0013049940578639507
Epoch 10/100: Training Loss: 0.0004714859183877707
Epoch 11/100: Training Loss: 0.0003754766192287207
Epoch 12/100: Training Loss: 0.0004160419572144747
Epoch 13/100: Training Loss: 0.0005518600344657898
Epoch 14/100: Training Loss: 0.00040090391412377356
Epoch 15/100: Training Loss: 0.0007447266485542059
Epoch 16/100: Training Loss: 0.0003313051303848624
Epoch 17/100: Training Loss: 0.0002356225857511163
Epoch 18/100: Training Loss: 0.0003655245993286371
Epoch 19/100: Training Loss: 0.0002745470264926553
Epoch 20/100: Training Loss: 0.00016102346125990152
Epoch 21/100: Training Loss: 0.00036537959240376947
Epoch 22/100: Training Loss: 0.00016411051619797946
Epoch 23/100: Training Loss: 0.00024198819883167744
Epoch 24/100: Training Loss: 0.00023392539005726576
Epoch 25/100: Training Loss: 0.00017298184102401137
Epoch 26/100: Training Loss: 0.0002829584991559386
Epoch 27/100: Training Loss: 9.685612167231739e-05
Epoch 28/100: Training Loss: 0.00010792720131576061
Epoch 29/100: Training Loss: 0.00012832359643653036
Epoch 30/100: Training Loss: 7.148653967306017e-05
Epoch 31/100: Training Loss: 6.81505596730858e-05
Epoch 32/100: Training Loss: 5.8408407494425776e-05
Epoch 33/100: Training Loss: 9.627119288779795e-05
Epoch 34/100: Training Loss: 9.4178895233199e-05
Epoch 35/100: Training Loss: 0.000134404085110873
Epoch 36/100: Training Loss: 0.00010703535517677664
Epoch 37/100: Training Loss: 0.00013835851568728686
Epoch 38/100: Training Loss: 7.650238112546503e-05
Epoch 39/100: Training Loss: 0.00019554458558559417
Epoch 40/100: Training Loss: 9.902712190523744e-05
Epoch 41/100: Training Loss: 0.00011750345584005117
Epoch 42/100: Training Loss: 8.341986685991287e-05
Epoch 43/100: Training Loss: 6.670458824373782e-05
Epoch 44/100: Training Loss: 7.555075571872294e-05
Epoch 45/100: Training Loss: 0.0001376800471916795
Epoch 46/100: Training Loss: 3.251969756092876e-05
Epoch 47/100: Training Loss: 5.750052514486015e-05
Epoch 48/100: Training Loss: 0.00011360344942659139
Epoch 49/100: Training Loss: 0.00016688136383891106
Epoch 50/100: Training Loss: 4.194376524537802e-05
Epoch 51/100: Training Loss: 5.5672164307907224e-05
Epoch 52/100: Training Loss: 0.00012305086711421608
Epoch 53/100: Training Loss: 6.911451346240938e-05
Epoch 54/100: Training Loss: 6.483901524916292e-05
Epoch 55/100: Training Loss: 5.7883607223629954e-05
Epoch 56/100: Training Loss: 4.893082659691572e-05
Epoch 57/100: Training Loss: 6.401391583494842e-05
Epoch 58/100: Training Loss: 7.412447594106198e-05
Epoch 59/100: Training Loss: 8.313782745972276e-05
Epoch 60/100: Training Loss: 0.00016891778213903307
Epoch 61/100: Training Loss: 0.00014025308191776276
Epoch 62/100: Training Loss: 0.00012421244755387307
Epoch 63/100: Training Loss: 0.0001741007319651544
Epoch 64/100: Training Loss: 0.00013554731849581004
Epoch 65/100: Training Loss: 0.0002367726992815733
Epoch 66/100: Training Loss: 0.00011438012588769198
Epoch 67/100: Training Loss: 0.00028369072824716566
Epoch 68/100: Training Loss: 3.8775111897848545e-05
Epoch 69/100: Training Loss: 0.00029236010741442444
Epoch 70/100: Training Loss: 9.633893496356905e-05
Epoch 71/100: Training Loss: 0.0003196739824488759
Epoch 72/100: Training Loss: 9.055870468728244e-05
Epoch 73/100: Training Loss: 0.0001248207176104188
Epoch 74/100: Training Loss: 7.178460364229978e-05
Epoch 75/100: Training Loss: 0.0001040773349814117
Epoch 76/100: Training Loss: 9.81191173195839e-05
Epoch 77/100: Training Loss: 0.00025743951555341483
Epoch 78/100: Training Loss: 0.0001663453644141555
Epoch 79/100: Training Loss: 6.861832225695253e-05
Epoch 80/100: Training Loss: 0.00012916821287944913
Epoch 81/100: Training Loss: 9.865449974313378e-05
Epoch 82/100: Training Loss: 6.211266736499965e-05
Epoch 83/100: Training Loss: 0.00011315708979964256
Epoch 84/100: Training Loss: 0.00016657570376992225
Epoch 85/100: Training Loss: 0.0002003122353926301
Epoch 86/100: Training Loss: 0.00014530103653669356
Epoch 87/100: Training Loss: 0.00014863619580864906
Epoch 88/100: Training Loss: 0.000118919275701046
Epoch 89/100: Training Loss: 0.00011791212018579245
Epoch 90/100: Training Loss: 0.0001333502004854381
Epoch 91/100: Training Loss: 0.0001839249162003398
Epoch 92/100: Training Loss: 9.88979241810739e-05
Epoch 93/100: Training Loss: 0.00017923075938597322
Epoch 94/100: Training Loss: 0.00012056392151862382
Epoch 95/100: Training Loss: 0.00014975283993408085
Epoch 96/100: Training Loss: 9.726602002047002e-05
Epoch 97/100: Training Loss: 9.498355211690068e-05
Epoch 98/100: Training Loss: 0.00012706929119303821
Epoch 99/100: Training Loss: 5.8827578322961925e-05
Epoch 0/100: Training Loss: 0.0021327069029212
Epoch 1/100: Training Loss: 0.0018686911091208458
Epoch 2/100: Training Loss: 0.0019447745755314827
Epoch 3/100: Training Loss: 0.0013959350064396859
Epoch 4/100: Training Loss: 0.0012848417274653912
Epoch 5/100: Training Loss: 0.0008617016486823559
Epoch 6/100: Training Loss: 0.0005188101436942816
Epoch 7/100: Training Loss: 0.0008268842473626136
Epoch 8/100: Training Loss: 0.0007314294576644898
Epoch 9/100: Training Loss: 0.00032351037953048944
Epoch 10/100: Training Loss: 0.0006397259887307883
Epoch 11/100: Training Loss: 0.0003002621466293931
Epoch 12/100: Training Loss: 0.00021021019201725722
Epoch 13/100: Training Loss: 0.00029789188411086796
Epoch 14/100: Training Loss: 0.0004092694725841284
Epoch 15/100: Training Loss: 0.0003155774204060435
Epoch 16/100: Training Loss: 0.0005152775440365076
Epoch 17/100: Training Loss: 0.00011907389853149652
Epoch 18/100: Training Loss: 0.0001785938860848546
Epoch 19/100: Training Loss: 0.00017280360916629433
Epoch 20/100: Training Loss: 0.00014557891990989446
Epoch 21/100: Training Loss: 0.0001897427369840443
Epoch 22/100: Training Loss: 0.0002749970415607095
Epoch 23/100: Training Loss: 0.0001485600834712386
Epoch 24/100: Training Loss: 0.0003054391127079725
Epoch 25/100: Training Loss: 0.00014121957356110214
Epoch 26/100: Training Loss: 0.00019698364194482566
Epoch 27/100: Training Loss: 0.0001349112717434764
Epoch 28/100: Training Loss: 0.0002059949329122901
Epoch 29/100: Training Loss: 0.0001156309968791902
Epoch 30/100: Training Loss: 0.00023491426836699247
Epoch 31/100: Training Loss: 0.00011452736798673868
Epoch 32/100: Training Loss: 6.698115030303597e-05
Epoch 33/100: Training Loss: 8.126915781758726e-05
Epoch 34/100: Training Loss: 0.0001688539399765432
Epoch 35/100: Training Loss: 0.00010912815341725945
Epoch 36/100: Training Loss: 0.00017759468173608183
Epoch 37/100: Training Loss: 0.00022486930247396232
Epoch 38/100: Training Loss: 0.00016599319642409682
Epoch 39/100: Training Loss: 0.0001349625177681446
Epoch 40/100: Training Loss: 0.0001911985920742154
Epoch 41/100: Training Loss: 0.00012404005974531174
Epoch 42/100: Training Loss: 0.00010166041320189834
Epoch 43/100: Training Loss: 8.225840283557773e-05
Epoch 44/100: Training Loss: 0.00012721773236989975
Epoch 45/100: Training Loss: 7.799188024364412e-05
Epoch 46/100: Training Loss: 0.00015578040620312095
Epoch 47/100: Training Loss: 0.00021096635609865188
Epoch 48/100: Training Loss: 8.042007102631033e-05
Epoch 49/100: Training Loss: 7.705512689426541e-05
Epoch 50/100: Training Loss: 6.23553351033479e-05
Epoch 51/100: Training Loss: 8.273227140307427e-05
Epoch 52/100: Training Loss: 0.00014100035186856986
Epoch 53/100: Training Loss: 0.00017944081919267773
Epoch 54/100: Training Loss: 0.000252678245306015
Epoch 55/100: Training Loss: 0.00014909086748957635
Epoch 56/100: Training Loss: 0.00026790902484208345
Epoch 57/100: Training Loss: 0.00014121331041678787
Epoch 58/100: Training Loss: 0.0001245967927388847
Epoch 59/100: Training Loss: 0.0003969075158238411
Epoch 60/100: Training Loss: 0.0001705888076685369
Epoch 61/100: Training Loss: 0.00012605257797986268
Epoch 62/100: Training Loss: 0.0002011558972299099
Epoch 63/100: Training Loss: 0.00012852319050580264
Epoch 64/100: Training Loss: 0.0001865471014752984
Epoch 65/100: Training Loss: 0.00011239951709285378
Epoch 66/100: Training Loss: 0.00010572418104857207
Epoch 67/100: Training Loss: 0.00010934575693681836
Epoch 68/100: Training Loss: 0.000273708114400506
Epoch 69/100: Training Loss: 0.0010340052656829357
Epoch 70/100: Training Loss: 3.575626469682902e-05
Epoch 71/100: Training Loss: 0.00010391902178525924
Epoch 72/100: Training Loss: 0.00021358863450586795
Epoch 73/100: Training Loss: 3.357285168021917e-05
Epoch 74/100: Training Loss: 9.410897619090974e-05
Epoch 75/100: Training Loss: 0.00010448683751747012
Epoch 76/100: Training Loss: 0.0002475179731845856
Epoch 77/100: Training Loss: 0.00011243202025070786
Epoch 78/100: Training Loss: 0.0002846241230145097
Epoch 79/100: Training Loss: 0.00015721211675554514
Epoch 80/100: Training Loss: 0.00010029661934822798
Epoch 81/100: Training Loss: 0.00038935437332838775
Epoch 82/100: Training Loss: 0.00012006470933556557
Epoch 83/100: Training Loss: 0.00014198168646544217
Epoch 84/100: Training Loss: 0.00012423753505572677
Epoch 85/100: Training Loss: 0.00015062432503327728
Epoch 86/100: Training Loss: 8.740583434700966e-05
Epoch 87/100: Training Loss: 0.00017290922114625572
Epoch 88/100: Training Loss: 5.206668865866959e-05
Epoch 89/100: Training Loss: 0.0001559855416417122
Epoch 90/100: Training Loss: 0.00019823370967060329
Epoch 91/100: Training Loss: 9.6427887910977e-05
Epoch 92/100: Training Loss: 0.0001458460814319551
Epoch 93/100: Training Loss: 0.00012318280059844255
Epoch 94/100: Training Loss: 0.00013482406502589582
Epoch 95/100: Training Loss: 9.631174034439028e-05
Epoch 96/100: Training Loss: 0.0003490871051326394
Epoch 97/100: Training Loss: 0.00038989931344985963
Epoch 98/100: Training Loss: 8.997704717330634e-05
Epoch 99/100: Training Loss: 9.691136074252427e-05
Epoch 0/100: Training Loss: 0.00238705612719059
Epoch 1/100: Training Loss: 0.0012125886976718902
Epoch 2/100: Training Loss: 0.0012714589945971965
Epoch 3/100: Training Loss: 0.0011642013676464557
Epoch 4/100: Training Loss: 0.0005729548167437315
Epoch 5/100: Training Loss: 0.0007456619292497635
Epoch 6/100: Training Loss: 0.0007329915184527636
Epoch 7/100: Training Loss: 0.00037717469967901707
Epoch 8/100: Training Loss: 0.00041790157556533816
Epoch 9/100: Training Loss: 0.0005059048533439636
Epoch 10/100: Training Loss: 0.00030936424154788257
Epoch 11/100: Training Loss: 0.0003612116212025285
Epoch 12/100: Training Loss: 0.0007642080076038837
Epoch 13/100: Training Loss: 0.0002635331358760595
Epoch 14/100: Training Loss: 0.0004889823962002992
Epoch 15/100: Training Loss: 0.0004414945375174284
Epoch 16/100: Training Loss: 0.0003264258150011301
Epoch 17/100: Training Loss: 0.00033457630779594184
Epoch 18/100: Training Loss: 0.000354673876427114
Epoch 19/100: Training Loss: 0.0002007418777793646
Epoch 20/100: Training Loss: 0.00025520205963402987
Epoch 21/100: Training Loss: 0.0001749103656038642
Epoch 22/100: Training Loss: 0.00021830243058502675
Epoch 23/100: Training Loss: 0.00031531874556094407
Epoch 24/100: Training Loss: 0.0001122104935348034
Epoch 25/100: Training Loss: 0.00017630794318392872
Epoch 26/100: Training Loss: 0.00014995710225775837
Epoch 27/100: Training Loss: 0.00010667849564924837
Epoch 28/100: Training Loss: 8.393771131522953e-05
Epoch 29/100: Training Loss: 0.00011508036404848099
Epoch 30/100: Training Loss: 0.00011429901933297515
Epoch 31/100: Training Loss: 9.15990793146193e-05
Epoch 32/100: Training Loss: 0.00013903764775022865
Epoch 33/100: Training Loss: 0.00013133425964042544
Epoch 34/100: Training Loss: 0.00011753548169508576
Epoch 35/100: Training Loss: 0.00010057596955448389
Epoch 36/100: Training Loss: 7.246261811815203e-05
Epoch 37/100: Training Loss: 3.3944527967832985e-05
Epoch 38/100: Training Loss: 6.504236371256411e-05
Epoch 39/100: Training Loss: 6.705116247758269e-05
Epoch 40/100: Training Loss: 0.00017909096786752343
Epoch 41/100: Training Loss: 3.2358660246245566e-05
Epoch 42/100: Training Loss: 8.084815344773233e-05
Epoch 43/100: Training Loss: 6.109325331635774e-05
Epoch 44/100: Training Loss: 7.482576183974743e-05
Epoch 45/100: Training Loss: 0.00010251017520204186
Epoch 46/100: Training Loss: 6.750671891495586e-05
Epoch 47/100: Training Loss: 7.677663816139103e-05
Epoch 48/100: Training Loss: 0.000175472185947001
Epoch 49/100: Training Loss: 0.00010866180527955294
Epoch 50/100: Training Loss: 0.0002563232555985451
Epoch 51/100: Training Loss: 0.00027210440021008253
Epoch 52/100: Training Loss: 5.082890274934471e-05
Epoch 53/100: Training Loss: 0.00016527081606909633
Epoch 54/100: Training Loss: 9.834221564233303e-05
Epoch 55/100: Training Loss: 0.0005115666426718235
Epoch 56/100: Training Loss: 9.17922705411911e-05
Epoch 57/100: Training Loss: 9.471821249462664e-05
Epoch 58/100: Training Loss: 5.935262306593359e-05
Epoch 59/100: Training Loss: 0.0002129176864400506
Epoch 60/100: Training Loss: 4.8498620162717995e-05
Epoch 61/100: Training Loss: 0.00011305783409625292
Epoch 62/100: Training Loss: 0.0002886872971430421
Epoch 63/100: Training Loss: 0.00025659077800810337
Epoch 64/100: Training Loss: 5.367856938391924e-05
Epoch 65/100: Training Loss: 5.2750087343156336e-05
Epoch 66/100: Training Loss: 5.477891536429524e-05
Epoch 67/100: Training Loss: 0.0001419425359927118
Epoch 68/100: Training Loss: 0.0002365749329328537
Epoch 69/100: Training Loss: 0.00014671323588117958
Epoch 70/100: Training Loss: 0.00018026807811111212
Epoch 71/100: Training Loss: 0.0001255149720236659
Epoch 72/100: Training Loss: 7.831313996575773e-05
Epoch 73/100: Training Loss: 0.00022260139230638741
Epoch 74/100: Training Loss: 6.340639083646238e-05
Epoch 75/100: Training Loss: 0.0001580473966896534
Epoch 76/100: Training Loss: 0.00011415125336498023
Epoch 77/100: Training Loss: 0.00010571667226031423
Epoch 78/100: Training Loss: 0.00018178534228354692
Epoch 79/100: Training Loss: 0.00021377692464739085
Epoch 80/100: Training Loss: 0.00015293287578970193
Epoch 81/100: Training Loss: 1.267361076315865e-05
Epoch 82/100: Training Loss: 0.00019552267622202635
Epoch 83/100: Training Loss: 0.00013191504403948785
Epoch 84/100: Training Loss: 0.00015648073749616743
Epoch 85/100: Training Loss: 0.0002487709745764732
Epoch 86/100: Training Loss: 9.749761084094643e-05
Epoch 87/100: Training Loss: 0.00010434872237965464
Epoch 88/100: Training Loss: 0.000150837074033916
Epoch 89/100: Training Loss: 0.00017579824198037385
Epoch 90/100: Training Loss: 0.00013560142833739518
Epoch 91/100: Training Loss: 0.0002013788791373372
Epoch 92/100: Training Loss: 0.00011760225752368569
Epoch 93/100: Training Loss: 9.872530354186893e-05
Epoch 94/100: Training Loss: 0.00010033140424638986
Epoch 95/100: Training Loss: 0.000132593116723001
Epoch 96/100: Training Loss: 6.295864586718381e-05
Epoch 97/100: Training Loss: 0.00016555350739508868
Epoch 98/100: Training Loss: 0.0002152451779693365
Epoch 99/100: Training Loss: 0.00012710200389847158
Epoch 0/100: Training Loss: 0.0012337206655247195
Epoch 1/100: Training Loss: 0.0005273272752002546
Epoch 2/100: Training Loss: 0.0016662947311522854
Epoch 3/100: Training Loss: 0.0008722078648342449
Epoch 4/100: Training Loss: 0.001372080130182254
Epoch 5/100: Training Loss: 0.001253077938298511
Epoch 6/100: Training Loss: 0.0014812129128510786
Epoch 7/100: Training Loss: 0.0013219965681148943
Epoch 8/100: Training Loss: 0.001062387588677133
Epoch 9/100: Training Loss: 0.0013460739972485098
Epoch 10/100: Training Loss: 0.001270013914746084
Epoch 11/100: Training Loss: 0.0014240702815875885
Epoch 12/100: Training Loss: 0.0014730599845290944
Epoch 13/100: Training Loss: 0.0013857195331792164
Epoch 14/100: Training Loss: 0.0013580740826904395
Epoch 15/100: Training Loss: 0.00048081880542123393
Epoch 16/100: Training Loss: 0.0019477334371797597
Epoch 17/100: Training Loss: 0.0015334380660087439
Epoch 18/100: Training Loss: 0.0015732497925970963
Epoch 19/100: Training Loss: 0.001024548415165798
Epoch 20/100: Training Loss: 0.0008381206518525531
Epoch 21/100: Training Loss: 0.00077724589663706
Epoch 22/100: Training Loss: 0.0007777703795463416
Epoch 23/100: Training Loss: 0.0007521057869218717
Epoch 24/100: Training Loss: 0.000805902348202505
Epoch 25/100: Training Loss: 0.0009443703920218596
Epoch 26/100: Training Loss: 0.0010171208981495754
Epoch 27/100: Training Loss: 0.0011049266074113786
Epoch 28/100: Training Loss: 0.0010142567431091502
Epoch 29/100: Training Loss: 0.0010331856786825095
Epoch 30/100: Training Loss: 0.001041405519862084
Epoch 31/100: Training Loss: 0.0010433925944528762
Epoch 32/100: Training Loss: 0.0010654685223937795
Epoch 33/100: Training Loss: 0.000999413003587419
Epoch 34/100: Training Loss: 0.0009494900323782757
Epoch 35/100: Training Loss: 0.0010810520049113377
Epoch 36/100: Training Loss: 0.0008617568357734923
Epoch 37/100: Training Loss: 0.0008560614601062362
Epoch 38/100: Training Loss: 0.0008428922504376454
Epoch 39/100: Training Loss: 0.000895597847403994
Epoch 40/100: Training Loss: 0.0008558085200133597
Epoch 41/100: Training Loss: 0.000855267807176918
Epoch 42/100: Training Loss: 0.0005852762301256702
Epoch 43/100: Training Loss: 0.00031414191434337834
Epoch 44/100: Training Loss: 0.0007655036867044533
Epoch 45/100: Training Loss: 0.0009768155350047313
Epoch 46/100: Training Loss: 0.0007692233297475584
Epoch 47/100: Training Loss: 0.0009060670046290015
Epoch 48/100: Training Loss: 0.0007322425865064001
Epoch 49/100: Training Loss: 0.0007026162306973889
Epoch 50/100: Training Loss: 0.0007004430814153829
Epoch 51/100: Training Loss: 0.0006860030020118519
Epoch 52/100: Training Loss: 0.0005189963396947095
Epoch 53/100: Training Loss: 0.0008011683347118888
Epoch 54/100: Training Loss: 0.001082189998049645
Epoch 55/100: Training Loss: 0.0007287351189145617
Epoch 56/100: Training Loss: 0.0007639244483534697
Epoch 57/100: Training Loss: 0.0008880992414085729
Epoch 58/100: Training Loss: 0.0008031816049745888
Epoch 59/100: Training Loss: 0.0005207130104113537
Epoch 60/100: Training Loss: 0.0007237096785739728
Epoch 61/100: Training Loss: 0.0008068855401057347
Epoch 62/100: Training Loss: 0.000740928634716447
Epoch 63/100: Training Loss: 0.000942163596487349
Epoch 64/100: Training Loss: 0.0008432699996195022
Epoch 65/100: Training Loss: 0.0008482544854947716
Epoch 66/100: Training Loss: 0.0003942240290581041
Epoch 67/100: Training Loss: 0.0007001718707904694
Epoch 68/100: Training Loss: 0.0009470526010367521
Epoch 69/100: Training Loss: 0.000772093084587413
Epoch 70/100: Training Loss: 0.0006568194574611202
Epoch 71/100: Training Loss: 0.0005643913035939454
Epoch 72/100: Training Loss: 0.0005777507166194308
Epoch 73/100: Training Loss: 0.00034125918036053896
Epoch 74/100: Training Loss: 0.0006107590190923898
Epoch 75/100: Training Loss: 0.0008644487257975682
Epoch 76/100: Training Loss: 0.0005257875676367693
Epoch 77/100: Training Loss: 0.0008260077162153402
Epoch 78/100: Training Loss: 0.0008464031348562544
Epoch 79/100: Training Loss: 0.0013444723596998081
Epoch 80/100: Training Loss: 0.0009164952548446169
Epoch 81/100: Training Loss: 0.00038827364896513094
Epoch 82/100: Training Loss: 0.0007927819232272494
Epoch 83/100: Training Loss: 0.00075032576254219
Epoch 84/100: Training Loss: 0.0007774339170212958
Epoch 85/100: Training Loss: 0.0007062295250072601
Epoch 86/100: Training Loss: 0.0008761313310853995
Epoch 87/100: Training Loss: 0.0005328137498752327
Epoch 88/100: Training Loss: 0.000548710963528627
Epoch 89/100: Training Loss: 0.0008582419650569842
Epoch 90/100: Training Loss: 0.0006242156693130542
Epoch 91/100: Training Loss: 0.0005227358667713822
Epoch 92/100: Training Loss: 0.0009936774802056089
Epoch 93/100: Training Loss: 0.0006895993545556524
Epoch 94/100: Training Loss: 0.0004415259619427335
Epoch 95/100: Training Loss: 0.0007962258947882682
Epoch 96/100: Training Loss: 0.0008630658600740372
Epoch 97/100: Training Loss: 0.0008268339239108335
Epoch 98/100: Training Loss: 0.0008069459040453479
Epoch 99/100: Training Loss: 0.0006138026524501242
Epoch 0/100: Training Loss: 0.0012664512084547882
Epoch 1/100: Training Loss: 0.0011790641553842338
Epoch 2/100: Training Loss: 0.0008627426852086547
Epoch 3/100: Training Loss: 0.001022752018491174
Epoch 4/100: Training Loss: 0.0010134882418213376
Epoch 5/100: Training Loss: 0.0014253419106173668
Epoch 6/100: Training Loss: 0.0008560891743678196
Epoch 7/100: Training Loss: 0.0007615602889638038
Epoch 8/100: Training Loss: 0.0011655555409231003
Epoch 9/100: Training Loss: 0.0008946221535372885
Epoch 10/100: Training Loss: 0.00139059752795347
Epoch 11/100: Training Loss: 0.0016952158918805943
Epoch 12/100: Training Loss: 0.0011508870086852153
Epoch 13/100: Training Loss: 0.0013913184784020587
Epoch 14/100: Training Loss: 0.001404935482201303
Epoch 15/100: Training Loss: 0.0015495875079161042
Epoch 16/100: Training Loss: 0.0012556351484007138
Epoch 17/100: Training Loss: 0.000961648430793908
Epoch 18/100: Training Loss: 0.0012774831929783911
Epoch 19/100: Training Loss: 0.001612591136033368
Epoch 20/100: Training Loss: 0.0015145136862044122
Epoch 21/100: Training Loss: 0.001428750195321004
Epoch 22/100: Training Loss: 0.00158369503203471
Epoch 23/100: Training Loss: 0.001106396886953123
Epoch 24/100: Training Loss: 0.0011868347787553338
Epoch 25/100: Training Loss: 0.0010937543431664728
Epoch 26/100: Training Loss: 0.0010279726450610313
Epoch 27/100: Training Loss: 0.0009935885477977194
Epoch 28/100: Training Loss: 0.001081320605460246
Epoch 29/100: Training Loss: 0.0009671144045082626
Epoch 30/100: Training Loss: 0.00100625994478821
Epoch 31/100: Training Loss: 0.0009685849687855715
Epoch 32/100: Training Loss: 0.0008297873910065669
Epoch 33/100: Training Loss: 0.0009381621126915998
Epoch 34/100: Training Loss: 0.0004766856788829633
Epoch 35/100: Training Loss: 0.0008819167781028019
Epoch 36/100: Training Loss: 0.0009191691116162926
Epoch 37/100: Training Loss: 0.0008455481688687756
Epoch 38/100: Training Loss: 0.0010964595208502119
Epoch 39/100: Training Loss: 0.0008884028644318793
Epoch 40/100: Training Loss: 0.0007789824039313444
Epoch 41/100: Training Loss: 0.0008035713130501426
Epoch 42/100: Training Loss: 0.0009755787386256418
Epoch 43/100: Training Loss: 0.0008691958371241381
Epoch 44/100: Training Loss: 0.0009425554875355617
Epoch 45/100: Training Loss: 0.0009212653348400335
Epoch 46/100: Training Loss: 0.0006644302967247689
Epoch 47/100: Training Loss: 0.0009381558485091872
Epoch 48/100: Training Loss: 0.0009713383616915174
Epoch 49/100: Training Loss: 0.0008961652304716171
Epoch 50/100: Training Loss: 0.0007980989802415203
Epoch 51/100: Training Loss: 0.000265499754885959
Epoch 52/100: Training Loss: 0.0006397812134900671
Epoch 53/100: Training Loss: 0.0009764698660297759
Epoch 54/100: Training Loss: 0.0007643871436453169
Epoch 55/100: Training Loss: 0.0008641455773335353
Epoch 56/100: Training Loss: 0.00043899499496836573
Epoch 57/100: Training Loss: 0.0005369923391919227
Epoch 58/100: Training Loss: 0.0006792245397142544
Epoch 59/100: Training Loss: 0.0007803898992811798
Epoch 60/100: Training Loss: 0.0009104341838010558
Epoch 61/100: Training Loss: 0.0009219207961088533
Epoch 62/100: Training Loss: 0.0010958173472410554
Epoch 63/100: Training Loss: 0.001016540607069708
Epoch 64/100: Training Loss: 0.0007630721398979236
Epoch 65/100: Training Loss: 0.0007615684513833113
Epoch 66/100: Training Loss: 0.0011360684208049897
Epoch 67/100: Training Loss: 0.0010446478986436394
Epoch 68/100: Training Loss: 0.0007873147631147105
Epoch 69/100: Training Loss: 0.00045155748060554457
Epoch 70/100: Training Loss: 0.0005518707689965606
Epoch 71/100: Training Loss: 0.0006535969152572049
Epoch 72/100: Training Loss: 0.0005594636224637365
Epoch 73/100: Training Loss: 0.0010654337846549454
Epoch 74/100: Training Loss: 0.001157113036532311
Epoch 75/100: Training Loss: 0.0010026229225146542
Epoch 76/100: Training Loss: 0.0011247681204680424
Epoch 77/100: Training Loss: 0.0005811515981983987
Epoch 78/100: Training Loss: 0.0005300317885010106
Epoch 79/100: Training Loss: 0.000757150067265626
Epoch 80/100: Training Loss: 0.0007841899326652478
Epoch 81/100: Training Loss: 0.0008030624905968928
Epoch 82/100: Training Loss: 0.0008394443874905823
Epoch 83/100: Training Loss: 0.0006691089766040729
Epoch 84/100: Training Loss: 0.0005401340639515288
Epoch 85/100: Training Loss: 0.0010800429020717645
Epoch 86/100: Training Loss: 0.0006209028659352831
Epoch 87/100: Training Loss: 0.000848306497191168
Epoch 88/100: Training Loss: 0.0007493424282711782
Epoch 89/100: Training Loss: 0.0007803396434540961
Epoch 90/100: Training Loss: 0.0006826704095123679
Epoch 91/100: Training Loss: 0.0005420470123837708
Epoch 92/100: Training Loss: 0.0007030413408947599
Epoch 93/100: Training Loss: 0.0003138762323340033
Epoch 94/100: Training Loss: 0.0006951379358388816
Epoch 95/100: Training Loss: 0.0005949390162328246
Epoch 96/100: Training Loss: 0.0006941402224218769
Epoch 97/100: Training Loss: 0.0010960051778015818
Epoch 98/100: Training Loss: 0.0005679417188000528
Epoch 99/100: Training Loss: 0.0004470484082106572
Epoch 0/100: Training Loss: 0.0023342519049431867
Epoch 1/100: Training Loss: 0.0016684501793733828
Epoch 2/100: Training Loss: 0.0011149306965481704
Epoch 3/100: Training Loss: 0.00113567178416404
Epoch 4/100: Training Loss: 0.0011591530719380469
Epoch 5/100: Training Loss: 0.0011730247242435529
Epoch 6/100: Training Loss: 0.00066164449142043
Epoch 7/100: Training Loss: 0.000638881211827515
Epoch 8/100: Training Loss: 0.0007948207722348013
Epoch 9/100: Training Loss: 0.0012479843987021476
Epoch 10/100: Training Loss: 0.001244235854999275
Epoch 11/100: Training Loss: 0.0016076807763166488
Epoch 12/100: Training Loss: 0.0017411036855855566
Epoch 13/100: Training Loss: 0.0019772020494861968
Epoch 14/100: Training Loss: 0.0015975197029721206
Epoch 15/100: Training Loss: 0.0019055390433900675
Epoch 16/100: Training Loss: 0.0015016686005197514
Epoch 17/100: Training Loss: 0.0014827315974387393
Epoch 18/100: Training Loss: 0.001369039249268307
Epoch 19/100: Training Loss: 0.001288385338084713
Epoch 20/100: Training Loss: 0.0014063810846608156
Epoch 21/100: Training Loss: 0.0012352604205441322
Epoch 22/100: Training Loss: 0.001050348589374761
Epoch 23/100: Training Loss: 0.0011746980202425818
Epoch 24/100: Training Loss: 0.0010942528202275562
Epoch 25/100: Training Loss: 0.0006544405392780425
Epoch 26/100: Training Loss: 0.001054026328833999
Epoch 27/100: Training Loss: 0.0011245326441564377
Epoch 28/100: Training Loss: 0.001158354578504137
Epoch 29/100: Training Loss: 0.0009758950798374833
Epoch 30/100: Training Loss: 0.0005656218832465493
Epoch 31/100: Training Loss: 0.0007885847311870308
Epoch 32/100: Training Loss: 0.0007895814954854881
Epoch 33/100: Training Loss: 0.001084257937540674
Epoch 34/100: Training Loss: 0.0005570632067455608
Epoch 35/100: Training Loss: 0.0007433783096872317
Epoch 36/100: Training Loss: 0.000837298335543104
Epoch 37/100: Training Loss: 0.0005613570665098299
Epoch 38/100: Training Loss: 0.0006221157445269785
Epoch 39/100: Training Loss: 0.0007096017432060971
Epoch 40/100: Training Loss: 0.0009319606670148813
Epoch 41/100: Training Loss: 0.001164610978144749
Epoch 42/100: Training Loss: 0.0009838954848089036
Epoch 43/100: Training Loss: 0.0009279542478026857
Epoch 44/100: Training Loss: 0.0009834310811036712
Epoch 45/100: Training Loss: 0.0009552020176201109
Epoch 46/100: Training Loss: 0.0009573862241331938
Epoch 47/100: Training Loss: 0.0009006024545924679
Epoch 48/100: Training Loss: 0.001137557587805827
Epoch 49/100: Training Loss: 0.0004925353891530614
Epoch 50/100: Training Loss: 0.0008936587032998443
Epoch 51/100: Training Loss: 0.0007047899494505232
Epoch 52/100: Training Loss: 0.0005586307234824843
Epoch 53/100: Training Loss: 0.0010588394988114667
Epoch 54/100: Training Loss: 0.00033972877415881797
Epoch 55/100: Training Loss: 0.0004378724250064534
Epoch 56/100: Training Loss: 0.0007068249070720308
Epoch 57/100: Training Loss: 0.0009585124482015136
Epoch 58/100: Training Loss: 0.00033587646807075304
Epoch 59/100: Training Loss: 0.0004232463658235635
Epoch 60/100: Training Loss: 0.0007637133169326053
Epoch 61/100: Training Loss: 0.000571902058306773
Epoch 62/100: Training Loss: 0.0007856059700820097
Epoch 63/100: Training Loss: 0.0006520184836569865
Epoch 64/100: Training Loss: 0.00039638602619717836
Epoch 65/100: Training Loss: 0.00019273400354157587
Epoch 66/100: Training Loss: 0.00030992443489420945
Epoch 67/100: Training Loss: 0.0008281159932446328
Epoch 68/100: Training Loss: 0.0008482433808077672
Epoch 69/100: Training Loss: 0.0006229646361557541
Epoch 70/100: Training Loss: 0.0008203790635819648
Epoch 71/100: Training Loss: 0.0007052650307394137
Epoch 72/100: Training Loss: 0.0006430579029071103
Epoch 73/100: Training Loss: 0.0002851266010551696
Epoch 74/100: Training Loss: 0.0007811956060160497
Epoch 75/100: Training Loss: 0.0006052220987666185
Epoch 76/100: Training Loss: 0.0010222480365425159
Epoch 77/100: Training Loss: 0.000850213276352852
Epoch 78/100: Training Loss: 0.0008113622475581564
Epoch 79/100: Training Loss: 0.000742522964052334
Epoch 80/100: Training Loss: 0.0002849972836530892
Epoch 81/100: Training Loss: 0.0006975139592103897
Epoch 82/100: Training Loss: 0.0009371242515600411
Epoch 83/100: Training Loss: 0.0006903959022965401
Epoch 84/100: Training Loss: 0.000981802393676369
Epoch 85/100: Training Loss: 0.0010184837374717566
Epoch 86/100: Training Loss: 0.0003945056325311114
Epoch 87/100: Training Loss: 0.0007697085666049058
Epoch 88/100: Training Loss: 0.0008749462616671422
Epoch 89/100: Training Loss: 0.0009580385533108074
Epoch 90/100: Training Loss: 0.0005442896845993722
Epoch 91/100: Training Loss: 0.0008220879515265203
Epoch 92/100: Training Loss: 0.0007171141588763826
Epoch 93/100: Training Loss: 0.0011053865502594384
Epoch 94/100: Training Loss: 0.00077584551967633
Epoch 95/100: Training Loss: 0.0007109541422242572
Epoch 96/100: Training Loss: 0.0008841416068897126
Epoch 97/100: Training Loss: 0.0009145532633848252
Epoch 98/100: Training Loss: 0.0011847402639449782
Epoch 99/100: Training Loss: 0.0006202390524232464
Epoch 0/100: Training Loss: 0.0026829854542056455
Epoch 1/100: Training Loss: 0.0020156441540118085
Epoch 2/100: Training Loss: 0.001834758859596505
Epoch 3/100: Training Loss: 0.0019593169752335706
Epoch 4/100: Training Loss: 0.0023030338697875574
Epoch 5/100: Training Loss: 0.0028390856768121782
Epoch 6/100: Training Loss: 0.0027615319419380846
Epoch 7/100: Training Loss: 0.0019642560687286176
Epoch 8/100: Training Loss: 0.002820731196182453
Epoch 9/100: Training Loss: 0.0021567930843656427
Epoch 10/100: Training Loss: 0.002648943702116707
Epoch 11/100: Training Loss: 0.002696978137982602
Epoch 12/100: Training Loss: 0.0021129787362963947
Epoch 13/100: Training Loss: 0.0018744954210243479
Epoch 14/100: Training Loss: 0.0023160618267311956
Epoch 15/100: Training Loss: 0.0017715214893517905
Epoch 16/100: Training Loss: 0.0023821655488172116
Epoch 17/100: Training Loss: 0.0022155462906060627
Epoch 18/100: Training Loss: 0.0019163455789452358
Epoch 19/100: Training Loss: 0.0016263246733621256
Epoch 20/100: Training Loss: 0.0018658286688343578
Epoch 21/100: Training Loss: 0.0019088657881250444
Epoch 22/100: Training Loss: 0.0012679542137297574
Epoch 23/100: Training Loss: 0.0013343745114787525
Epoch 24/100: Training Loss: 0.0007430487219861012
Epoch 25/100: Training Loss: 0.0014842026281041026
Epoch 26/100: Training Loss: 0.0014168458269131893
Epoch 27/100: Training Loss: 0.001699919140102058
Epoch 28/100: Training Loss: 0.0013883652671283443
Epoch 29/100: Training Loss: 0.0018063205362155738
Epoch 30/100: Training Loss: 0.001648457831894325
Epoch 31/100: Training Loss: 0.0008168152922036632
Epoch 32/100: Training Loss: 0.0009901775232214012
Epoch 33/100: Training Loss: 0.0012786052874381969
Epoch 34/100: Training Loss: 0.001274351647358067
Epoch 35/100: Training Loss: 0.0013761285519757807
Epoch 36/100: Training Loss: 0.001416479909656853
Epoch 37/100: Training Loss: 0.0015705075879760136
Epoch 38/100: Training Loss: 0.001521714377087473
Epoch 39/100: Training Loss: 0.0012328233939922408
Epoch 40/100: Training Loss: 0.001330211857296773
Epoch 41/100: Training Loss: 0.001525917590059192
Epoch 42/100: Training Loss: 0.0012845388114057629
Epoch 43/100: Training Loss: 0.0012616451015535568
Epoch 44/100: Training Loss: 0.0012933151019330056
Epoch 45/100: Training Loss: 0.0009883813905400157
Epoch 46/100: Training Loss: 0.0008971491791554634
Epoch 47/100: Training Loss: 0.0013737825565780235
Epoch 48/100: Training Loss: 0.0010116443728769061
Epoch 49/100: Training Loss: 0.0009168870993797353
Epoch 50/100: Training Loss: 0.0007845917778299344
Epoch 51/100: Training Loss: 0.0006340986352093173
Epoch 52/100: Training Loss: 0.0006377166075422274
Epoch 53/100: Training Loss: 0.0009631849085258332
Epoch 54/100: Training Loss: 0.0005624386549785437
Epoch 55/100: Training Loss: 0.00035401391765929217
Epoch 56/100: Training Loss: 0.0008145215495532712
Epoch 57/100: Training Loss: 0.0004913440800660494
Epoch 58/100: Training Loss: 0.0006170437134654317
Epoch 59/100: Training Loss: 0.0008906830620292006
Epoch 60/100: Training Loss: 0.0005849627962965049
Epoch 61/100: Training Loss: 0.0007591639330845006
Epoch 62/100: Training Loss: 0.0005461627876521736
Epoch 63/100: Training Loss: 0.0006633119669971087
Epoch 64/100: Training Loss: 0.0008809942480744116
Epoch 65/100: Training Loss: 0.000889393864877966
Epoch 66/100: Training Loss: 0.0008467831556370716
Epoch 67/100: Training Loss: 0.0006781962040244349
Epoch 68/100: Training Loss: 0.0009256384230607393
Epoch 69/100: Training Loss: 0.00029161498443969826
Epoch 70/100: Training Loss: 0.0005406789136248709
Epoch 71/100: Training Loss: 0.0007845758404952801
Epoch 72/100: Training Loss: 0.0004284133678240492
Epoch 73/100: Training Loss: 0.000715542362620499
Epoch 74/100: Training Loss: 0.001173747098998518
Epoch 75/100: Training Loss: 0.0006219922312048098
Epoch 76/100: Training Loss: 0.0010054168716961186
Epoch 77/100: Training Loss: 0.0006044990574287263
Epoch 78/100: Training Loss: 0.0007098044780705938
Epoch 79/100: Training Loss: 0.0005271832477178006
Epoch 80/100: Training Loss: 0.0007632798607775707
Epoch 81/100: Training Loss: 0.0004529929318964876
Epoch 82/100: Training Loss: 0.0005603256999262121
Epoch 83/100: Training Loss: 0.0003680175059283806
Epoch 84/100: Training Loss: 0.0007558132441628058
Epoch 85/100: Training Loss: 0.000597517764726222
Epoch 86/100: Training Loss: 0.000969491158889619
Epoch 87/100: Training Loss: 0.0002846253283371199
Epoch 88/100: Training Loss: 0.0007688940952945229
Epoch 89/100: Training Loss: 0.0015016621509135165
Epoch 90/100: Training Loss: 0.0009363461409183527
Epoch 91/100: Training Loss: 0.000703886743412902
Epoch 92/100: Training Loss: 0.0006169937304313609
Epoch 93/100: Training Loss: 0.0007082521915435791
Epoch 94/100: Training Loss: 0.0008544123528019482
Epoch 95/100: Training Loss: 0.0007663897133820894
Epoch 96/100: Training Loss: 0.0005934223631359883
Epoch 97/100: Training Loss: 0.0005675011517985767
Epoch 98/100: Training Loss: 0.0008581433667252395
Epoch 99/100: Training Loss: 0.0006256055654279444
Epoch 0/100: Training Loss: 0.002140558318586539
Epoch 1/100: Training Loss: 0.002129859087482983
Epoch 2/100: Training Loss: 0.00155157521860489
Epoch 3/100: Training Loss: 0.0022385702622647317
Epoch 4/100: Training Loss: 0.0021038452126332465
Epoch 5/100: Training Loss: 0.001487090690246481
Epoch 6/100: Training Loss: 0.002068255121344762
Epoch 7/100: Training Loss: 0.0018951640223825214
Epoch 8/100: Training Loss: 0.002402620205026589
Epoch 9/100: Training Loss: 0.002152414708737506
Epoch 10/100: Training Loss: 0.0016923388897977917
Epoch 11/100: Training Loss: 0.0023738771479650837
Epoch 12/100: Training Loss: 0.002402265735019911
Epoch 13/100: Training Loss: 0.002780345891485151
Epoch 14/100: Training Loss: 0.002228476551194854
Epoch 15/100: Training Loss: 0.0015827581187747171
Epoch 16/100: Training Loss: 0.001998134401460357
Epoch 17/100: Training Loss: 0.001404362798526587
Epoch 18/100: Training Loss: 0.002476997920219472
Epoch 19/100: Training Loss: 0.0016348189273417391
Epoch 20/100: Training Loss: 0.0017366663904379534
Epoch 21/100: Training Loss: 0.0016545262557781295
Epoch 22/100: Training Loss: 0.0012206145074983305
Epoch 23/100: Training Loss: 0.001671247332301361
Epoch 24/100: Training Loss: 0.0019316199599512366
Epoch 25/100: Training Loss: 0.0015581927157395723
Epoch 26/100: Training Loss: 0.0011835432802604524
Epoch 27/100: Training Loss: 0.0012038302737356022
Epoch 28/100: Training Loss: 0.000966497604420643
Epoch 29/100: Training Loss: 0.0014877834462172148
Epoch 30/100: Training Loss: 0.001128587501727982
Epoch 31/100: Training Loss: 0.0016067592513482301
Epoch 32/100: Training Loss: 0.0010855286721362183
Epoch 33/100: Training Loss: 0.0015322769319774299
Epoch 34/100: Training Loss: 0.001358895507079876
Epoch 35/100: Training Loss: 0.001470906844991722
Epoch 36/100: Training Loss: 0.0013698990771312588
Epoch 37/100: Training Loss: 0.0014411410353831109
Epoch 38/100: Training Loss: 0.0015040968624961298
Epoch 39/100: Training Loss: 0.0012262420149038958
Epoch 40/100: Training Loss: 0.0014028584720283154
Epoch 41/100: Training Loss: 0.001242151718265963
Epoch 42/100: Training Loss: 0.0014514025078704025
Epoch 43/100: Training Loss: 0.0012696461369659728
Epoch 44/100: Training Loss: 0.0013033989446842118
Epoch 45/100: Training Loss: 0.0011306545197568981
Epoch 46/100: Training Loss: 0.0010277934816499419
Epoch 47/100: Training Loss: 0.0012256607709341491
Epoch 48/100: Training Loss: 0.0009858943768684438
Epoch 49/100: Training Loss: 0.0008646218192498416
Epoch 50/100: Training Loss: 0.0008040359675489514
Epoch 51/100: Training Loss: 0.0012063033730778474
Epoch 52/100: Training Loss: 0.0008841336562933511
Epoch 53/100: Training Loss: 0.0008900514896342296
Epoch 54/100: Training Loss: 0.0008123044343973627
Epoch 55/100: Training Loss: 0.0009280902068346541
Epoch 56/100: Training Loss: 0.0002130078805598202
Epoch 57/100: Training Loss: 0.0008491746439839041
Epoch 58/100: Training Loss: 0.000586724044471387
Epoch 59/100: Training Loss: 0.00040200249051416156
Epoch 60/100: Training Loss: 0.0008456763250148849
Epoch 61/100: Training Loss: 0.0006456831038392933
Epoch 62/100: Training Loss: 0.00045006426162277625
Epoch 63/100: Training Loss: 0.0007210786374199469
Epoch 64/100: Training Loss: 0.0006275830284649173
Epoch 65/100: Training Loss: 0.0008007956064300032
Epoch 66/100: Training Loss: 0.00070974812997098
Epoch 67/100: Training Loss: 0.0004471429432464751
Epoch 68/100: Training Loss: 0.0007553623606827085
Epoch 69/100: Training Loss: 0.0014970819681685492
Epoch 70/100: Training Loss: 0.0007165625494047505
Epoch 71/100: Training Loss: 0.0006494564035080916
Epoch 72/100: Training Loss: 0.0006161446109512784
Epoch 73/100: Training Loss: 0.0003370749239889991
Epoch 74/100: Training Loss: 0.0007356302627664528
Epoch 75/100: Training Loss: 0.0007403897035200864
Epoch 76/100: Training Loss: 0.0007615955361467324
Epoch 77/100: Training Loss: 0.0005410237620208437
Epoch 78/100: Training Loss: 0.0006639982592191128
Epoch 79/100: Training Loss: 0.000866378281290168
Epoch 80/100: Training Loss: 0.0007418070407892695
Epoch 81/100: Training Loss: 0.00038742806935152473
Epoch 82/100: Training Loss: 0.0009999323562281022
Epoch 83/100: Training Loss: 0.0007135879914492171
Epoch 84/100: Training Loss: 0.0004711377600960384
Epoch 85/100: Training Loss: 0.0005945768083957647
Epoch 86/100: Training Loss: 0.0008166220211824834
Epoch 87/100: Training Loss: 0.0004243046933452025
Epoch 88/100: Training Loss: 0.000492720611837526
Epoch 89/100: Training Loss: 0.0006543209418555759
Epoch 90/100: Training Loss: 0.0005393273980412262
Epoch 91/100: Training Loss: 0.0005576854806072665
Epoch 92/100: Training Loss: 0.0006726313111008398
Epoch 93/100: Training Loss: 0.00021509315497827847
Epoch 94/100: Training Loss: 0.0010767648156905017
Epoch 95/100: Training Loss: 0.0007123732507623584
Epoch 96/100: Training Loss: 0.0005001005352727625
Epoch 97/100: Training Loss: 0.0005020301863057723
Epoch 98/100: Training Loss: 0.0008358246838020173
Epoch 99/100: Training Loss: 0.000577838560998045
Epoch 0/100: Training Loss: 0.002646343597513161
Epoch 1/100: Training Loss: 0.002121626343948162
Epoch 2/100: Training Loss: 0.0019419045243042193
Epoch 3/100: Training Loss: 0.0018583480885486729
Epoch 4/100: Training Loss: 0.002341937545119532
Epoch 5/100: Training Loss: 0.0015785628991411222
Epoch 6/100: Training Loss: 0.001957752649357777
Epoch 7/100: Training Loss: 0.0011647532120445706
Epoch 8/100: Training Loss: 0.0016156398500038298
Epoch 9/100: Training Loss: 0.001926014952312242
Epoch 10/100: Training Loss: 0.0018368823244082218
Epoch 11/100: Training Loss: 0.00290899146471592
Epoch 12/100: Training Loss: 0.0018801014154952093
Epoch 13/100: Training Loss: 0.002102856801835117
Epoch 14/100: Training Loss: 0.0023476112362564795
Epoch 15/100: Training Loss: 0.0022148201797182196
Epoch 16/100: Training Loss: 0.001958296788449319
Epoch 17/100: Training Loss: 0.001894812710237819
Epoch 18/100: Training Loss: 0.0016897285221428272
Epoch 19/100: Training Loss: 0.0016985507990350786
Epoch 20/100: Training Loss: 0.0018161701050815203
Epoch 21/100: Training Loss: 0.0018742360816096629
Epoch 22/100: Training Loss: 0.0020062574092915516
Epoch 23/100: Training Loss: 0.0018930597021090275
Epoch 24/100: Training Loss: 0.0016896464177314809
Epoch 25/100: Training Loss: 0.0013129431877704646
Epoch 26/100: Training Loss: 0.0011574098013884184
Epoch 27/100: Training Loss: 0.0015786740164093623
Epoch 28/100: Training Loss: 0.001492556653275395
Epoch 29/100: Training Loss: 0.0013255545042997953
Epoch 30/100: Training Loss: 0.0012527364768729304
Epoch 31/100: Training Loss: 0.0013059894770186468
Epoch 32/100: Training Loss: 0.0011667414808904889
Epoch 33/100: Training Loss: 0.0014450863891879455
Epoch 34/100: Training Loss: 0.0013183713551388671
Epoch 35/100: Training Loss: 0.00098224152002903
Epoch 36/100: Training Loss: 0.0015434386911771156
Epoch 37/100: Training Loss: 0.0016877767660759932
Epoch 38/100: Training Loss: 0.0015770506779879134
Epoch 39/100: Training Loss: 0.0016781904839522001
Epoch 40/100: Training Loss: 0.0012735850763636709
Epoch 41/100: Training Loss: 0.000968781528093957
Epoch 42/100: Training Loss: 0.001432868226474484
Epoch 43/100: Training Loss: 0.0011421691700322738
Epoch 44/100: Training Loss: 0.0011143327154071127
Epoch 45/100: Training Loss: 0.0012655287783666952
Epoch 46/100: Training Loss: 0.0014225977738172013
Epoch 47/100: Training Loss: 0.0011240101807954296
Epoch 48/100: Training Loss: 0.001137851287197593
Epoch 49/100: Training Loss: 0.0014552166130369073
Epoch 50/100: Training Loss: 0.0007652082289291534
Epoch 51/100: Training Loss: 0.0011291596668445512
Epoch 52/100: Training Loss: 0.001022208704064224
Epoch 53/100: Training Loss: 0.0010632758108985345
Epoch 54/100: Training Loss: 0.0007139673296189466
Epoch 55/100: Training Loss: 0.0010377470625946854
Epoch 56/100: Training Loss: 0.0008467753596653212
Epoch 57/100: Training Loss: 0.0007619754170739888
Epoch 58/100: Training Loss: 0.0007458485613595571
Epoch 59/100: Training Loss: 0.000820933094877281
Epoch 60/100: Training Loss: 0.0008667016660930306
Epoch 61/100: Training Loss: 0.0010080942452348621
Epoch 62/100: Training Loss: 0.0009281100421551838
Epoch 63/100: Training Loss: 0.0007975239627408666
Epoch 64/100: Training Loss: 0.00078517741320149
Epoch 65/100: Training Loss: 0.00040406146586336047
Epoch 66/100: Training Loss: 0.0005409431871988916
Epoch 67/100: Training Loss: 0.0009272899848735885
Epoch 68/100: Training Loss: 0.0010377051222403319
Epoch 69/100: Training Loss: 0.0003695334523718878
Epoch 70/100: Training Loss: 0.0009576075321791188
Epoch 71/100: Training Loss: 0.0006309948022791881
Epoch 72/100: Training Loss: 0.0011681980447263906
Epoch 73/100: Training Loss: 0.0008552928041938125
Epoch 74/100: Training Loss: 0.0008153586790261679
Epoch 75/100: Training Loss: 0.0010502935442703448
Epoch 76/100: Training Loss: 0.0012461933868610307
Epoch 77/100: Training Loss: 0.0008462375362977287
Epoch 78/100: Training Loss: 0.0007594713312111153
Epoch 79/100: Training Loss: 0.0007402738001172906
Epoch 80/100: Training Loss: 0.0007947307351409205
Epoch 81/100: Training Loss: 0.000842063237499717
Epoch 82/100: Training Loss: 0.0007950730177740387
Epoch 83/100: Training Loss: 0.0007120643230463495
Epoch 84/100: Training Loss: 0.0007343434340116993
Epoch 85/100: Training Loss: 0.0007446189195115045
Epoch 86/100: Training Loss: 0.0017089756908795692
Epoch 87/100: Training Loss: 0.000927710079199431
Epoch 88/100: Training Loss: 0.0006713225746786358
Epoch 89/100: Training Loss: 0.0007031107481741747
Epoch 90/100: Training Loss: 0.0007573055806538916
Epoch 91/100: Training Loss: 0.0009460010078569122
Epoch 92/100: Training Loss: 0.0007338573699755385
Epoch 93/100: Training Loss: 0.0007840892337015922
Epoch 94/100: Training Loss: 0.000606067774706329
Epoch 95/100: Training Loss: 0.0007271036407015971
Epoch 96/100: Training Loss: 0.0006978648979932267
Epoch 97/100: Training Loss: 0.000798857764692496
Epoch 98/100: Training Loss: 0.0008570904171229988
Epoch 99/100: Training Loss: 0.000785524778018724
Epoch 0/100: Training Loss: 0.0016506110920625574
Epoch 1/100: Training Loss: 0.0006052698720903957
Epoch 2/100: Training Loss: 7.5819600811776e-05
Epoch 3/100: Training Loss: 0.00034188595326507793
Epoch 4/100: Training Loss: 0.0005117158679401173
Epoch 5/100: Training Loss: 0.0002730067819356918
Epoch 6/100: Training Loss: 0.0007456520024467917
Epoch 7/100: Training Loss: 8.081958136137794e-05
Epoch 8/100: Training Loss: 0.0005707172786488253
Epoch 9/100: Training Loss: 0.0005286100594436421
Epoch 10/100: Training Loss: 0.0009131236111416536
Epoch 11/100: Training Loss: 9.865560294950709e-05
Epoch 12/100: Training Loss: 0.0005188165780375985
Epoch 13/100: Training Loss: 0.0011397686951300676
Epoch 14/100: Training Loss: 0.0008679368040140937
Epoch 15/100: Training Loss: 5.3192543632843916e-05
Epoch 16/100: Training Loss: 0.0009641105637830847
Epoch 17/100: Training Loss: 0.0010791995069559883
Epoch 18/100: Training Loss: 0.0005152690498267903
Epoch 19/100: Training Loss: 0.0008301088038612814
Epoch 20/100: Training Loss: 0.0007393730913891512
Epoch 21/100: Training Loss: 0.0008659161189023186
Epoch 22/100: Training Loss: 0.0009202823919408461
Epoch 23/100: Training Loss: 0.0005017305559971753
Epoch 24/100: Training Loss: 0.0008304936920895296
Epoch 25/100: Training Loss: 0.0012827799600713392
Epoch 26/100: Training Loss: 0.0008153425420031828
Epoch 27/100: Training Loss: 0.0003909122856224284
Epoch 28/100: Training Loss: 5.4397286080262244e-05
Epoch 29/100: Training Loss: 0.0008195765754755805
Epoch 30/100: Training Loss: 0.0008350869312005885
Epoch 31/100: Training Loss: 1.755953417159617e-06
Epoch 32/100: Training Loss: 0.0007717396406566395
Epoch 33/100: Training Loss: 0.0008070150718969458
Epoch 34/100: Training Loss: 0.0010691373663790087
Epoch 35/100: Training Loss: 0.0007498369497411392
Epoch 36/100: Training Loss: 1.3635215616565856e-06
Epoch 37/100: Training Loss: 0.00011352775070597144
Epoch 38/100: Training Loss: 0.000808956693200504
Epoch 39/100: Training Loss: 0.0008182978805373696
Epoch 40/100: Training Loss: 0.0007419343380367055
Epoch 41/100: Training Loss: 0.0007202066481113434
Epoch 42/100: Training Loss: 0.0007781969273791593
Epoch 43/100: Training Loss: 0.0001960174783187754
Epoch 44/100: Training Loss: 0.0005476103109471938
Epoch 45/100: Training Loss: 0.000715742347871556
Epoch 46/100: Training Loss: 0.0007065739701775943
Epoch 47/100: Training Loss: 5.483272252604365e-06
Epoch 48/100: Training Loss: 0.00029862906564684475
Epoch 49/100: Training Loss: 6.687217665945782e-05
Epoch 50/100: Training Loss: 0.00015873140929376377
Epoch 51/100: Training Loss: 0.0007919841829468222
Epoch 52/100: Training Loss: 0.0006625708411721622
Epoch 53/100: Training Loss: 2.0911374731975444e-05
Epoch 54/100: Training Loss: 4.935077775050612e-05
Epoch 55/100: Training Loss: 0.0003873489797115326
Epoch 56/100: Training Loss: 0.0005961310775840984
Epoch 57/100: Training Loss: 0.00011861497426734251
Epoch 58/100: Training Loss: 6.18419171694447e-05
Epoch 59/100: Training Loss: 3.8144022555035706e-05
Epoch 60/100: Training Loss: 0.0003093269817969378
Epoch 61/100: Training Loss: 0.00034904243314967437
Epoch 62/100: Training Loss: 3.939272342797588e-05
Epoch 63/100: Training Loss: 0.0005998341476216036
Epoch 64/100: Training Loss: 8.103724788216983e-05
Epoch 65/100: Training Loss: 8.734169361345908e-05
Epoch 66/100: Training Loss: 0.0006156274501015158
Epoch 67/100: Training Loss: 0.0001286383389550097
Epoch 68/100: Training Loss: 3.0585422235376694e-05
Epoch 69/100: Training Loss: 0.0010308324414141038
Epoch 70/100: Training Loss: 0.0006199289770687327
Epoch 71/100: Training Loss: 2.1139784332583933e-05
Epoch 72/100: Training Loss: 0.0007176606532405405
Epoch 73/100: Training Loss: 0.00017848493640913683
Epoch 74/100: Training Loss: 1.7102833782487057e-05
Epoch 75/100: Training Loss: 4.306333892814377e-06
Epoch 76/100: Training Loss: 0.00011918903054559932
Epoch 77/100: Training Loss: 0.00033743609400356517
Epoch 78/100: Training Loss: 0.0008079013403724222
Epoch 79/100: Training Loss: 0.0006460954161251292
Epoch 80/100: Training Loss: 0.0007744605050367467
Epoch 81/100: Training Loss: 0.000877333476262934
Epoch 82/100: Training Loss: 0.00011133907691520803
Epoch 83/100: Training Loss: 0.0007728470598950105
Epoch 84/100: Training Loss: 0.0007547619588234845
Epoch 85/100: Training Loss: 0.0007374592563685249
Epoch 86/100: Training Loss: 0.0008272682042682872
Epoch 87/100: Training Loss: 0.0005673701272291296
Epoch 88/100: Training Loss: 0.0008697438765974606
Epoch 89/100: Training Loss: 0.000522035316509359
Epoch 90/100: Training Loss: 3.288467483156744e-06
Epoch 91/100: Training Loss: 0.0006998139269211713
Epoch 92/100: Training Loss: 0.0008131483021904441
Epoch 93/100: Training Loss: 0.0009802179301486296
Epoch 94/100: Training Loss: 0.0008022723829045015
Epoch 95/100: Training Loss: 0.0007600618635906892
Epoch 96/100: Training Loss: 0.0008910192286267
Epoch 97/100: Training Loss: 0.0008134046898168676
Epoch 98/100: Training Loss: 1.6577595242244357e-05
Epoch 99/100: Training Loss: 0.0002675661488490946
Epoch 0/100: Training Loss: 0.001418029473108404
Epoch 1/100: Training Loss: 0.0005936417071258321
Epoch 2/100: Training Loss: 0.000596155971288681
