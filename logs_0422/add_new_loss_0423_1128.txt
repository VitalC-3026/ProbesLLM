2024-04-23 15:29:15.885373: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-23 15:29:19.768375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Epoch 0/100: Training Loss: 0.004437249440413255
Epoch 1/100: Training Loss: 0.0050057660449634896
Epoch 2/100: Training Loss: 0.004884290945279849
Epoch 3/100: Training Loss: 0.0038451239779278947
Epoch 4/100: Training Loss: 0.0027204001700127877
Epoch 5/100: Training Loss: 0.0044945861909772965
Epoch 6/100: Training Loss: 0.004956137467097569
Epoch 7/100: Training Loss: 0.003114065298667321
Epoch 8/100: Training Loss: 0.0021261443624963293
Epoch 9/100: Training Loss: 0.0034564033254876835
Epoch 10/100: Training Loss: 0.0028874807424478597
Epoch 11/100: Training Loss: 0.0023280986539133777
Epoch 12/100: Training Loss: 0.0033332092778666036
Epoch 13/100: Training Loss: 0.003777176766962438
Epoch 14/100: Training Loss: 0.003823875130473317
Epoch 15/100: Training Loss: 0.0036424160837293506
Epoch 16/100: Training Loss: 0.003654141526122193
Epoch 17/100: Training Loss: 0.0019799320847838074
Epoch 18/100: Training Loss: 0.004107643674303602
Epoch 19/100: Training Loss: 0.002886717552905316
Epoch 20/100: Training Loss: 0.003571660368592589
Epoch 21/100: Training Loss: 0.0032717573059188737
Epoch 22/100: Training Loss: 0.0018731989226974807
Epoch 23/100: Training Loss: 0.0022351522962530176
Epoch 24/100: Training Loss: 0.0022142800417813387
Epoch 25/100: Training Loss: 0.0018995289619152362
Epoch 26/100: Training Loss: 0.0024368898435072465
Epoch 27/100: Training Loss: 0.0020128828245443062
Epoch 28/100: Training Loss: 0.0016705716823364471
Epoch 29/100: Training Loss: 0.002249831503087824
Epoch 30/100: Training Loss: 0.0023764027998997616
Epoch 31/100: Training Loss: 0.001977191521571233
Epoch 32/100: Training Loss: 0.0020068450407548385
Epoch 33/100: Training Loss: 0.0021054463369863017
Epoch 34/100: Training Loss: 0.0028628238014407927
Epoch 35/100: Training Loss: 0.0013932866024804283
Epoch 36/100: Training Loss: 0.0012899836251785706
Epoch 37/100: Training Loss: 0.0003351668169448426
Epoch 38/100: Training Loss: 0.0014106990782530992
Epoch 39/100: Training Loss: 0.0017390378288455776
Epoch 40/100: Training Loss: 0.0019035112190913487
Epoch 41/100: Training Loss: 0.0009796142161309302
Epoch 42/100: Training Loss: 0.0016491796586896989
Epoch 43/100: Training Loss: 0.0008696256192414077
Epoch 44/100: Training Loss: 0.0008196329007615576
Epoch 45/100: Training Loss: 0.0017548745328729804
Epoch 46/100: Training Loss: 0.001060529918103785
Epoch 47/100: Training Loss: 0.0015829902637254942
Epoch 48/100: Training Loss: 0.0003538339340186619
Epoch 49/100: Training Loss: 0.001703235757100832
Epoch 50/100: Training Loss: 0.0004974278536709872
Epoch 51/100: Training Loss: 0.001405881835030509
Epoch 52/100: Training Loss: 0.0024385846161342167
Epoch 53/100: Training Loss: 0.0012926150868822644
Epoch 54/100: Training Loss: 0.0017539831725033846
Epoch 55/100: Training Loss: 0.0014855555304280528
Epoch 56/100: Training Loss: 0.001582731733788977
Epoch 57/100: Training Loss: 0.0013906290897956262
Epoch 58/100: Training Loss: 0.0013155637087521853
Epoch 59/100: Training Loss: 0.0008227105636696715
Epoch 60/100: Training Loss: 0.0017221761750174569
Epoch 61/100: Training Loss: 0.0016244026747616854
Epoch 62/100: Training Loss: 0.0013866707995221332
Epoch 63/100: Training Loss: 0.0019269914893837242
Epoch 64/100: Training Loss: 0.001687340386263974
Epoch 65/100: Training Loss: 0.0014762343851836412
Epoch 66/100: Training Loss: 0.0014199131018631942
Epoch 67/100: Training Loss: 0.0008293522613031881
Epoch 68/100: Training Loss: 0.0018963990928409816
Epoch 69/100: Training Loss: 0.00018339226400101936
Epoch 70/100: Training Loss: 0.0018855370841659865
Epoch 71/100: Training Loss: 0.0010693623469426082
Epoch 72/100: Training Loss: 0.001356900571943163
Epoch 73/100: Training Loss: 0.001351058170512006
Epoch 74/100: Training Loss: 0.0006587246914843579
Epoch 75/100: Training Loss: 0.0014797987846227793
Epoch 76/100: Training Loss: 0.0016137415712529962
Epoch 77/100: Training Loss: 0.0015288126635384727
Epoch 78/100: Training Loss: 0.0007880998032910007
Epoch 79/100: Training Loss: 0.0011981323465600714
Epoch 80/100: Training Loss: 0.0015266527245928357
Epoch 81/100: Training Loss: 0.0007952420965774909
Epoch 82/100: Training Loss: 0.0012433627893874695
Epoch 83/100: Training Loss: 0.0012104705080285773
Epoch 84/100: Training Loss: 0.0013238680321019847
Epoch 85/100: Training Loss: 0.0012182870528081081
Epoch 86/100: Training Loss: 0.0009251541191047721
Epoch 87/100: Training Loss: 0.001270916286881987
Epoch 88/100: Training Loss: 0.0008657549123664002
Epoch 89/100: Training Loss: 0.001409136123590536
Epoch 90/100: Training Loss: 0.000665379049894693
Epoch 91/100: Training Loss: 0.0010963180265226565
Epoch 92/100: Training Loss: 0.001390511756176715
Epoch 93/100: Training Loss: 0.0011272203255366612
Epoch 94/100: Training Loss: 0.0009358330414845393
Epoch 95/100: Training Loss: 0.0010258385559895656
Epoch 96/100: Training Loss: 0.001271162520755421
Epoch 97/100: Training Loss: 0.000792059135603738
Epoch 98/100: Training Loss: 0.0008714867013317722
Epoch 99/100: Training Loss: 0.001377993321918941
Epoch 0/100: Training Loss: 0.004751999061424416
Epoch 1/100: Training Loss: 0.003165071869229937
Epoch 2/100: Training Loss: 0.0035773103053753194
Epoch 3/100: Training Loss: 0.0043506726518377555
Epoch 4/100: Training Loss: 0.004316753023987883
Epoch 5/100: Training Loss: 0.002993872949293443
Epoch 6/100: Training Loss: 0.004268673750070425
Epoch 7/100: Training Loss: 0.002304138628752915
Epoch 8/100: Training Loss: 0.0031840963797135787
Epoch 9/100: Training Loss: 0.0019071081301549099
Epoch 10/100: Training Loss: 0.0026790591386648323
Epoch 11/100: Training Loss: 0.0029682369082124085
Epoch 12/100: Training Loss: 0.0032770125182358537
Epoch 13/100: Training Loss: 0.0032384808246905985
Epoch 14/100: Training Loss: 0.0036812220420037118
Epoch 15/100: Training Loss: 0.0024605549715615654
Epoch 16/100: Training Loss: 0.0022013266603429834
Epoch 17/100: Training Loss: 0.0033721515348741223
Epoch 18/100: Training Loss: 0.0028062073084024284
Epoch 19/100: Training Loss: 0.0010939155008409408
Epoch 20/100: Training Loss: 0.002658004110509699
Epoch 21/100: Training Loss: 0.002309523679159738
Epoch 22/100: Training Loss: 0.0016324196036879
Epoch 23/100: Training Loss: 0.0009248699550028447
Epoch 24/100: Training Loss: 0.0018582014770774575
Epoch 25/100: Training Loss: 0.0028098955021037923
Epoch 26/100: Training Loss: 0.0023827165156811267
Epoch 27/100: Training Loss: 0.0028240726544306828
Epoch 28/100: Training Loss: 0.002176382741728029
Epoch 29/100: Training Loss: 0.0008631791476603154
Epoch 30/100: Training Loss: 0.0011635164280871411
Epoch 31/100: Training Loss: 0.0006071686536282092
Epoch 32/100: Training Loss: 0.0018966539756401436
Epoch 33/100: Training Loss: 0.0023846838857744124
Epoch 34/100: Training Loss: 0.0016968812975850138
Epoch 35/100: Training Loss: 0.00192240359899881
Epoch 36/100: Training Loss: 0.002145143030406712
Epoch 37/100: Training Loss: 0.001216780472468663
Epoch 38/100: Training Loss: 0.0025622567513605933
Epoch 39/100: Training Loss: 0.0023122054713589327
Epoch 40/100: Training Loss: 0.0016903404172483858
Epoch 41/100: Training Loss: 0.0005730963670290434
Epoch 42/100: Training Loss: 0.0018265639151726569
Epoch 43/100: Training Loss: 0.0016069813416554378
Epoch 44/100: Training Loss: 0.003414228245928571
Epoch 45/100: Training Loss: 0.0016941182263247618
Epoch 46/100: Training Loss: 0.0023545933353317366
Epoch 47/100: Training Loss: 0.0012312520008820754
Epoch 48/100: Training Loss: 0.0015999753992040674
Epoch 49/100: Training Loss: 0.0020075627973863293
Epoch 50/100: Training Loss: 0.001090206883170388
Epoch 51/100: Training Loss: 0.002191317248177695
Epoch 52/100: Training Loss: 0.0017755652641082977
Epoch 53/100: Training Loss: 0.0018678236674595546
Epoch 54/100: Training Loss: 0.0019342688830582412
Epoch 55/100: Training Loss: 0.0019858446154561076
Epoch 56/100: Training Loss: 0.0019543587744652808
Epoch 57/100: Training Loss: 0.002094471162849373
Epoch 58/100: Training Loss: 0.0015854295733925346
Epoch 59/100: Training Loss: 0.00145886327836897
Epoch 60/100: Training Loss: 0.0012620627046465041
Epoch 61/100: Training Loss: 0.0011768830822897957
Epoch 62/100: Training Loss: 0.0014553728637161788
Epoch 63/100: Training Loss: 0.0011387936301998326
Epoch 64/100: Training Loss: 0.0018474511750094541
Epoch 65/100: Training Loss: 0.0013722445998158488
Epoch 66/100: Training Loss: 0.0014047120417748297
Epoch 67/100: Training Loss: 0.000977413012431218
Epoch 68/100: Training Loss: 0.0018998294860332996
Epoch 69/100: Training Loss: 0.001752457418641844
Epoch 70/100: Training Loss: 0.0007507339953542589
Epoch 71/100: Training Loss: 0.0011318236381023914
Epoch 72/100: Training Loss: 0.000852651946194522
Epoch 73/100: Training Loss: 0.0016456799698876335
Epoch 74/100: Training Loss: 0.0006322063036731907
Epoch 75/100: Training Loss: 0.001587414032929427
Epoch 76/100: Training Loss: 0.001281645748165104
Epoch 77/100: Training Loss: 0.0010272431206869912
Epoch 78/100: Training Loss: 0.0015141934781641394
Epoch 79/100: Training Loss: 0.0017593530091372404
Epoch 80/100: Training Loss: 0.0013799407890626601
Epoch 81/100: Training Loss: 0.0017225786105736153
Epoch 82/100: Training Loss: 0.0010092156333523197
Epoch 83/100: Training Loss: 0.0010445907816186652
Epoch 84/100: Training Loss: 0.0012056027259026373
Epoch 85/100: Training Loss: 0.0014978507598796924
Epoch 86/100: Training Loss: 0.0009567287418392155
Epoch 87/100: Training Loss: 0.0008188390231632686
Epoch 88/100: Training Loss: 0.0008838268426748422
Epoch 89/100: Training Loss: 0.0005103008938836051
Epoch 90/100: Training Loss: 0.0007997373496735846
Epoch 91/100: Training Loss: 0.0008087866789811141
Epoch 92/100: Training Loss: 0.0007104017621987349
Epoch 93/100: Training Loss: 0.0008432311819983529
Epoch 94/100: Training Loss: 0.000664146421672581
Epoch 95/100: Training Loss: 0.001071146630740666
Epoch 96/100: Training Loss: 0.0007577312367779391
Epoch 97/100: Training Loss: 0.0012243375494763568
Epoch 98/100: Training Loss: 0.0007667775962736223
Epoch 99/100: Training Loss: 0.0008038959198898368
Epoch 0/100: Training Loss: 0.003797922934685554
Epoch 1/100: Training Loss: 0.004237527613873249
Epoch 2/100: Training Loss: 0.005616846201303122
Epoch 3/100: Training Loss: 0.004446969165668621
Epoch 4/100: Training Loss: 0.004929897251662674
Epoch 5/100: Training Loss: 0.004973368628041728
Epoch 6/100: Training Loss: 0.005539824912598083
Epoch 7/100: Training Loss: 0.0035697300950964014
Epoch 8/100: Training Loss: 0.0033545068927578157
Epoch 9/100: Training Loss: 0.0027084677786260217
Epoch 10/100: Training Loss: 0.0027871025608969735
Epoch 11/100: Training Loss: 0.004254324452860372
Epoch 12/100: Training Loss: 0.004207127577775008
Epoch 13/100: Training Loss: 0.003426328614041522
Epoch 14/100: Training Loss: 0.0032898114694582
Epoch 15/100: Training Loss: 0.0035338260077096366
Epoch 16/100: Training Loss: 0.0024572525407884505
Epoch 17/100: Training Loss: 0.002110081952768606
Epoch 18/100: Training Loss: 0.0038293704286321895
Epoch 19/100: Training Loss: 0.0030027159027286345
Epoch 20/100: Training Loss: 0.0030356278786292444
Epoch 21/100: Training Loss: 0.0023078136927598006
Epoch 22/100: Training Loss: 0.0021571708725882576
Epoch 23/100: Training Loss: 0.001714054312739339
Epoch 24/100: Training Loss: 0.0013522278595637608
Epoch 25/100: Training Loss: 0.0011102217477518361
Epoch 26/100: Training Loss: 0.0020088255405426025
Epoch 27/100: Training Loss: 0.0030753162357357
Epoch 28/100: Training Loss: 0.002419989217411388
Epoch 29/100: Training Loss: 0.001639483066705557
Epoch 30/100: Training Loss: 0.002605915486395776
Epoch 31/100: Training Loss: 0.0016074420272053538
Epoch 32/100: Training Loss: 0.0015143998019345156
Epoch 33/100: Training Loss: 0.0017065765349181382
Epoch 34/100: Training Loss: 0.0014248348616219902
Epoch 35/100: Training Loss: 0.0020264901898124003
Epoch 36/100: Training Loss: 0.0019070818707659528
Epoch 37/100: Training Loss: 0.0016017574947197121
Epoch 38/100: Training Loss: 0.0021410832455108215
Epoch 39/100: Training Loss: 0.0018516387139166986
Epoch 40/100: Training Loss: 0.0017925084054053247
Epoch 41/100: Training Loss: 0.0016517788171768188
Epoch 42/100: Training Loss: 0.0017938751440781814
Epoch 43/100: Training Loss: 0.0015868869694796476
Epoch 44/100: Training Loss: 0.0018469899684399158
Epoch 45/100: Training Loss: 0.0006897129066340573
Epoch 46/100: Training Loss: 0.00194964354688471
Epoch 47/100: Training Loss: 0.001683383763253272
Epoch 48/100: Training Loss: 0.002318231792716713
Epoch 49/100: Training Loss: 0.001397470390046393
Epoch 50/100: Training Loss: 0.0021039645571808716
Epoch 51/100: Training Loss: 0.0015688242612185179
Epoch 52/100: Training Loss: 0.0011299905868676992
Epoch 53/100: Training Loss: 0.001950364638041783
Epoch 54/100: Training Loss: 0.001320358443927098
Epoch 55/100: Training Loss: 0.0016516912858802956
Epoch 56/100: Training Loss: 0.0014957933575956972
Epoch 57/100: Training Loss: 0.0016916746442968195
Epoch 58/100: Training Loss: 0.001947923765315876
Epoch 59/100: Training Loss: 0.0011503663096394572
Epoch 60/100: Training Loss: 0.0016813636659742234
Epoch 61/100: Training Loss: 0.0016184056347066705
Epoch 62/100: Training Loss: 0.0011176857706550118
Epoch 63/100: Training Loss: 0.0005120290117663937
Epoch 64/100: Training Loss: 0.0013985300397539471
Epoch 65/100: Training Loss: 0.0021509359349737634
Epoch 66/100: Training Loss: 0.0009473204821139783
Epoch 67/100: Training Loss: 0.0005813561953031099
Epoch 68/100: Training Loss: 0.000804212074596565
Epoch 69/100: Training Loss: 0.0013404526076950393
Epoch 70/100: Training Loss: 0.001180770826506448
Epoch 71/100: Training Loss: 0.001101765182468441
Epoch 72/100: Training Loss: 0.001256180080500516
Epoch 73/100: Training Loss: 0.0010466977849706903
Epoch 74/100: Training Loss: 0.00045929348968959356
Epoch 75/100: Training Loss: 0.001311366374676044
Epoch 76/100: Training Loss: 0.0011369767305734273
Epoch 77/100: Training Loss: 0.0010403790674009524
Epoch 78/100: Training Loss: 0.0009011294875111613
Epoch 79/100: Training Loss: 0.0010975010536767387
Epoch 80/100: Training Loss: 0.0006972124109735022
Epoch 81/100: Training Loss: 0.0009093656614943818
Epoch 82/100: Training Loss: 0.0012929017518783783
Epoch 83/100: Training Loss: 0.001218543915481834
Epoch 84/100: Training Loss: 0.0011971148994419124
Epoch 85/100: Training Loss: 0.0011908820459059068
Epoch 86/100: Training Loss: 0.0015695951618514695
Epoch 87/100: Training Loss: 0.00156475301389094
Epoch 88/100: Training Loss: 0.0013065538206300535
Epoch 89/100: Training Loss: 0.0006820698092867445
Epoch 90/100: Training Loss: 0.0010358474471352317
Epoch 91/100: Training Loss: 0.0007446652108972722
Epoch 92/100: Training Loss: 0.0012033994381244366
Epoch 93/100: Training Loss: 0.0007031226491594648
Epoch 94/100: Training Loss: 0.0009776940504154126
Epoch 95/100: Training Loss: 0.0009349064601884855
Epoch 96/100: Training Loss: 0.0011538212949579413
Epoch 97/100: Training Loss: 0.00100109773082333
Epoch 98/100: Training Loss: 0.0008103738610561078
Epoch 99/100: Training Loss: 0.0011529901644566677
Epoch 0/100: Training Loss: 0.004480325371209829
Epoch 1/100: Training Loss: 0.0031453539257400606
Epoch 2/100: Training Loss: 0.002346045948976388
Epoch 3/100: Training Loss: 0.002297779350924346
Epoch 4/100: Training Loss: 0.0012335797394711547
Epoch 5/100: Training Loss: 0.0009865377761103624
Epoch 6/100: Training Loss: 0.0005980341529553653
Epoch 7/100: Training Loss: 0.0011197608307095394
Epoch 8/100: Training Loss: 0.0028867370511856546
Epoch 9/100: Training Loss: 0.0005472072977229861
Epoch 10/100: Training Loss: 0.001030188305246318
Epoch 11/100: Training Loss: 0.00052670046595708
Epoch 12/100: Training Loss: 0.00044711766067458077
Epoch 13/100: Training Loss: 0.0007502824250905792
Epoch 14/100: Training Loss: 0.0032480874675914553
Epoch 15/100: Training Loss: 0.001972714450461733
Epoch 16/100: Training Loss: 0.0021298856822990933
Epoch 17/100: Training Loss: 0.0006508926855274505
Epoch 18/100: Training Loss: 0.0007653762957801117
Epoch 19/100: Training Loss: 0.0005233707420665062
Epoch 20/100: Training Loss: 0.00049618837292209
Epoch 21/100: Training Loss: 0.0004278700227386381
Epoch 22/100: Training Loss: 0.000433668128551881
Epoch 23/100: Training Loss: 0.0007801747029544386
Epoch 24/100: Training Loss: 0.000748016305862029
Epoch 25/100: Training Loss: 0.0009385884905153989
Epoch 26/100: Training Loss: 0.00039257292001525316
Epoch 27/100: Training Loss: 0.00042463948755907865
Epoch 28/100: Training Loss: 0.0003800243139266968
Epoch 29/100: Training Loss: 0.0005907438284049005
Epoch 30/100: Training Loss: 0.0007064251537703298
Epoch 31/100: Training Loss: 0.000478889678884869
Epoch 32/100: Training Loss: 0.00035393699729369463
Epoch 33/100: Training Loss: 0.0007713026612814218
Epoch 34/100: Training Loss: 0.0004353767340899976
Epoch 35/100: Training Loss: 0.0004302751432898586
Epoch 36/100: Training Loss: 0.0003900072691630732
Epoch 37/100: Training Loss: 0.00028238134698633767
Epoch 38/100: Training Loss: 0.0010449738224591215
Epoch 39/100: Training Loss: 0.00048190560991778693
Epoch 40/100: Training Loss: 0.0004179144929523117
Epoch 41/100: Training Loss: 0.0004905804168958605
Epoch 42/100: Training Loss: 0.0011620186954919545
Epoch 43/100: Training Loss: 0.0004297200064717626
Epoch 44/100: Training Loss: 0.0002270737674338686
Epoch 45/100: Training Loss: 0.0003210901299868625
Epoch 46/100: Training Loss: 0.000338040452244823
Epoch 47/100: Training Loss: 0.0004550593396637337
Epoch 48/100: Training Loss: 0.00023321457710002828
Epoch 49/100: Training Loss: 8.908600940660465e-05
Epoch 50/100: Training Loss: 0.0003735930458899656
Epoch 51/100: Training Loss: 0.000285415195979955
Epoch 52/100: Training Loss: 0.00039086362884088526
Epoch 53/100: Training Loss: 0.0004479200379248777
Epoch 54/100: Training Loss: 0.00023492208562014293
Epoch 55/100: Training Loss: 0.00033221905765357926
Epoch 56/100: Training Loss: 0.0007308782792530176
Epoch 57/100: Training Loss: 0.0002681756266421336
Epoch 58/100: Training Loss: 0.00026652445456733004
Epoch 59/100: Training Loss: 9.745000604471547e-05
Epoch 60/100: Training Loss: 0.0003461987694348294
Epoch 61/100: Training Loss: 9.327814371490771e-05
Epoch 62/100: Training Loss: 0.00011715391205132373
Epoch 63/100: Training Loss: 3.296911053679472e-05
Epoch 64/100: Training Loss: 0.0002496908504538741
Epoch 65/100: Training Loss: 0.00021936365066130468
Epoch 66/100: Training Loss: 2.4934884937811484e-05
Epoch 67/100: Training Loss: 0.0004003382990696679
Epoch 68/100: Training Loss: 9.792749455735728e-05
Epoch 69/100: Training Loss: 1.0070091033457247e-05
Epoch 70/100: Training Loss: 4.463951586191457e-06
Epoch 71/100: Training Loss: 0.0003153542570906914
Epoch 72/100: Training Loss: 3.410451559841267e-05
Epoch 73/100: Training Loss: 7.63298769372921e-06
Epoch 74/100: Training Loss: 9.143298657531022e-06
Epoch 75/100: Training Loss: 0.0001316084726456484
Epoch 76/100: Training Loss: 6.034628608109761e-05
Epoch 77/100: Training Loss: 4.892113498566341e-05
Epoch 78/100: Training Loss: 0.0003018282993805189
Epoch 79/100: Training Loss: 0.00032959608761079474
Epoch 80/100: Training Loss: 9.152457186597988e-05
Epoch 81/100: Training Loss: 0.00010918935566592071
Epoch 82/100: Training Loss: 0.00013272151168138702
Epoch 83/100: Training Loss: 9.946970760456623e-05
Epoch 84/100: Training Loss: 4.881827954911381e-06
Epoch 85/100: Training Loss: 4.4109348344839425e-05
Epoch 86/100: Training Loss: 1.786915196871465e-05
Epoch 87/100: Training Loss: 4.4278957612492556e-05
Epoch 88/100: Training Loss: 0.00018080442778171938
Epoch 89/100: Training Loss: 7.11216882693987e-05
Epoch 90/100: Training Loss: 7.464621141781471e-06
Epoch 91/100: Training Loss: 0.00046054808640041235
Epoch 92/100: Training Loss: 8.552648024233572e-06
Epoch 93/100: Training Loss: 7.228955106546908e-06
Epoch 94/100: Training Loss: 9.47577181769295e-05
Epoch 95/100: Training Loss: 0.0005489438772201538
Epoch 96/100: Training Loss: 0.0004101593070234989
Epoch 97/100: Training Loss: 5.853109195988419e-06
Epoch 98/100: Training Loss: 9.836018388302413e-06
Epoch 99/100: Training Loss: 2.89200817269096e-06
Epoch 0/100: Training Loss: 0.004192911774102895
Epoch 1/100: Training Loss: 0.0028793936126802594
Epoch 2/100: Training Loss: 0.0029464673045222745
Epoch 3/100: Training Loss: 0.0026756729816366557
Epoch 4/100: Training Loss: 0.002133747551338804
Epoch 5/100: Training Loss: 0.0010353908217026412
Epoch 6/100: Training Loss: 0.00037042490360927
Epoch 7/100: Training Loss: 0.0010158923323169077
Epoch 8/100: Training Loss: 0.0008589651869849924
Epoch 9/100: Training Loss: 0.002223615631735398
Epoch 10/100: Training Loss: 0.00043902678723715564
Epoch 11/100: Training Loss: 0.0005776328177539849
Epoch 12/100: Training Loss: 0.0020597430825964806
Epoch 13/100: Training Loss: 0.0009343407453934839
Epoch 14/100: Training Loss: 0.002630246563191794
Epoch 15/100: Training Loss: 0.0020591580063287467
Epoch 16/100: Training Loss: 0.0015495542002601857
Epoch 17/100: Training Loss: 0.0008170772001055852
Epoch 18/100: Training Loss: 0.00059168831519554
Epoch 19/100: Training Loss: 0.0004450768415181915
Epoch 20/100: Training Loss: 0.00047551452016537905
Epoch 21/100: Training Loss: 0.00043079174735063426
Epoch 22/100: Training Loss: 0.0004061087051783603
Epoch 23/100: Training Loss: 0.0004070459242247365
Epoch 24/100: Training Loss: 0.0005004544016773715
Epoch 25/100: Training Loss: 0.0005398126650441644
Epoch 26/100: Training Loss: 0.0004972415559130944
Epoch 27/100: Training Loss: 0.00048333671561048077
Epoch 28/100: Training Loss: 0.0011338490101457373
Epoch 29/100: Training Loss: 0.0014549090635557116
Epoch 30/100: Training Loss: 0.0009225391171461234
Epoch 31/100: Training Loss: 0.0009138145329762091
Epoch 32/100: Training Loss: 0.0007591730246514631
Epoch 33/100: Training Loss: 0.0009248782337808901
Epoch 34/100: Training Loss: 0.0009702769525212013
Epoch 35/100: Training Loss: 0.0008067090087141727
Epoch 36/100: Training Loss: 0.0019384948022526465
Epoch 37/100: Training Loss: 0.00045894895411707873
Epoch 38/100: Training Loss: 0.0003784326322239601
Epoch 39/100: Training Loss: 0.0018545793243712444
Epoch 40/100: Training Loss: 0.0004410411865433301
Epoch 41/100: Training Loss: 0.0004231986458316171
Epoch 42/100: Training Loss: 0.0003949097511958491
Epoch 43/100: Training Loss: 0.00023268304902351707
Epoch 44/100: Training Loss: 0.0003823234122589322
Epoch 45/100: Training Loss: 0.00018796557846244858
Epoch 46/100: Training Loss: 0.00019335006277985367
Epoch 47/100: Training Loss: 0.00020397980154657656
Epoch 48/100: Training Loss: 0.00023526643500006272
Epoch 49/100: Training Loss: 0.00020406454618723113
Epoch 50/100: Training Loss: 0.00017566444135151026
Epoch 51/100: Training Loss: 0.0004106790193019469
Epoch 52/100: Training Loss: 8.949899097527463e-05
Epoch 53/100: Training Loss: 9.394829030051554e-05
Epoch 54/100: Training Loss: 0.00013308064794979212
Epoch 55/100: Training Loss: 9.709646913902891e-05
Epoch 56/100: Training Loss: 5.605019788983409e-05
Epoch 57/100: Training Loss: 6.648243913438423e-05
Epoch 58/100: Training Loss: 5.305273904025189e-05
Epoch 59/100: Training Loss: 0.0002544178553154132
Epoch 60/100: Training Loss: 0.0003797407804822629
Epoch 61/100: Training Loss: 0.00015174277538170845
Epoch 62/100: Training Loss: 0.0003541711649280384
Epoch 63/100: Training Loss: 0.00043141252241251656
Epoch 64/100: Training Loss: 3.998982005872609e-05
Epoch 65/100: Training Loss: 7.659761360817891e-05
Epoch 66/100: Training Loss: 3.981304017861196e-05
Epoch 67/100: Training Loss: 3.402794431323654e-05
Epoch 68/100: Training Loss: 4.237468862917525e-05
Epoch 69/100: Training Loss: 0.00034768904553600616
Epoch 70/100: Training Loss: 2.5503928744536968e-05
Epoch 71/100: Training Loss: 0.00016982176918193607
Epoch 72/100: Training Loss: 2.524821784781532e-05
Epoch 73/100: Training Loss: 6.448651201154557e-05
Epoch 74/100: Training Loss: 7.3750120547651516e-06
Epoch 75/100: Training Loss: 2.8510537981255654e-05
Epoch 76/100: Training Loss: 6.223455117158363e-05
Epoch 77/100: Training Loss: 0.000432621573377972
Epoch 78/100: Training Loss: 1.26969592040119e-05
Epoch 79/100: Training Loss: 1.945674270848555e-05
Epoch 80/100: Training Loss: 4.419666983507162e-05
Epoch 81/100: Training Loss: 0.00013975360276508917
Epoch 82/100: Training Loss: 6.403922577577134e-05
Epoch 83/100: Training Loss: 7.249091529041711e-05
Epoch 84/100: Training Loss: 5.896538895971936e-06
Epoch 85/100: Training Loss: 1.958820203239201e-05
Epoch 86/100: Training Loss: 1.4396682003101598e-06
Epoch 87/100: Training Loss: 1.3937562292704554e-05
Epoch 88/100: Training Loss: 6.290836019750022e-05
Epoch 89/100: Training Loss: 1.5218812183825516e-05
Epoch 90/100: Training Loss: 5.6657385926670825e-05
Epoch 91/100: Training Loss: 2.440194273653206e-05
Epoch 92/100: Training Loss: 2.175889783567446e-05
Epoch 93/100: Training Loss: 6.148744763040836e-05
Epoch 94/100: Training Loss: 3.3188728398523445e-05
Epoch 95/100: Training Loss: 1.0736250215741388e-05
Epoch 96/100: Training Loss: 4.829712457772047e-06
Epoch 97/100: Training Loss: 9.817039119822481e-06
Epoch 98/100: Training Loss: 2.749229672770559e-05
Epoch 99/100: Training Loss: 1.9405761367978495e-05
Epoch 0/100: Training Loss: 0.003413852738456492
Epoch 1/100: Training Loss: 0.0029046707358097008
Epoch 2/100: Training Loss: 0.0025365937706882968
Epoch 3/100: Training Loss: 0.001598933905911592
Epoch 4/100: Training Loss: 0.00125152037187588
Epoch 5/100: Training Loss: 0.001556941519485661
Epoch 6/100: Training Loss: 0.0019457693114602493
Epoch 7/100: Training Loss: 0.00043293358358137445
Epoch 8/100: Training Loss: 0.0002760072838675025
Epoch 9/100: Training Loss: 0.0002155591236667399
Epoch 10/100: Training Loss: 0.0011771328610145242
Epoch 11/100: Training Loss: 0.001550845390448541
Epoch 12/100: Training Loss: 0.001962554601072534
Epoch 13/100: Training Loss: 0.002630990707069818
Epoch 14/100: Training Loss: 0.002421257686029914
Epoch 15/100: Training Loss: 0.002384360948223278
Epoch 16/100: Training Loss: 0.0022948856002714007
Epoch 17/100: Training Loss: 0.0017744832975001422
Epoch 18/100: Training Loss: 0.0017924261239408716
Epoch 19/100: Training Loss: 0.001254382857515768
Epoch 20/100: Training Loss: 0.0009269783833275543
Epoch 21/100: Training Loss: 0.0007666423916816711
Epoch 22/100: Training Loss: 0.00047687596521494576
Epoch 23/100: Training Loss: 0.0004315827887482438
Epoch 24/100: Training Loss: 0.00045985239415081
Epoch 25/100: Training Loss: 0.000541792416865109
Epoch 26/100: Training Loss: 0.0005775806636898064
Epoch 27/100: Training Loss: 0.00041629305463627075
Epoch 28/100: Training Loss: 0.0003937074194656559
Epoch 29/100: Training Loss: 0.000618640082014119
Epoch 30/100: Training Loss: 0.00035670532222174426
Epoch 31/100: Training Loss: 0.00039482326961002467
Epoch 32/100: Training Loss: 0.0004122424070820487
Epoch 33/100: Training Loss: 0.0004021357630659466
Epoch 34/100: Training Loss: 0.0006110623387471298
Epoch 35/100: Training Loss: 0.0002886004563123902
Epoch 36/100: Training Loss: 0.00037278961733075005
Epoch 37/100: Training Loss: 0.0003375229111478373
Epoch 38/100: Training Loss: 0.0003548459224174359
Epoch 39/100: Training Loss: 0.0002131626878413686
Epoch 40/100: Training Loss: 0.0001592592570496483
Epoch 41/100: Training Loss: 0.00012710354536588938
Epoch 42/100: Training Loss: 0.0007259317336638281
Epoch 43/100: Training Loss: 0.00030209425768237905
Epoch 44/100: Training Loss: 0.0011536302559214868
Epoch 45/100: Training Loss: 0.0003073555103108927
Epoch 46/100: Training Loss: 0.00023427980443451303
Epoch 47/100: Training Loss: 0.00030469914978267223
Epoch 48/100: Training Loss: 0.00024513395194627026
Epoch 49/100: Training Loss: 0.00018924939806110288
Epoch 50/100: Training Loss: 0.001689801186871675
Epoch 51/100: Training Loss: 9.914144782200912e-05
Epoch 52/100: Training Loss: 3.4333658090398356e-05
Epoch 53/100: Training Loss: 0.00025399682894806187
Epoch 54/100: Training Loss: 0.00024797870246179266
Epoch 55/100: Training Loss: 5.000803985295852e-05
Epoch 56/100: Training Loss: 0.00020076087647420498
Epoch 57/100: Training Loss: 0.00011338108430610844
Epoch 58/100: Training Loss: 8.680010671538809e-06
Epoch 59/100: Training Loss: 3.0166703773422476e-05
Epoch 60/100: Training Loss: 7.357818297356184e-06
Epoch 61/100: Training Loss: 9.495157039969977e-05
Epoch 62/100: Training Loss: 0.00046387598192764937
Epoch 63/100: Training Loss: 9.997770693038871e-05
Epoch 64/100: Training Loss: 8.45929550612631e-05
Epoch 65/100: Training Loss: 9.094394652024368e-05
Epoch 66/100: Training Loss: 2.0005018878842424e-05
Epoch 67/100: Training Loss: 0.00011065966832491518
Epoch 68/100: Training Loss: 6.828797649752143e-05
Epoch 69/100: Training Loss: 9.463583490599883e-05
Epoch 70/100: Training Loss: 0.00030686427479141327
Epoch 71/100: Training Loss: 0.00014710346339670427
Epoch 72/100: Training Loss: 0.0005653617572199348
Epoch 73/100: Training Loss: 0.00047723766119202223
Epoch 74/100: Training Loss: 0.0013006645843295231
Epoch 75/100: Training Loss: 9.564857821385919e-06
Epoch 76/100: Training Loss: 5.74292673620801e-06
Epoch 77/100: Training Loss: 9.119844184102822e-06
Epoch 78/100: Training Loss: 6.436924535803999e-06
Epoch 79/100: Training Loss: 1.4268235907678498e-06
Epoch 80/100: Training Loss: 0.00021082571953352243
Epoch 81/100: Training Loss: 1.9497578060882954e-05
Epoch 82/100: Training Loss: 1.9514236164970633e-05
Epoch 83/100: Training Loss: 1.1164924998316297e-05
Epoch 84/100: Training Loss: 2.0239353637022474e-05
Epoch 85/100: Training Loss: 1.9519410576054287e-06
Epoch 86/100: Training Loss: 6.2907594570353e-05
Epoch 87/100: Training Loss: 4.572930611510036e-06
Epoch 88/100: Training Loss: 3.8281500202380806e-05
Epoch 89/100: Training Loss: 1.9791083227545936e-05
Epoch 90/100: Training Loss: 0.0001559099810986431
Epoch 91/100: Training Loss: 1.5190775374784791e-05
Epoch 92/100: Training Loss: 1.6829544575484985e-05
Epoch 93/100: Training Loss: 4.008306658889618e-06
Epoch 94/100: Training Loss: 4.333770331109594e-06
Epoch 95/100: Training Loss: 7.6296159346228e-06
Epoch 96/100: Training Loss: 0.0010008075120258916
Epoch 97/100: Training Loss: 0.0003695895701098296
Epoch 98/100: Training Loss: 0.0003937347077884557
Epoch 99/100: Training Loss: 1.182823736174889e-05
Epoch 0/100: Training Loss: 0.0038797002285718917
Epoch 1/100: Training Loss: 0.0027557415887713432
Epoch 2/100: Training Loss: 0.003560783341526985
Epoch 3/100: Training Loss: 0.002922377735376358
Epoch 4/100: Training Loss: 0.0023930706083774567
Epoch 5/100: Training Loss: 0.0036830976605415344
Epoch 6/100: Training Loss: 0.0024093203246593475
Epoch 7/100: Training Loss: 0.002341616339981556
Epoch 8/100: Training Loss: 0.0027351081371307373
Epoch 9/100: Training Loss: 0.0022474467754364015
Epoch 10/100: Training Loss: 0.003007555939257145
Epoch 11/100: Training Loss: 0.0019003326073288918
Epoch 12/100: Training Loss: 0.0024143533781170847
Epoch 13/100: Training Loss: 0.002045787498354912
Epoch 14/100: Training Loss: 0.0019366273656487465
Epoch 15/100: Training Loss: 0.002139279991388321
Epoch 16/100: Training Loss: 0.002098705992102623
Epoch 17/100: Training Loss: 0.002427454851567745
Epoch 18/100: Training Loss: 0.001822001114487648
Epoch 19/100: Training Loss: 0.0031304202973842623
Epoch 20/100: Training Loss: 0.002341919019818306
Epoch 21/100: Training Loss: 0.002607506699860096
Epoch 22/100: Training Loss: 0.002722846530377865
Epoch 23/100: Training Loss: 0.0019339798018336296
Epoch 24/100: Training Loss: 0.003519551455974579
Epoch 25/100: Training Loss: 0.001959150657057762
Epoch 26/100: Training Loss: 0.002076829597353935
Epoch 27/100: Training Loss: 0.002202606946229935
Epoch 28/100: Training Loss: 0.0022902108728885652
Epoch 29/100: Training Loss: 0.0021080255508422853
Epoch 30/100: Training Loss: 0.0023625932633876802
Epoch 31/100: Training Loss: 0.0015047144144773484
Epoch 32/100: Training Loss: 0.0022306960076093675
Epoch 33/100: Training Loss: 0.0014251790940761565
Epoch 34/100: Training Loss: 0.0018540909513831139
Epoch 35/100: Training Loss: 0.001662342995405197
Epoch 36/100: Training Loss: 0.0025337196886539457
Epoch 37/100: Training Loss: 0.002061587572097778
Epoch 38/100: Training Loss: 0.0016790146008133888
Epoch 39/100: Training Loss: 0.00199541337788105
Epoch 40/100: Training Loss: 0.0013520251959562302
Epoch 41/100: Training Loss: 0.0016560383141040803
Epoch 42/100: Training Loss: 0.0020845592021942138
Epoch 43/100: Training Loss: 0.0010189984925091267
Epoch 44/100: Training Loss: 0.00063908901065588
Epoch 45/100: Training Loss: 0.0013844919390976428
Epoch 46/100: Training Loss: 0.00140927042812109
Epoch 47/100: Training Loss: 0.0013432351872324944
Epoch 48/100: Training Loss: 0.0017069673165678978
Epoch 49/100: Training Loss: 0.0017560318112373352
Epoch 50/100: Training Loss: 0.0018998341634869575
Epoch 51/100: Training Loss: 0.0017868300899863243
Epoch 52/100: Training Loss: 0.0025255292654037475
Epoch 53/100: Training Loss: 0.0016095228493213654
Epoch 54/100: Training Loss: 0.0015817483887076377
Epoch 55/100: Training Loss: 0.0012277199886739254
Epoch 56/100: Training Loss: 0.0015919636934995651
Epoch 57/100: Training Loss: 0.001454220898449421
Epoch 58/100: Training Loss: 0.0009946169331669808
Epoch 59/100: Training Loss: 0.001960884779691696
Epoch 60/100: Training Loss: 0.0013432089239358903
Epoch 61/100: Training Loss: 0.0025608398020267485
Epoch 62/100: Training Loss: 0.0011954717338085175
Epoch 63/100: Training Loss: 0.0010101432912051679
Epoch 64/100: Training Loss: 0.0007002957165241242
Epoch 65/100: Training Loss: 0.0011450481601059438
Epoch 66/100: Training Loss: 0.0008489725179970265
Epoch 67/100: Training Loss: 0.001128617115318775
Epoch 68/100: Training Loss: 0.001068997010588646
Epoch 69/100: Training Loss: 0.0010555824264883995
Epoch 70/100: Training Loss: 0.0009880821220576764
Epoch 71/100: Training Loss: 0.0013882100582122802
Epoch 72/100: Training Loss: 0.002101893723011017
Epoch 73/100: Training Loss: 0.0017099974676966668
Epoch 74/100: Training Loss: 0.0011886924505233765
Epoch 75/100: Training Loss: 0.0017115738242864608
Epoch 76/100: Training Loss: 0.000620713597163558
Epoch 77/100: Training Loss: 0.0016719410195946693
Epoch 78/100: Training Loss: 0.0009051119908690452
Epoch 79/100: Training Loss: 0.001113760471343994
Epoch 80/100: Training Loss: 0.0015058638527989388
Epoch 81/100: Training Loss: 0.0010827970691025257
Epoch 82/100: Training Loss: 0.0010410144925117493
Epoch 83/100: Training Loss: 0.001499432884156704
Epoch 84/100: Training Loss: 0.000999294128268957
Epoch 85/100: Training Loss: 0.0010973861441016196
Epoch 86/100: Training Loss: 0.0009041356854140759
Epoch 87/100: Training Loss: 0.001181950233876705
Epoch 88/100: Training Loss: 0.0010505219921469688
Epoch 89/100: Training Loss: 0.001190132275223732
Epoch 90/100: Training Loss: 0.001258876547217369
Epoch 91/100: Training Loss: 0.0013658237643539906
Epoch 92/100: Training Loss: 0.001101534627377987
Epoch 93/100: Training Loss: 0.0017271611839532852
Epoch 94/100: Training Loss: 0.001754104346036911
Epoch 95/100: Training Loss: 0.003651701658964157
Epoch 96/100: Training Loss: 0.0016684280708432198
Epoch 97/100: Training Loss: 0.0014339713379740715
Epoch 98/100: Training Loss: 0.001210120879113674
Epoch 99/100: Training Loss: 0.002014873921871185
Epoch 0/100: Training Loss: 0.003990856185555458
Epoch 1/100: Training Loss: 0.003637312725186348
Epoch 2/100: Training Loss: 0.0031252391636371613
Epoch 3/100: Training Loss: 0.003650938719511032
Epoch 4/100: Training Loss: 0.0025805961340665817
Epoch 5/100: Training Loss: 0.0023388709872961045
Epoch 6/100: Training Loss: 0.0022710204124450684
Epoch 7/100: Training Loss: 0.0018792510032653808
Epoch 8/100: Training Loss: 0.002111107297241688
Epoch 9/100: Training Loss: 0.002323155105113983
Epoch 10/100: Training Loss: 0.0028454042971134187
Epoch 11/100: Training Loss: 0.0024105435237288474
Epoch 12/100: Training Loss: 0.0034711655229330064
Epoch 13/100: Training Loss: 0.0017228294163942337
Epoch 14/100: Training Loss: 0.002142803929746151
Epoch 15/100: Training Loss: 0.00209631472826004
Epoch 16/100: Training Loss: 0.00273448470979929
Epoch 17/100: Training Loss: 0.0032350637018680574
Epoch 18/100: Training Loss: 0.0020918795838952065
Epoch 19/100: Training Loss: 0.004221035912632942
Epoch 20/100: Training Loss: 0.0015609677881002425
Epoch 21/100: Training Loss: 0.0019992439076304434
Epoch 22/100: Training Loss: 0.0012117672711610794
Epoch 23/100: Training Loss: 0.0029758688062429426
Epoch 24/100: Training Loss: 0.002334138751029968
Epoch 25/100: Training Loss: 0.0018368901684880257
Epoch 26/100: Training Loss: 0.0031898673623800278
Epoch 27/100: Training Loss: 0.0029605241492390633
Epoch 28/100: Training Loss: 0.0022196609526872633
Epoch 29/100: Training Loss: 0.0022032327950000765
Epoch 30/100: Training Loss: 0.0022356586530804636
Epoch 31/100: Training Loss: 0.0020360182970762253
Epoch 32/100: Training Loss: 0.001736893877387047
Epoch 33/100: Training Loss: 0.001221519522368908
Epoch 34/100: Training Loss: 0.0014937842264771462
Epoch 35/100: Training Loss: 0.001857605390250683
Epoch 36/100: Training Loss: 0.0009908691048622132
Epoch 37/100: Training Loss: 0.0016376132145524025
Epoch 38/100: Training Loss: 0.002846014313399792
Epoch 39/100: Training Loss: 0.0013786355033516885
Epoch 40/100: Training Loss: 0.0019186396151781083
Epoch 41/100: Training Loss: 0.0012828442268073559
Epoch 42/100: Training Loss: 0.0013175390660762787
Epoch 43/100: Training Loss: 0.0015950284898281098
Epoch 44/100: Training Loss: 0.0020338937640190123
Epoch 45/100: Training Loss: 0.0017852053046226502
Epoch 46/100: Training Loss: 0.0012203622609376907
Epoch 47/100: Training Loss: 0.001674218289554119
Epoch 48/100: Training Loss: 0.001084248349070549
Epoch 49/100: Training Loss: 0.0010728970170021056
Epoch 50/100: Training Loss: 0.0014432210475206376
Epoch 51/100: Training Loss: 0.0011910305358469487
Epoch 52/100: Training Loss: 0.0009871014393866063
Epoch 53/100: Training Loss: 0.0012379709631204605
Epoch 54/100: Training Loss: 0.0011654091998934747
Epoch 55/100: Training Loss: 0.001081183087080717
Epoch 56/100: Training Loss: 0.0009206748567521572
Epoch 57/100: Training Loss: 0.0010785426944494247
Epoch 58/100: Training Loss: 0.0008741876110434533
Epoch 59/100: Training Loss: 0.0020752042531967164
Epoch 60/100: Training Loss: 0.0010393044911324977
Epoch 61/100: Training Loss: 0.0007797017227858305
Epoch 62/100: Training Loss: 0.0012375175021588803
Epoch 63/100: Training Loss: 0.001229519583284855
Epoch 64/100: Training Loss: 0.00131802037358284
Epoch 65/100: Training Loss: 0.0016754299402236938
Epoch 66/100: Training Loss: 0.0010709182359278202
Epoch 67/100: Training Loss: 0.0009494395926594734
Epoch 68/100: Training Loss: 0.0009796261787414552
Epoch 69/100: Training Loss: 0.0010996077209711075
Epoch 70/100: Training Loss: 0.0008930830284953117
Epoch 71/100: Training Loss: 0.0011167879216372966
Epoch 72/100: Training Loss: 0.0010344672948122025
Epoch 73/100: Training Loss: 0.0009679270908236504
Epoch 74/100: Training Loss: 0.0010160895995795726
Epoch 75/100: Training Loss: 0.0010281797498464585
Epoch 76/100: Training Loss: 0.0010394049808382989
Epoch 77/100: Training Loss: 0.0009654466062784195
Epoch 78/100: Training Loss: 0.0009739138185977936
Epoch 79/100: Training Loss: 0.0016188181936740876
Epoch 80/100: Training Loss: 0.0010192608460783958
Epoch 81/100: Training Loss: 0.0010923227295279504
Epoch 82/100: Training Loss: 0.0008746417239308357
Epoch 83/100: Training Loss: 0.0009324313141405582
Epoch 84/100: Training Loss: 0.0009318087249994278
Epoch 85/100: Training Loss: 0.001195988617837429
Epoch 86/100: Training Loss: 0.0012737184762954712
Epoch 87/100: Training Loss: 0.0014269583858549594
Epoch 88/100: Training Loss: 0.001121808961033821
Epoch 89/100: Training Loss: 0.0009006679058074952
Epoch 90/100: Training Loss: 0.0010368104092776775
Epoch 91/100: Training Loss: 0.0008783522062003613
Epoch 92/100: Training Loss: 0.0009011180140078068
Epoch 93/100: Training Loss: 0.000829431414604187
Epoch 94/100: Training Loss: 0.0008713638409972191
Epoch 95/100: Training Loss: 0.0015107119455933572
Epoch 96/100: Training Loss: 0.0012060118839144706
Epoch 97/100: Training Loss: 0.0009164364077150821
Epoch 98/100: Training Loss: 0.001014451216906309
Epoch 99/100: Training Loss: 0.0008850330486893654
Epoch 0/100: Training Loss: 0.00394405908882618
Epoch 1/100: Training Loss: 0.003631465882062912
Epoch 2/100: Training Loss: 0.004448293894529343
Epoch 3/100: Training Loss: 0.003502842038869858
Epoch 4/100: Training Loss: 0.0026759397238492965
Epoch 5/100: Training Loss: 0.002813669666647911
Epoch 6/100: Training Loss: 0.0025296561419963838
Epoch 7/100: Training Loss: 0.0022079385817050934
Epoch 8/100: Training Loss: 0.002181212976574898
Epoch 9/100: Training Loss: 0.0016446366906166076
Epoch 10/100: Training Loss: 0.0027576269581913947
Epoch 11/100: Training Loss: 0.0029378648847341537
Epoch 12/100: Training Loss: 0.002799621783196926
Epoch 13/100: Training Loss: 0.0037286799401044846
Epoch 14/100: Training Loss: 0.003352779522538185
Epoch 15/100: Training Loss: 0.0028607334941625597
Epoch 16/100: Training Loss: 0.0032131064683198927
Epoch 17/100: Training Loss: 0.003422528877854347
Epoch 18/100: Training Loss: 0.002828293852508068
Epoch 19/100: Training Loss: 0.0034059986472129824
Epoch 20/100: Training Loss: 0.0030336394906044007
Epoch 21/100: Training Loss: 0.0033319246023893355
Epoch 22/100: Training Loss: 0.0032049283385276795
Epoch 23/100: Training Loss: 0.0034655775874853135
Epoch 24/100: Training Loss: 0.0033998161554336546
Epoch 25/100: Training Loss: 0.0023418433964252474
Epoch 26/100: Training Loss: 0.002730207145214081
Epoch 27/100: Training Loss: 0.0024896543473005295
Epoch 28/100: Training Loss: 0.001783519983291626
Epoch 29/100: Training Loss: 0.0024778030812740324
Epoch 30/100: Training Loss: 0.0016627762466669082
Epoch 31/100: Training Loss: 0.0023589976131916045
Epoch 32/100: Training Loss: 0.0016998521983623504
Epoch 33/100: Training Loss: 0.0033913116902112963
Epoch 34/100: Training Loss: 0.002380148693919182
Epoch 35/100: Training Loss: 0.001953304745256901
Epoch 36/100: Training Loss: 0.0014495177194476128
Epoch 37/100: Training Loss: 0.001332362461835146
Epoch 38/100: Training Loss: 0.001549171842634678
Epoch 39/100: Training Loss: 0.0009934891946613788
Epoch 40/100: Training Loss: 0.0009740574285387992
Epoch 41/100: Training Loss: 0.0008072121068835259
Epoch 42/100: Training Loss: 0.0008299538865685463
Epoch 43/100: Training Loss: 0.0009735362604260444
Epoch 44/100: Training Loss: 0.0010468208231031895
Epoch 45/100: Training Loss: 0.001448538899421692
Epoch 46/100: Training Loss: 0.0020130932331085204
Epoch 47/100: Training Loss: 0.0010015151463449
Epoch 48/100: Training Loss: 0.0027062900364398955
Epoch 49/100: Training Loss: 0.00215870663523674
Epoch 50/100: Training Loss: 0.00131034255027771
Epoch 51/100: Training Loss: 0.001058315299451351
Epoch 52/100: Training Loss: 0.0010767199099063873
Epoch 53/100: Training Loss: 0.001051490381360054
Epoch 54/100: Training Loss: 0.0014513984322547912
Epoch 55/100: Training Loss: 0.0008107399567961693
Epoch 56/100: Training Loss: 0.001684875227510929
Epoch 57/100: Training Loss: 0.0014680219814181329
Epoch 58/100: Training Loss: 0.0011911053210496903
Epoch 59/100: Training Loss: 0.00109961349517107
Epoch 60/100: Training Loss: 0.0012300453148782254
Epoch 61/100: Training Loss: 0.0016165733337402343
Epoch 62/100: Training Loss: 0.0015491209924221039
Epoch 63/100: Training Loss: 0.0021503221243619917
Epoch 64/100: Training Loss: 0.0011299708858132362
Epoch 65/100: Training Loss: 0.0016822997480630876
Epoch 66/100: Training Loss: 0.0010178718715906144
Epoch 67/100: Training Loss: 0.00099666528403759
Epoch 68/100: Training Loss: 0.0009685626253485679
Epoch 69/100: Training Loss: 0.0007867809385061264
Epoch 70/100: Training Loss: 0.000589188700541854
Epoch 71/100: Training Loss: 0.0010488107800483704
Epoch 72/100: Training Loss: 0.00142426872625947
Epoch 73/100: Training Loss: 0.0011100644245743752
Epoch 74/100: Training Loss: 0.0011517630890011787
Epoch 75/100: Training Loss: 0.000883689895272255
Epoch 76/100: Training Loss: 0.0009706635028123856
Epoch 77/100: Training Loss: 0.0011417478322982787
Epoch 78/100: Training Loss: 0.0008239930495619774
Epoch 79/100: Training Loss: 0.0013295561075210571
Epoch 80/100: Training Loss: 0.000994296744465828
Epoch 81/100: Training Loss: 0.0010014104656875134
Epoch 82/100: Training Loss: 0.0009553308598697185
Epoch 83/100: Training Loss: 0.0009239107370376587
Epoch 84/100: Training Loss: 0.0007665876299142837
Epoch 85/100: Training Loss: 0.0006406981498003006
Epoch 86/100: Training Loss: 0.0004552974365651608
Epoch 87/100: Training Loss: 0.0008440881967544556
Epoch 88/100: Training Loss: 0.0009588857181370258
Epoch 89/100: Training Loss: 0.001057327724993229
Epoch 90/100: Training Loss: 0.0010288269259035587
Epoch 91/100: Training Loss: 0.0008993377909064293
Epoch 92/100: Training Loss: 0.0009056584909558296
Epoch 93/100: Training Loss: 0.0009134981781244278
Epoch 94/100: Training Loss: 0.0009119101800024509
Epoch 95/100: Training Loss: 0.0008878478780388832
Epoch 96/100: Training Loss: 0.0008317167870700359
Epoch 97/100: Training Loss: 0.0008789229206740857
Epoch 98/100: Training Loss: 0.0011459736153483391
Epoch 99/100: Training Loss: 0.0011630244553089142
Epoch 0/100: Training Loss: 0.004154901595631982
Epoch 1/100: Training Loss: 0.0018421252062366267
Epoch 2/100: Training Loss: 0.002928125820342143
Epoch 3/100: Training Loss: 0.0032002766420886775
Epoch 4/100: Training Loss: 0.0032996785868505004
Epoch 5/100: Training Loss: 0.002984236759744632
Epoch 6/100: Training Loss: 0.0017341060243594418
Epoch 7/100: Training Loss: 0.002353562481084447
Epoch 8/100: Training Loss: 0.002682006662818277
Epoch 9/100: Training Loss: 0.002264398108622071
Epoch 10/100: Training Loss: 0.0014799843738033513
Epoch 11/100: Training Loss: 0.0018579808010417186
Epoch 12/100: Training Loss: 0.0013480006129878341
Epoch 13/100: Training Loss: 0.0035946634924335845
Epoch 14/100: Training Loss: 0.0017333826062026297
Epoch 15/100: Training Loss: 0.002423314721720993
Epoch 16/100: Training Loss: 0.0022815737375028572
Epoch 17/100: Training Loss: 0.003148605109779698
Epoch 18/100: Training Loss: 0.0022839609604732246
Epoch 19/100: Training Loss: 0.0009197709476871855
Epoch 20/100: Training Loss: 0.002898221562622459
Epoch 21/100: Training Loss: 0.002346893784346854
Epoch 22/100: Training Loss: 0.00222857628658319
Epoch 23/100: Training Loss: 0.001615614648077898
Epoch 24/100: Training Loss: 0.0017001268210684417
Epoch 25/100: Training Loss: 0.0012065709396532386
Epoch 26/100: Training Loss: 0.0010768600330231296
Epoch 27/100: Training Loss: 0.0019259614169977273
Epoch 28/100: Training Loss: 0.0016253374184772467
Epoch 29/100: Training Loss: 0.0014621878315688697
Epoch 30/100: Training Loss: 0.0017904988519705026
Epoch 31/100: Training Loss: 0.0019217832073284563
Epoch 32/100: Training Loss: 0.001375454911001169
Epoch 33/100: Training Loss: 0.0014582301970500096
Epoch 34/100: Training Loss: 0.0013244912313048248
Epoch 35/100: Training Loss: 0.0016547785063458097
Epoch 36/100: Training Loss: 0.0019817236502459095
Epoch 37/100: Training Loss: 0.0017923446977214448
Epoch 38/100: Training Loss: 0.001596782997155645
Epoch 39/100: Training Loss: 0.00143260257259296
Epoch 40/100: Training Loss: 0.001064449738545023
Epoch 41/100: Training Loss: 0.001998695408462719
Epoch 42/100: Training Loss: 0.002112605769163484
Epoch 43/100: Training Loss: 0.00132159803323685
Epoch 44/100: Training Loss: 0.001532709522611776
Epoch 45/100: Training Loss: 0.0009777894255461965
Epoch 46/100: Training Loss: 0.0009926029830981211
Epoch 47/100: Training Loss: 0.0008523781208475684
Epoch 48/100: Training Loss: 0.0011733926975043716
Epoch 49/100: Training Loss: 0.0011332414712116217
Epoch 50/100: Training Loss: 0.0008832733532425705
Epoch 51/100: Training Loss: 0.0010967135998853452
Epoch 52/100: Training Loss: 0.0017963446629275183
Epoch 53/100: Training Loss: 0.0013604515297397687
Epoch 54/100: Training Loss: 0.0017242433538862095
Epoch 55/100: Training Loss: 0.0009256931626872651
Epoch 56/100: Training Loss: 0.0012956705822306834
Epoch 57/100: Training Loss: 0.0008719091772273847
Epoch 58/100: Training Loss: 0.0009359168778559205
Epoch 59/100: Training Loss: 0.0010574162006378174
Epoch 60/100: Training Loss: 0.0017838582491419119
Epoch 61/100: Training Loss: 0.0008959437062026589
Epoch 62/100: Training Loss: 0.0012734167894740015
Epoch 63/100: Training Loss: 0.000961718285918995
Epoch 64/100: Training Loss: 0.0007266941343902783
Epoch 65/100: Training Loss: 0.0008885925932295004
Epoch 66/100: Training Loss: 0.0008479395679607513
Epoch 67/100: Training Loss: 0.0009040422500318782
Epoch 68/100: Training Loss: 0.0008968528668591931
Epoch 69/100: Training Loss: 0.000760396100153589
Epoch 70/100: Training Loss: 0.0005626583554942137
Epoch 71/100: Training Loss: 0.0008471673651106039
Epoch 72/100: Training Loss: 0.0005331140984395507
Epoch 73/100: Training Loss: 0.0008861721511099749
Epoch 74/100: Training Loss: 0.0008545790318470851
Epoch 75/100: Training Loss: 0.0003297466571163979
Epoch 76/100: Training Loss: 0.0009453335575237395
Epoch 77/100: Training Loss: 0.00143936295418223
Epoch 78/100: Training Loss: 0.000992167432596729
Epoch 79/100: Training Loss: 0.000853861782960831
Epoch 80/100: Training Loss: 0.0005991666275224868
Epoch 81/100: Training Loss: 0.0009860161003793122
Epoch 82/100: Training Loss: 0.0008869867795591901
Epoch 83/100: Training Loss: 0.0007473828306623325
Epoch 84/100: Training Loss: 0.0007478553018752177
Epoch 85/100: Training Loss: 0.0008504236959348059
Epoch 86/100: Training Loss: 0.0007068222495400982
Epoch 87/100: Training Loss: 0.0002807293822810908
Epoch 88/100: Training Loss: 0.0009243749319368108
Epoch 89/100: Training Loss: 0.0009039988753142631
Epoch 90/100: Training Loss: 0.0006982229982212091
Epoch 91/100: Training Loss: 0.0006953990383512655
Epoch 92/100: Training Loss: 0.000648349713368021
Epoch 93/100: Training Loss: 0.0013366014144982502
Epoch 94/100: Training Loss: 0.0007582555530936854
Epoch 95/100: Training Loss: 0.0007465486978269686
Epoch 96/100: Training Loss: 0.0006051230107902722
Epoch 97/100: Training Loss: 0.002596931093058009
Epoch 98/100: Training Loss: 0.0006202490656239212
Epoch 99/100: Training Loss: 0.0005712589830349964
Epoch 0/100: Training Loss: 0.0031570877618850414
Epoch 1/100: Training Loss: 0.002374402656676663
Epoch 2/100: Training Loss: 0.001371144489118248
Epoch 3/100: Training Loss: 0.002610895094598175
Epoch 4/100: Training Loss: 0.002460952587188429
Epoch 5/100: Training Loss: 0.003617202780049318
Epoch 6/100: Training Loss: 0.0030130204881072802
Epoch 7/100: Training Loss: 0.00382877914768875
Epoch 8/100: Training Loss: 0.0030090059064755773
Epoch 9/100: Training Loss: 0.0029821868535060032
Epoch 10/100: Training Loss: 0.003586812004162248
Epoch 11/100: Training Loss: 0.002868182340245338
Epoch 12/100: Training Loss: 0.004302101150439803
Epoch 13/100: Training Loss: 0.0030344876514118947
Epoch 14/100: Training Loss: 0.0027665924874080974
Epoch 15/100: Training Loss: 0.003564601870858745
Epoch 16/100: Training Loss: 0.0020646745232260153
Epoch 17/100: Training Loss: 0.001768404890777199
Epoch 18/100: Training Loss: 0.0027815589479580046
Epoch 19/100: Training Loss: 0.002269667424973409
Epoch 20/100: Training Loss: 0.002614924102831798
Epoch 21/100: Training Loss: 0.001614506647085688
Epoch 22/100: Training Loss: 0.002531891985304037
Epoch 23/100: Training Loss: 0.0024549699133368814
Epoch 24/100: Training Loss: 0.0016797651910478142
Epoch 25/100: Training Loss: 0.001765468317991609
Epoch 26/100: Training Loss: 0.0021331169802671786
Epoch 27/100: Training Loss: 0.0015880633501490211
Epoch 28/100: Training Loss: 0.002124490821437471
Epoch 29/100: Training Loss: 0.0019526037440937795
Epoch 30/100: Training Loss: 0.0013610454881267183
Epoch 31/100: Training Loss: 0.0017838398362420927
Epoch 32/100: Training Loss: 0.0017141694096243305
Epoch 33/100: Training Loss: 0.0012002126046806384
Epoch 34/100: Training Loss: 0.0011000973973304602
Epoch 35/100: Training Loss: 0.0017073446777975483
Epoch 36/100: Training Loss: 0.0007204724250325732
Epoch 37/100: Training Loss: 0.00153245458936995
Epoch 38/100: Training Loss: 0.0025326647576253128
Epoch 39/100: Training Loss: 0.0007634482755782498
Epoch 40/100: Training Loss: 0.0015599065145869165
Epoch 41/100: Training Loss: 0.001125537381050693
Epoch 42/100: Training Loss: 0.000735438695758771
Epoch 43/100: Training Loss: 0.0007548130052104877
Epoch 44/100: Training Loss: 0.0009937628059630181
Epoch 45/100: Training Loss: 0.0005751112179391703
Epoch 46/100: Training Loss: 0.0006879225468179982
Epoch 47/100: Training Loss: 0.0006112995895610493
Epoch 48/100: Training Loss: 0.0007423964465499683
Epoch 49/100: Training Loss: 0.0006105368304404484
Epoch 50/100: Training Loss: 0.0007976037301834981
Epoch 51/100: Training Loss: 0.0011026613461743494
Epoch 52/100: Training Loss: 0.0006628523871397517
Epoch 53/100: Training Loss: 0.0008115195165014571
Epoch 54/100: Training Loss: 0.0015602822706198237
Epoch 55/100: Training Loss: 0.0006500094844277498
Epoch 56/100: Training Loss: 0.0009052273194501355
Epoch 57/100: Training Loss: 0.0009004228813633039
Epoch 58/100: Training Loss: 0.0005629755983686751
Epoch 59/100: Training Loss: 0.0014894247814348548
Epoch 60/100: Training Loss: 0.0007226972063635565
Epoch 61/100: Training Loss: 0.00040941334264293596
Epoch 62/100: Training Loss: 0.0008493454023531288
Epoch 63/100: Training Loss: 0.0008441419548289791
Epoch 64/100: Training Loss: 0.0011014309088895275
Epoch 65/100: Training Loss: 0.0009110915433069703
Epoch 66/100: Training Loss: 0.0008233736275107997
Epoch 67/100: Training Loss: 0.0009411813537026667
Epoch 68/100: Training Loss: 0.0007827279104548655
Epoch 69/100: Training Loss: 0.000808226644613181
Epoch 70/100: Training Loss: 0.0009977838416008434
Epoch 71/100: Training Loss: 0.0005686904309661525
Epoch 72/100: Training Loss: 0.0008620518218180177
Epoch 73/100: Training Loss: 0.0007107925073356386
Epoch 74/100: Training Loss: 0.0007370935314020533
Epoch 75/100: Training Loss: 0.0006587736925501732
Epoch 76/100: Training Loss: 0.0008182428824673793
Epoch 77/100: Training Loss: 0.0007113658698501101
Epoch 78/100: Training Loss: 0.0006981354420352133
Epoch 79/100: Training Loss: 0.0005519500203952668
Epoch 80/100: Training Loss: 0.0005834123511223277
Epoch 81/100: Training Loss: 0.0002915851866743367
Epoch 82/100: Training Loss: 0.002771211277907062
Epoch 83/100: Training Loss: 0.0005871438106913475
Epoch 84/100: Training Loss: 0.0006052382812378513
Epoch 85/100: Training Loss: 0.000466912795024313
Epoch 86/100: Training Loss: 0.0010599721768859087
Epoch 87/100: Training Loss: 0.0006930693319648694
Epoch 88/100: Training Loss: 0.0005405023219479118
Epoch 89/100: Training Loss: 0.0006886109899563394
Epoch 90/100: Training Loss: 0.00037185102701187134
Epoch 91/100: Training Loss: 0.000699679040984743
Epoch 92/100: Training Loss: 0.0006031218417890512
Epoch 93/100: Training Loss: 0.0005041837312613324
Epoch 94/100: Training Loss: 0.0005515761625994542
Epoch 95/100: Training Loss: 0.0004883635860339851
Epoch 96/100: Training Loss: 0.0006059967218690617
Epoch 97/100: Training Loss: 0.0007544008030253611
Epoch 98/100: Training Loss: 0.0007513823687650596
Epoch 99/100: Training Loss: 0.0002841884210990493
Epoch 0/100: Training Loss: 0.003135188369993951
Epoch 1/100: Training Loss: 0.002116880599100878
Epoch 2/100: Training Loss: 0.0033743787722982418
Epoch 3/100: Training Loss: 0.002523383706997914
Epoch 4/100: Training Loss: 0.002704720967894147
Epoch 5/100: Training Loss: 0.0031640937753543734
Epoch 6/100: Training Loss: 0.0029525578401650592
Epoch 7/100: Training Loss: 0.0013961074458565682
Epoch 8/100: Training Loss: 0.0012140741014176873
Epoch 9/100: Training Loss: 0.002093505517692323
Epoch 10/100: Training Loss: 0.001351474291959386
Epoch 11/100: Training Loss: 0.0015627696255969394
Epoch 12/100: Training Loss: 0.0005585297372690431
Epoch 13/100: Training Loss: 0.004194710285040983
Epoch 14/100: Training Loss: 0.00421318203021007
Epoch 15/100: Training Loss: 0.0022726968215529327
Epoch 16/100: Training Loss: 0.001763456566318585
Epoch 17/100: Training Loss: 0.002533099833567431
Epoch 18/100: Training Loss: 0.0022111202880835076
Epoch 19/100: Training Loss: 0.0024517227889625888
Epoch 20/100: Training Loss: 0.003319744091884346
Epoch 21/100: Training Loss: 0.001244084090943549
Epoch 22/100: Training Loss: 0.0011362302455173176
Epoch 23/100: Training Loss: 0.000983445602617446
Epoch 24/100: Training Loss: 0.0018650483173929203
Epoch 25/100: Training Loss: 0.0011434702167085781
Epoch 26/100: Training Loss: 0.0008218123275003616
Epoch 27/100: Training Loss: 0.0010526060678397015
Epoch 28/100: Training Loss: 0.0030386945244612966
Epoch 29/100: Training Loss: 0.0019137185470313783
Epoch 30/100: Training Loss: 0.0019652551146829202
Epoch 31/100: Training Loss: 0.0017921985334651486
Epoch 32/100: Training Loss: 0.0011991634490383658
Epoch 33/100: Training Loss: 0.0020333496248646147
Epoch 34/100: Training Loss: 0.0018704336160307478
Epoch 35/100: Training Loss: 0.0014029042735980574
Epoch 36/100: Training Loss: 0.0013711663188448377
Epoch 37/100: Training Loss: 0.0014457156893554006
Epoch 38/100: Training Loss: 0.0012185274605538436
Epoch 39/100: Training Loss: 0.0019192126146547353
Epoch 40/100: Training Loss: 0.0011428105793181498
Epoch 41/100: Training Loss: 0.0021472717546353673
Epoch 42/100: Training Loss: 0.0015626969231162101
Epoch 43/100: Training Loss: 0.0013732941477162064
Epoch 44/100: Training Loss: 0.001092366731850205
Epoch 45/100: Training Loss: 0.000531778214084115
Epoch 46/100: Training Loss: 0.0015296862953028101
Epoch 47/100: Training Loss: 0.001464839384054682
Epoch 48/100: Training Loss: 0.001386411630423965
Epoch 49/100: Training Loss: 0.0020129088383571358
Epoch 50/100: Training Loss: 0.0020877830921464664
Epoch 51/100: Training Loss: 0.0038727506710465546
Epoch 52/100: Training Loss: 0.0010875618192040996
Epoch 53/100: Training Loss: 0.0013129519429176477
Epoch 54/100: Training Loss: 0.000989673338877927
Epoch 55/100: Training Loss: 0.0008955045490507867
Epoch 56/100: Training Loss: 0.0010366234809729704
Epoch 57/100: Training Loss: 0.0005363652091117422
Epoch 58/100: Training Loss: 0.0008727111823999198
Epoch 59/100: Training Loss: 0.00047533878475237805
Epoch 60/100: Training Loss: 0.0008698120048850964
Epoch 61/100: Training Loss: 0.0020097738997951436
Epoch 62/100: Training Loss: 0.001124847941337877
Epoch 63/100: Training Loss: 0.0010936158667704103
Epoch 64/100: Training Loss: 0.001141378074694591
Epoch 65/100: Training Loss: 0.0010819733142852783
Epoch 66/100: Training Loss: 0.0025052082766393187
Epoch 67/100: Training Loss: 0.0009999547604542629
Epoch 68/100: Training Loss: 0.0007467323997218138
Epoch 69/100: Training Loss: 0.0014383091478590753
Epoch 70/100: Training Loss: 0.0011555095007465144
Epoch 71/100: Training Loss: 0.0008585182534661263
Epoch 72/100: Training Loss: 0.0009327241379743929
Epoch 73/100: Training Loss: 0.0006870231620825021
Epoch 74/100: Training Loss: 0.0010070554010427682
Epoch 75/100: Training Loss: 0.0012227293981867992
Epoch 76/100: Training Loss: 0.0014952349055344892
Epoch 77/100: Training Loss: 0.0011702228313798357
Epoch 78/100: Training Loss: 0.0011157894590098387
Epoch 79/100: Training Loss: 0.000982433937157795
Epoch 80/100: Training Loss: 0.0028672448009442373
Epoch 81/100: Training Loss: 0.0010907167841674415
Epoch 82/100: Training Loss: 0.0011402919034289706
Epoch 83/100: Training Loss: 0.001163239027284513
Epoch 84/100: Training Loss: 0.001157912858732187
Epoch 85/100: Training Loss: 0.0010105179753273157
Epoch 86/100: Training Loss: 0.0015787765098984833
Epoch 87/100: Training Loss: 0.0008518700576891565
Epoch 88/100: Training Loss: 0.0010285037718001445
Epoch 89/100: Training Loss: 0.0007557570934295654
Epoch 90/100: Training Loss: 0.0011571254699852815
Epoch 91/100: Training Loss: 0.0008556485935381264
Epoch 92/100: Training Loss: 0.0009850407861600257
Epoch 93/100: Training Loss: 0.001188391333173035
Epoch 94/100: Training Loss: 0.0012733964783370874
Epoch 95/100: Training Loss: 0.0014449401645903375
Epoch 96/100: Training Loss: 0.0012805471374730396
Epoch 97/100: Training Loss: 0.001172541243255518
Epoch 98/100: Training Loss: 0.0011234338496141374
Epoch 99/100: Training Loss: 0.0006814021023975056
Epoch 0/100: Training Loss: 0.00378396495288571
Epoch 1/100: Training Loss: 0.003050036777723704
Epoch 2/100: Training Loss: 0.0031177462726239336
Epoch 3/100: Training Loss: 0.0030446569651167914
Epoch 4/100: Training Loss: 0.002923939796473017
Epoch 5/100: Training Loss: 0.0024751712944333917
Epoch 6/100: Training Loss: 0.0033645460147731353
Epoch 7/100: Training Loss: 0.002566871066756596
Epoch 8/100: Training Loss: 0.002187416253500427
Epoch 9/100: Training Loss: 0.003560472797873794
Epoch 10/100: Training Loss: 0.0019391581712179626
Epoch 11/100: Training Loss: 0.0026849141184067883
Epoch 12/100: Training Loss: 0.0018007086207535094
Epoch 13/100: Training Loss: 0.002180165210307039
Epoch 14/100: Training Loss: 0.003250561013127005
Epoch 15/100: Training Loss: 0.003208790196488235
Epoch 16/100: Training Loss: 0.0022287976662844224
Epoch 17/100: Training Loss: 0.0019268089572325447
Epoch 18/100: Training Loss: 0.002485075139052031
Epoch 19/100: Training Loss: 0.0021878255913589176
Epoch 20/100: Training Loss: 0.0020147317292674486
Epoch 21/100: Training Loss: 0.002251063356336379
Epoch 22/100: Training Loss: 0.0020101861843210183
Epoch 23/100: Training Loss: 0.0021144341159340563
Epoch 24/100: Training Loss: 0.0021112584909855924
Epoch 25/100: Training Loss: 0.0018111094339004416
Epoch 26/100: Training Loss: 0.0017760940734913807
Epoch 27/100: Training Loss: 0.0020966066035213848
Epoch 28/100: Training Loss: 0.0016631896527397711
Epoch 29/100: Training Loss: 0.0017182957257656072
Epoch 30/100: Training Loss: 0.0017626786863567023
Epoch 31/100: Training Loss: 0.0022004507235343883
Epoch 32/100: Training Loss: 0.0017667570650972278
Epoch 33/100: Training Loss: 0.00264657668720018
Epoch 34/100: Training Loss: 0.00169711456393564
Epoch 35/100: Training Loss: 0.0017511840687682296
Epoch 36/100: Training Loss: 0.0015680701132641723
Epoch 37/100: Training Loss: 0.0013455654809017056
Epoch 38/100: Training Loss: 0.0015982419055029257
Epoch 39/100: Training Loss: 0.0015153209894698187
Epoch 40/100: Training Loss: 0.0014659634094364596
Epoch 41/100: Training Loss: 0.0015371259277230068
Epoch 42/100: Training Loss: 0.001748547846118346
Epoch 43/100: Training Loss: 0.0015524466898267633
Epoch 44/100: Training Loss: 0.001379969400285885
Epoch 45/100: Training Loss: 0.0015802596578534866
Epoch 46/100: Training Loss: 0.001545589491231552
Epoch 47/100: Training Loss: 0.0014126689623523232
Epoch 48/100: Training Loss: 0.0014768752041241981
Epoch 49/100: Training Loss: 0.0014942668329011525
Epoch 50/100: Training Loss: 0.0012147254896479726
Epoch 51/100: Training Loss: 0.001562658425987951
Epoch 52/100: Training Loss: 0.0013806039331764575
Epoch 53/100: Training Loss: 0.0013212705684813443
Epoch 54/100: Training Loss: 0.0010238968773393442
Epoch 55/100: Training Loss: 0.0008897758674937369
Epoch 56/100: Training Loss: 0.0012919828789123636
Epoch 57/100: Training Loss: 0.0009693342526227433
Epoch 58/100: Training Loss: 0.0009713877510550796
Epoch 59/100: Training Loss: 0.0012193675467510098
Epoch 60/100: Training Loss: 0.0014352832014197544
Epoch 61/100: Training Loss: 0.0009928809491214373
Epoch 62/100: Training Loss: 0.000994342447116675
Epoch 63/100: Training Loss: 0.0009818440241529452
Epoch 64/100: Training Loss: 0.0008937297080526289
Epoch 65/100: Training Loss: 0.0011639200298991423
Epoch 66/100: Training Loss: 0.0005714301735360102
Epoch 67/100: Training Loss: 0.0013275800753902915
Epoch 68/100: Training Loss: 0.0010423275413892128
Epoch 69/100: Training Loss: 0.0008135313131161873
Epoch 70/100: Training Loss: 0.000920389365676223
Epoch 71/100: Training Loss: 0.001046044048884057
Epoch 72/100: Training Loss: 0.0008656290785366336
Epoch 73/100: Training Loss: 0.0008560698356060003
Epoch 74/100: Training Loss: 0.0010502710445037741
Epoch 75/100: Training Loss: 0.0018241279172581553
Epoch 76/100: Training Loss: 0.0009015490677183038
Epoch 77/100: Training Loss: 0.000880403629201927
Epoch 78/100: Training Loss: 0.0010655173008015614
Epoch 79/100: Training Loss: 0.001002617229689036
Epoch 80/100: Training Loss: 0.0009972273513970786
Epoch 81/100: Training Loss: 0.0011300673547959485
Epoch 82/100: Training Loss: 0.000821513549381534
Epoch 83/100: Training Loss: 0.000836458821959843
Epoch 84/100: Training Loss: 0.0011917854973811978
Epoch 85/100: Training Loss: 0.0011458659408897754
Epoch 86/100: Training Loss: 0.0010718806887304547
Epoch 87/100: Training Loss: 0.0009582133482623574
Epoch 88/100: Training Loss: 0.0010497706220639461
Epoch 89/100: Training Loss: 0.0010890055768537205
Epoch 90/100: Training Loss: 0.0010464440118398098
Epoch 91/100: Training Loss: 0.0007977182699355069
Epoch 92/100: Training Loss: 0.0009305400169448347
Epoch 93/100: Training Loss: 0.0010945044013838106
Epoch 94/100: Training Loss: 0.0013200125552171114
Epoch 95/100: Training Loss: 0.0009628086295348919
Epoch 96/100: Training Loss: 0.0008259435856579155
Epoch 97/100: Training Loss: 0.0011794254282452414
Epoch 98/100: Training Loss: 0.0010799917558960567
Epoch 99/100: Training Loss: 0.0008723782190423928
Epoch 0/100: Training Loss: 0.0036422235286788433
Epoch 1/100: Training Loss: 0.0030368069149800483
Epoch 2/100: Training Loss: 0.003485828045977662
Epoch 3/100: Training Loss: 0.0036455061262017055
Epoch 4/100: Training Loss: 0.0026210459652325963
Epoch 5/100: Training Loss: 0.003095021311021009
Epoch 6/100: Training Loss: 0.0031210389358318404
Epoch 7/100: Training Loss: 0.00289540042150889
Epoch 8/100: Training Loss: 0.003048042587886583
Epoch 9/100: Training Loss: 0.002335119918482193
Epoch 10/100: Training Loss: 0.0021655683880610183
Epoch 11/100: Training Loss: 0.0022420928572976827
Epoch 12/100: Training Loss: 0.0035532776093640866
Epoch 13/100: Training Loss: 0.0030639258441546107
Epoch 14/100: Training Loss: 0.0024540988814751833
Epoch 15/100: Training Loss: 0.0022575602626168966
Epoch 16/100: Training Loss: 0.0023306233203963726
Epoch 17/100: Training Loss: 0.00215034137498464
Epoch 18/100: Training Loss: 0.0026724164849085525
Epoch 19/100: Training Loss: 0.0024476911847954555
Epoch 20/100: Training Loss: 0.002497324485652494
Epoch 21/100: Training Loss: 0.0018846266317051768
Epoch 22/100: Training Loss: 0.0022240782415630014
Epoch 23/100: Training Loss: 0.0017198754462185285
Epoch 24/100: Training Loss: 0.0016831729980494013
Epoch 25/100: Training Loss: 0.0018015817695895568
Epoch 26/100: Training Loss: 0.0017804633702663396
Epoch 27/100: Training Loss: 0.0018009284868935086
Epoch 28/100: Training Loss: 0.0017522703732875799
Epoch 29/100: Training Loss: 0.0017212481293457232
Epoch 30/100: Training Loss: 0.001485974583404743
Epoch 31/100: Training Loss: 0.0018502659355567781
Epoch 32/100: Training Loss: 0.0017418788363601989
Epoch 33/100: Training Loss: 0.0014255348815033768
Epoch 34/100: Training Loss: 0.001368403434753418
Epoch 35/100: Training Loss: 0.0012852138044028882
Epoch 36/100: Training Loss: 0.0014790094254032665
Epoch 37/100: Training Loss: 0.0015502194103026233
Epoch 38/100: Training Loss: 0.0014578296451379133
Epoch 39/100: Training Loss: 0.0012311907793512407
Epoch 40/100: Training Loss: 0.001450632976380405
Epoch 41/100: Training Loss: 0.0013620443888847401
Epoch 42/100: Training Loss: 0.0013949707249142477
Epoch 43/100: Training Loss: 0.0014333503925247698
Epoch 44/100: Training Loss: 0.0013361007764639444
Epoch 45/100: Training Loss: 0.0012916361061942499
Epoch 46/100: Training Loss: 0.0011641171002230108
Epoch 47/100: Training Loss: 0.0010173111561907837
Epoch 48/100: Training Loss: 0.0011883200399133544
Epoch 49/100: Training Loss: 0.0012514826083025396
Epoch 50/100: Training Loss: 0.0011815736625368231
Epoch 51/100: Training Loss: 0.0013778345869076961
Epoch 52/100: Training Loss: 0.0012360108609231102
Epoch 53/100: Training Loss: 0.0011331029483024647
Epoch 54/100: Training Loss: 0.001196659163923453
Epoch 55/100: Training Loss: 0.001326379298374353
Epoch 56/100: Training Loss: 0.0010783052602351107
Epoch 57/100: Training Loss: 0.0013152076708559958
Epoch 58/100: Training Loss: 0.001146310113913176
Epoch 59/100: Training Loss: 0.0011649757426306113
Epoch 60/100: Training Loss: 0.0011066602950064552
Epoch 61/100: Training Loss: 0.0011374579360153502
Epoch 62/100: Training Loss: 0.0011283480963170133
Epoch 63/100: Training Loss: 0.0012615617142607834
Epoch 64/100: Training Loss: 0.0012760060709833309
Epoch 65/100: Training Loss: 0.0011436526743781488
Epoch 66/100: Training Loss: 0.0009191475364546112
Epoch 67/100: Training Loss: 0.0010143350686458562
Epoch 68/100: Training Loss: 0.0011120902386722185
Epoch 69/100: Training Loss: 0.0011925843377776494
Epoch 70/100: Training Loss: 0.0009002197065100764
Epoch 71/100: Training Loss: 0.0009772777557373047
Epoch 72/100: Training Loss: 0.0012557181893595008
Epoch 73/100: Training Loss: 0.0010616536566753262
Epoch 74/100: Training Loss: 0.0012080306248949063
Epoch 75/100: Training Loss: 0.0013483949252311757
Epoch 76/100: Training Loss: 0.0009183335975305924
Epoch 77/100: Training Loss: 0.0009258077634091409
Epoch 78/100: Training Loss: 0.0009696315850643133
Epoch 79/100: Training Loss: 0.0007361853556917203
Epoch 80/100: Training Loss: 0.0010905795736818125
Epoch 81/100: Training Loss: 0.0013755737551000733
Epoch 82/100: Training Loss: 0.0009483132536048131
Epoch 83/100: Training Loss: 0.001010963853621325
Epoch 84/100: Training Loss: 0.0008026563765986866
Epoch 85/100: Training Loss: 0.0008777936562797092
Epoch 86/100: Training Loss: 0.0009296907494399722
Epoch 87/100: Training Loss: 0.0008077415212100705
Epoch 88/100: Training Loss: 0.0006004305470068723
Epoch 89/100: Training Loss: 0.0006581053433828796
Epoch 90/100: Training Loss: 0.00038795863950489374
Epoch 91/100: Training Loss: 0.00046775248271740033
Epoch 92/100: Training Loss: 0.0007866476940003452
Epoch 93/100: Training Loss: 0.0012487466169508877
Epoch 94/100: Training Loss: 0.00082307540817766
Epoch 95/100: Training Loss: 0.0007351887048475
Epoch 96/100: Training Loss: 0.0006794292011008357
Epoch 97/100: Training Loss: 0.0006324745566639679
Epoch 98/100: Training Loss: 0.0006191569645673234
Epoch 99/100: Training Loss: 0.0006444471956088843
Epoch 0/100: Training Loss: 0.004119172001516582
Epoch 1/100: Training Loss: 0.0032344180227115455
Epoch 2/100: Training Loss: 0.0032199386334577145
Epoch 3/100: Training Loss: 0.003708586392813171
Epoch 4/100: Training Loss: 0.003098813113787316
Epoch 5/100: Training Loss: 0.003313576148835239
Epoch 6/100: Training Loss: 0.003678993673514057
Epoch 7/100: Training Loss: 0.003183341578931998
Epoch 8/100: Training Loss: 0.003411403554954276
Epoch 9/100: Training Loss: 0.0029778535792369717
Epoch 10/100: Training Loss: 0.0031391248008273294
Epoch 11/100: Training Loss: 0.0033999113057622847
Epoch 12/100: Training Loss: 0.0029289765863229106
Epoch 13/100: Training Loss: 0.0030828639371505637
Epoch 14/100: Training Loss: 0.0026248077683101428
Epoch 15/100: Training Loss: 0.0028748387927251145
Epoch 16/100: Training Loss: 0.0025375560419448953
Epoch 17/100: Training Loss: 0.0021753808520487603
Epoch 18/100: Training Loss: 0.002322592482661569
Epoch 19/100: Training Loss: 0.002457526543282515
Epoch 20/100: Training Loss: 0.002122066668327281
Epoch 21/100: Training Loss: 0.0024383289135055035
Epoch 22/100: Training Loss: 0.0015734203209150706
Epoch 23/100: Training Loss: 0.0015228039381519848
Epoch 24/100: Training Loss: 0.0014185810720683722
Epoch 25/100: Training Loss: 0.002366306765979489
Epoch 26/100: Training Loss: 0.0018667949745986635
Epoch 27/100: Training Loss: 0.002072778758623742
Epoch 28/100: Training Loss: 0.0023019104603900025
Epoch 29/100: Training Loss: 0.0017613906734037083
Epoch 30/100: Training Loss: 0.0014651249970821355
Epoch 31/100: Training Loss: 0.0022515022991508836
Epoch 32/100: Training Loss: 0.0018560219284714451
Epoch 33/100: Training Loss: 0.0019376617393746282
Epoch 34/100: Training Loss: 0.0018426947641056895
Epoch 35/100: Training Loss: 0.0016336827878130982
Epoch 36/100: Training Loss: 0.0016790340278322333
Epoch 37/100: Training Loss: 0.0018106225310571937
Epoch 38/100: Training Loss: 0.0017505734172088422
Epoch 39/100: Training Loss: 0.0019317630505719721
Epoch 40/100: Training Loss: 0.0015847363219355906
Epoch 41/100: Training Loss: 0.0016419461231358004
Epoch 42/100: Training Loss: 0.001482309489850177
Epoch 43/100: Training Loss: 0.0016661835032583073
Epoch 44/100: Training Loss: 0.0013463337295102757
Epoch 45/100: Training Loss: 0.001250208608362059
Epoch 46/100: Training Loss: 0.00151979232465984
Epoch 47/100: Training Loss: 0.001413695662226898
Epoch 48/100: Training Loss: 0.0014094321538280967
Epoch 49/100: Training Loss: 0.001265983905223821
Epoch 50/100: Training Loss: 0.0012120351886117694
