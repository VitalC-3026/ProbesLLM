2024-04-23 03:40:45.189185: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-23 03:40:47.279130: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Epoch 0/100: Training Loss: 0.0029755895371203654
Epoch 1/100: Training Loss: 0.0025394219201761528
Epoch 2/100: Training Loss: 0.0021950573354334265
Epoch 3/100: Training Loss: 0.003002867623642608
Epoch 4/100: Training Loss: 0.0016690256087096421
Epoch 5/100: Training Loss: 0.002139273431751278
Epoch 6/100: Training Loss: 0.0026183399287137117
Epoch 7/100: Training Loss: 0.0030446463114731795
Epoch 8/100: Training Loss: 0.0035162876535962512
Epoch 9/100: Training Loss: 0.001650624029286258
Epoch 10/100: Training Loss: 0.0018653657052900407
Epoch 11/100: Training Loss: 0.002397180020392358
Epoch 12/100: Training Loss: 0.002147382372742766
Epoch 13/100: Training Loss: 0.003932278473060448
Epoch 14/100: Training Loss: 0.004421491722960572
Epoch 15/100: Training Loss: 0.0027318227958012292
Epoch 16/100: Training Loss: 0.0020523629822097457
Epoch 17/100: Training Loss: 0.0027118958793320024
Epoch 18/100: Training Loss: 0.0010269593734007615
Epoch 19/100: Training Loss: 0.002496730614375401
Epoch 20/100: Training Loss: 0.0020029063408191386
Epoch 21/100: Training Loss: 0.002573447627621097
Epoch 22/100: Training Loss: 0.0015211921263407994
Epoch 23/100: Training Loss: 0.002045986744073721
Epoch 24/100: Training Loss: 0.0015179503422517043
Epoch 25/100: Training Loss: 0.0021823315353660315
Epoch 26/100: Training Loss: 0.0016377725592859975
Epoch 27/100: Training Loss: 0.0007645360656551548
Epoch 28/100: Training Loss: 0.0008357192773919005
Epoch 29/100: Training Loss: 0.0005749029504669296
Epoch 30/100: Training Loss: 0.0012865122798439506
Epoch 31/100: Training Loss: 0.0009655982672751366
Epoch 32/100: Training Loss: 0.0005195365919099821
Epoch 33/100: Training Loss: 0.0007930883056633956
Epoch 34/100: Training Loss: 0.000950468691078933
Epoch 35/100: Training Loss: 0.0005563680942241962
Epoch 36/100: Training Loss: 0.0005717773016516145
Epoch 37/100: Training Loss: 0.000398719826569924
Epoch 38/100: Training Loss: 0.0005666279084198958
Epoch 39/100: Training Loss: 0.0008682103215397654
Epoch 40/100: Training Loss: 0.0009137559812385719
Epoch 41/100: Training Loss: 0.000669189162187643
Epoch 42/100: Training Loss: 0.0005014434040009559
Epoch 43/100: Training Loss: 0.0005581192411742844
Epoch 44/100: Training Loss: 0.0007061262751792694
Epoch 45/100: Training Loss: 0.0006011966225150582
Epoch 46/100: Training Loss: 0.0003890076821500605
Epoch 47/100: Training Loss: 0.0010563939601391345
Epoch 48/100: Training Loss: 0.0005502456968480891
Epoch 49/100: Training Loss: 0.0005742321898053576
Epoch 50/100: Training Loss: 0.0006438683900799784
Epoch 51/100: Training Loss: 0.0010110312825316317
Epoch 52/100: Training Loss: 0.0006033752139631684
Epoch 53/100: Training Loss: 0.00047140672698721186
Epoch 54/100: Training Loss: 0.0006593662229451266
Epoch 55/100: Training Loss: 0.0004603438652478732
Epoch 56/100: Training Loss: 0.0005550912835381248
Epoch 57/100: Training Loss: 0.0004368553888964486
Epoch 58/100: Training Loss: 0.0005505143345652761
Epoch 59/100: Training Loss: 0.0005281204943890338
Epoch 60/100: Training Loss: 0.0005443733367886576
Epoch 61/100: Training Loss: 0.0005201157052200158
Epoch 62/100: Training Loss: 0.000477735604439582
Epoch 63/100: Training Loss: 0.0003941352707105917
Epoch 64/100: Training Loss: 0.0002732372002584951
Epoch 65/100: Training Loss: 0.0004933093498636793
Epoch 66/100: Training Loss: 0.0005357622891872913
Epoch 67/100: Training Loss: 0.00045940738457899826
Epoch 68/100: Training Loss: 0.0006090712609824601
Epoch 69/100: Training Loss: 0.0006939099280984252
Epoch 70/100: Training Loss: 0.00045626339587298304
Epoch 71/100: Training Loss: 0.000501025650467906
Epoch 72/100: Training Loss: 0.0008025063084555672
Epoch 73/100: Training Loss: 0.00094044177265434
Epoch 74/100: Training Loss: 0.00033219049235323924
Epoch 75/100: Training Loss: 0.0004145376957379855
Epoch 76/100: Training Loss: 0.00034841522574424744
Epoch 77/100: Training Loss: 0.00028426629992631765
Epoch 78/100: Training Loss: 0.0003404695723023448
Epoch 79/100: Training Loss: 0.0005568956786935979
Epoch 80/100: Training Loss: 0.0004032258387212153
Epoch 81/100: Training Loss: 0.00038958799380522507
Epoch 82/100: Training Loss: 0.0005197545344179326
Epoch 83/100: Training Loss: 0.0004319153152979337
Epoch 84/100: Training Loss: 0.00027319405983378006
Epoch 85/100: Training Loss: 0.0003310138997914908
Epoch 86/100: Training Loss: 0.00024625135364232366
Epoch 87/100: Training Loss: 0.00032086438544980296
Epoch 88/100: Training Loss: 0.00040612119686353454
Epoch 89/100: Training Loss: 0.0004948419811842325
Epoch 90/100: Training Loss: 0.0003778525478356368
Epoch 91/100: Training Loss: 0.0003802316276343552
Epoch 92/100: Training Loss: 0.00038932349819403427
Epoch 93/100: Training Loss: 0.00024072109506680415
Epoch 94/100: Training Loss: 0.0009333593445224362
Epoch 95/100: Training Loss: 0.00040684549229128377
Epoch 96/100: Training Loss: 0.00032182452040952403
Epoch 97/100: Training Loss: 0.00020416196878556605
Epoch 98/100: Training Loss: 0.0003315705571558092
Epoch 99/100: Training Loss: 0.0002503684246456706
Epoch 0/100: Training Loss: 0.003145015323078716
Epoch 1/100: Training Loss: 0.0020720933700774935
Epoch 2/100: Training Loss: 0.0021520215314585014
Epoch 3/100: Training Loss: 0.0023930281192272693
Epoch 4/100: Training Loss: 0.0025722909640598962
Epoch 5/100: Training Loss: 0.0028495188359614018
Epoch 6/100: Training Loss: 0.002790760327052403
Epoch 7/100: Training Loss: 0.0026725782797886776
Epoch 8/100: Training Loss: 0.002091930045948162
Epoch 9/100: Training Loss: 0.0016987878125864309
Epoch 10/100: Training Loss: 0.0029202089026257707
Epoch 11/100: Training Loss: 0.003761333602291721
Epoch 12/100: Training Loss: 0.0025818206213570976
Epoch 13/100: Training Loss: 0.0019662661569101827
Epoch 14/100: Training Loss: 0.0018798131625969094
Epoch 15/100: Training Loss: 0.0022201396368600273
Epoch 16/100: Training Loss: 0.003268079741017802
Epoch 17/100: Training Loss: 0.0024203666440256824
Epoch 18/100: Training Loss: 0.0015162089904705127
Epoch 19/100: Training Loss: 0.002119666838145756
Epoch 20/100: Training Loss: 0.0018422759913064384
Epoch 21/100: Training Loss: 0.003253263610226291
Epoch 22/100: Training Loss: 0.001128692831192817
Epoch 23/100: Training Loss: 0.0013448131251168418
Epoch 24/100: Training Loss: 0.0020120598219491386
Epoch 25/100: Training Loss: 0.0012194670580483818
Epoch 26/100: Training Loss: 0.0008764852593828749
Epoch 27/100: Training Loss: 0.0020104061056683948
Epoch 28/100: Training Loss: 0.0006688656090022801
Epoch 29/100: Training Loss: 0.001616893635763155
Epoch 30/100: Training Loss: 0.0012023274923537994
Epoch 31/100: Training Loss: 0.000880210132865639
Epoch 32/100: Training Loss: 0.0007800158191394139
Epoch 33/100: Training Loss: 0.0011399618603966453
Epoch 34/100: Training Loss: 0.0009321137950136945
Epoch 35/100: Training Loss: 0.000813344141820094
Epoch 36/100: Training Loss: 0.0008140686196047109
Epoch 37/100: Training Loss: 0.0008722374906073084
Epoch 38/100: Training Loss: 0.0008337491979965797
Epoch 39/100: Training Loss: 0.0006536377164033743
Epoch 40/100: Training Loss: 0.0004885461884778697
Epoch 41/100: Training Loss: 0.0005576715290129601
Epoch 42/100: Training Loss: 0.0007967144980297222
Epoch 43/100: Training Loss: 0.0005669588600838934
Epoch 44/100: Training Loss: 0.0003895027028930771
Epoch 45/100: Training Loss: 0.0013748093710079059
Epoch 46/100: Training Loss: 0.0010320527570230977
Epoch 47/100: Training Loss: 0.0003914261510322144
Epoch 48/100: Training Loss: 0.0006675475335621334
Epoch 49/100: Training Loss: 0.0005314415255626598
Epoch 50/100: Training Loss: 0.0006886885820568858
Epoch 51/100: Training Loss: 0.0004188638258647252
Epoch 52/100: Training Loss: 0.0005510239959596754
Epoch 53/100: Training Loss: 0.00048117204145951706
Epoch 54/100: Training Loss: 0.0008186253009142575
Epoch 55/100: Training Loss: 0.0004852090577979188
Epoch 56/100: Training Loss: 0.0007948796753283147
Epoch 57/100: Training Loss: 0.0004611687435136808
Epoch 58/100: Training Loss: 0.0003986640253683904
Epoch 59/100: Training Loss: 0.0003906536612894152
Epoch 60/100: Training Loss: 0.0004988743083460347
Epoch 61/100: Training Loss: 0.0004314231341118579
Epoch 62/100: Training Loss: 0.0005845254534608001
Epoch 63/100: Training Loss: 0.000498747387966076
Epoch 64/100: Training Loss: 0.0003138252540485009
Epoch 65/100: Training Loss: 0.00047728841329787994
Epoch 66/100: Training Loss: 0.0006264721180175568
Epoch 67/100: Training Loss: 0.0003891103490666076
Epoch 68/100: Training Loss: 0.0005572453349620313
Epoch 69/100: Training Loss: 0.0004494956635928654
Epoch 70/100: Training Loss: 0.0004252054943488194
Epoch 71/100: Training Loss: 0.000329208879412471
Epoch 72/100: Training Loss: 0.00031196844431903814
Epoch 73/100: Training Loss: 0.00045885354072063955
Epoch 74/100: Training Loss: 0.0005043913851251135
Epoch 75/100: Training Loss: 0.0005139174473869217
Epoch 76/100: Training Loss: 0.00035081175970030833
Epoch 77/100: Training Loss: 0.0002732881299265615
Epoch 78/100: Training Loss: 0.00026241392939240784
Epoch 79/100: Training Loss: 0.00022394697253520673
Epoch 80/100: Training Loss: 0.00021682848984544927
Epoch 81/100: Training Loss: 0.00044499910794771637
Epoch 82/100: Training Loss: 0.0002586414607671591
Epoch 83/100: Training Loss: 0.00045232625899614985
Epoch 84/100: Training Loss: 0.00019379042193189367
Epoch 85/100: Training Loss: 0.0006300764275597526
Epoch 86/100: Training Loss: 0.0003275776190774424
Epoch 87/100: Training Loss: 0.0003260765875969733
Epoch 88/100: Training Loss: 0.0001988992277350459
Epoch 89/100: Training Loss: 0.0002146596805407451
Epoch 90/100: Training Loss: 0.0001897023196195389
Epoch 91/100: Training Loss: 0.00019153965624062332
Epoch 92/100: Training Loss: 0.0002456740117990054
Epoch 93/100: Training Loss: 0.0002677105627693496
Epoch 94/100: Training Loss: 0.00030668392464831156
Epoch 95/100: Training Loss: 0.000239154988235527
Epoch 96/100: Training Loss: 0.000403916997300995
Epoch 97/100: Training Loss: 0.0008237186845365937
Epoch 98/100: Training Loss: 0.0002658893647310617
Epoch 99/100: Training Loss: 0.0002949170611955069
Epoch 0/100: Training Loss: 0.0024079332401702454
Epoch 1/100: Training Loss: 0.002474994509370177
Epoch 2/100: Training Loss: 0.0022642574943862593
Epoch 3/100: Training Loss: 0.003033257239348405
Epoch 4/100: Training Loss: 0.0016940608099623993
Epoch 5/100: Training Loss: 0.001444828468602854
Epoch 6/100: Training Loss: 0.002079334292378459
Epoch 7/100: Training Loss: 0.0020600880359436247
Epoch 8/100: Training Loss: 0.0026097310172927962
Epoch 9/100: Training Loss: 0.0022901252849952323
Epoch 10/100: Training Loss: 0.002114512078411929
Epoch 11/100: Training Loss: 0.002353101968765259
Epoch 12/100: Training Loss: 0.004050573268970409
Epoch 13/100: Training Loss: 0.0013271669199416687
Epoch 14/100: Training Loss: 0.003136011270376352
Epoch 15/100: Training Loss: 0.003150927853751016
Epoch 16/100: Training Loss: 0.0033914105041877372
Epoch 17/100: Training Loss: 0.0010575667753086224
Epoch 18/100: Training Loss: 0.002347461201927879
Epoch 19/100: Training Loss: 0.001621292083413451
Epoch 20/100: Training Loss: 0.0017113235446956608
Epoch 21/100: Training Loss: 0.0025447594535934343
Epoch 22/100: Training Loss: 0.0018768523122880843
Epoch 23/100: Training Loss: 0.0014469324500410708
Epoch 24/100: Training Loss: 0.0012136235103740558
Epoch 25/100: Training Loss: 0.0016039747458237868
Epoch 26/100: Training Loss: 0.0009289348458910322
Epoch 27/100: Training Loss: 0.0009297790018828599
Epoch 28/100: Training Loss: 0.0008618854559384859
Epoch 29/100: Training Loss: 0.0012271378215376314
Epoch 30/100: Training Loss: 0.0010816429878448273
Epoch 31/100: Training Loss: 0.0010283672726237691
Epoch 32/100: Training Loss: 0.0008567830586766863
Epoch 33/100: Training Loss: 0.0009373669232521858
Epoch 34/100: Training Loss: 0.0005381281350876068
Epoch 35/100: Training Loss: 0.0007948492998843427
Epoch 36/100: Training Loss: 0.0006014173785289684
Epoch 37/100: Training Loss: 0.000612925191025634
Epoch 38/100: Training Loss: 0.001357720448420598
Epoch 39/100: Training Loss: 0.0004477626481256285
Epoch 40/100: Training Loss: 0.0006879000709607051
Epoch 41/100: Training Loss: 0.0009437324283839939
Epoch 42/100: Training Loss: 0.000637571972150069
Epoch 43/100: Training Loss: 0.0005346113568419343
Epoch 44/100: Training Loss: 0.0007184254122780754
Epoch 45/100: Training Loss: 0.000544471236375662
Epoch 46/100: Training Loss: 0.000367929755182533
Epoch 47/100: Training Loss: 0.0010463887161308236
Epoch 48/100: Training Loss: 0.0004842726292310061
Epoch 49/100: Training Loss: 0.0005790778285973555
Epoch 50/100: Training Loss: 0.000420447438955307
Epoch 51/100: Training Loss: 0.0005338782301315895
Epoch 52/100: Training Loss: 0.0004631426263522435
Epoch 53/100: Training Loss: 0.0005876774658689966
Epoch 54/100: Training Loss: 0.00018608972586535075
Epoch 55/100: Training Loss: 0.00040833506134006526
Epoch 56/100: Training Loss: 0.0006641034896557147
Epoch 57/100: Training Loss: 0.00045596037086073334
Epoch 58/100: Training Loss: 0.0005054857868414659
Epoch 59/100: Training Loss: 0.00033322997860141566
Epoch 60/100: Training Loss: 0.0004843135292713459
Epoch 61/100: Training Loss: 0.0005661946806040677
Epoch 62/100: Training Loss: 0.00041844208653156576
Epoch 63/100: Training Loss: 0.0005385863718452987
Epoch 64/100: Training Loss: 0.0004488276643352909
Epoch 65/100: Training Loss: 0.0004740697103780466
Epoch 66/100: Training Loss: 0.00030699062284889755
Epoch 67/100: Training Loss: 0.00048441502389374313
Epoch 68/100: Training Loss: 0.00035035091784450556
Epoch 69/100: Training Loss: 0.0003743738561243444
Epoch 70/100: Training Loss: 0.0004722870417408176
Epoch 71/100: Training Loss: 0.0004970607953471738
Epoch 72/100: Training Loss: 0.0003730376752523276
Epoch 73/100: Training Loss: 0.000539781226144804
Epoch 74/100: Training Loss: 0.00032555887644941157
Epoch 75/100: Training Loss: 0.00013776541641958944
Epoch 76/100: Training Loss: 0.0002492283555594358
Epoch 77/100: Training Loss: 0.0003346231590200971
Epoch 78/100: Training Loss: 0.0002326112683419581
Epoch 79/100: Training Loss: 0.0007864771918817
Epoch 80/100: Training Loss: 0.0002661932233747069
Epoch 81/100: Training Loss: 0.00152004254864646
Epoch 82/100: Training Loss: 0.00041318567586945485
Epoch 83/100: Training Loss: 0.00023704449405203334
Epoch 84/100: Training Loss: 0.00026746815839013855
Epoch 85/100: Training Loss: 0.0004058349226321374
Epoch 86/100: Training Loss: 0.0005533256522425405
Epoch 87/100: Training Loss: 0.00038509961816814397
Epoch 88/100: Training Loss: 0.0005257239083310107
Epoch 89/100: Training Loss: 0.00032550172059686035
Epoch 90/100: Training Loss: 0.0005332614992048357
Epoch 91/100: Training Loss: 0.0004662660347831833
Epoch 92/100: Training Loss: 0.0004213573476234516
Epoch 93/100: Training Loss: 0.0004452417988877196
Epoch 94/100: Training Loss: 0.000497210953202281
Epoch 95/100: Training Loss: 0.00037241346769399577
Epoch 96/100: Training Loss: 0.0004059985488444775
Epoch 97/100: Training Loss: 0.00040064796388566076
Epoch 98/100: Training Loss: 0.0003587748412485723
Epoch 99/100: Training Loss: 0.00035668099364200674
Epoch 0/100: Training Loss: 0.0022206710525816934
Epoch 1/100: Training Loss: 0.0012746081213278273
Epoch 2/100: Training Loss: 0.0007776002759582426
Epoch 3/100: Training Loss: 0.0007911138922158926
Epoch 4/100: Training Loss: 0.0019256664565735799
Epoch 5/100: Training Loss: 0.0009253387070872301
Epoch 6/100: Training Loss: 0.0006809010187541049
Epoch 7/100: Training Loss: 0.0005598189366375742
Epoch 8/100: Training Loss: 0.00036332651150007187
Epoch 9/100: Training Loss: 0.000761667049369929
Epoch 10/100: Training Loss: 0.001003263643914205
Epoch 11/100: Training Loss: 0.0011465981876923263
Epoch 12/100: Training Loss: 0.001661054012965571
Epoch 13/100: Training Loss: 0.0016206890527456085
Epoch 14/100: Training Loss: 0.0012074675113876905
Epoch 15/100: Training Loss: 0.000719662595745976
Epoch 16/100: Training Loss: 0.0008354025201563455
Epoch 17/100: Training Loss: 0.0010972681221055106
Epoch 18/100: Training Loss: 0.0001795262646821379
Epoch 19/100: Training Loss: 0.00026397802438472677
Epoch 20/100: Training Loss: 0.0001179081005004286
Epoch 21/100: Training Loss: 0.00026645979906883706
Epoch 22/100: Training Loss: 0.00022578122882755257
Epoch 23/100: Training Loss: 3.481255215735523e-05
Epoch 24/100: Training Loss: 0.00020336755122875143
Epoch 25/100: Training Loss: 0.00020126740168208726
Epoch 26/100: Training Loss: 0.00021969949815170897
Epoch 27/100: Training Loss: 0.00018785660800758316
Epoch 28/100: Training Loss: 0.0007655912655994204
Epoch 29/100: Training Loss: 0.0006114290627233821
Epoch 30/100: Training Loss: 0.000562817955309628
Epoch 31/100: Training Loss: 0.00026419767938508576
Epoch 32/100: Training Loss: 0.000248244957872695
Epoch 33/100: Training Loss: 0.00020153653676524484
Epoch 34/100: Training Loss: 0.0001463935899039719
Epoch 35/100: Training Loss: 8.586674722974285e-05
Epoch 36/100: Training Loss: 4.48470015330183e-05
Epoch 37/100: Training Loss: 1.5660474773930625e-05
Epoch 38/100: Training Loss: 3.0224962857054786e-05
Epoch 39/100: Training Loss: 2.0192894638955958e-05
Epoch 40/100: Training Loss: 0.00023129424708752543
Epoch 41/100: Training Loss: 0.00018857245796297226
Epoch 42/100: Training Loss: 0.00015113931263517017
Epoch 43/100: Training Loss: 0.00032778072850835836
Epoch 44/100: Training Loss: 0.00018289672679330674
Epoch 45/100: Training Loss: 4.403503108883928e-06
Epoch 46/100: Training Loss: 0.0002885519589748851
Epoch 47/100: Training Loss: 0.00016917772819659461
Epoch 48/100: Training Loss: 0.00021627842465792697
Epoch 49/100: Training Loss: 0.00018532879284920137
Epoch 50/100: Training Loss: 6.706617841142818e-05
Epoch 51/100: Training Loss: 1.0519654152949164e-05
Epoch 52/100: Training Loss: 6.183947042270672e-05
Epoch 53/100: Training Loss: 0.00011648358834301767
Epoch 54/100: Training Loss: 3.784217591757423e-05
Epoch 55/100: Training Loss: 2.3148695372639257e-05
Epoch 56/100: Training Loss: 3.0711030393290374e-05
Epoch 57/100: Training Loss: 4.766257251241456e-05
Epoch 58/100: Training Loss: 2.3968259595403095e-06
Epoch 59/100: Training Loss: 1.687202116965882e-05
Epoch 60/100: Training Loss: 3.444426264499594e-05
Epoch 61/100: Training Loss: 9.76035885649956e-05
Epoch 62/100: Training Loss: 0.00013272968218004777
Epoch 63/100: Training Loss: 4.270487176425801e-06
Epoch 64/100: Training Loss: 0.0002027350746415144
Epoch 65/100: Training Loss: 1.3867580257584713e-05
Epoch 66/100: Training Loss: 0.00040171651935284853
Epoch 67/100: Training Loss: 2.361572650404064e-06
Epoch 68/100: Training Loss: 2.8771095112126114e-06
Epoch 69/100: Training Loss: 2.3890830907810686e-06
Epoch 70/100: Training Loss: 1.3496315369576764e-05
Epoch 71/100: Training Loss: 2.991600944860581e-06
Epoch 72/100: Training Loss: 2.1182907676678493e-05
Epoch 73/100: Training Loss: 5.372827786929403e-07
Epoch 74/100: Training Loss: 9.180821730659566e-08
Epoch 75/100: Training Loss: 5.3766749205033475e-05
Epoch 76/100: Training Loss: 1.493357036239896e-05
Epoch 77/100: Training Loss: 3.6863786556923683e-06
Epoch 78/100: Training Loss: 2.5291741108578955e-06
Epoch 79/100: Training Loss: 1.7593399067323633e-05
Epoch 80/100: Training Loss: 5.330743290986752e-06
Epoch 81/100: Training Loss: 1.2496494698092524e-06
Epoch 82/100: Training Loss: 2.7063484103676e-06
Epoch 83/100: Training Loss: 2.132562821890953e-06
Epoch 84/100: Training Loss: 5.984349259135365e-07
Epoch 85/100: Training Loss: 1.3236160692901698e-05
Epoch 86/100: Training Loss: 2.2552596163033206e-07
Epoch 87/100: Training Loss: 3.347806475393794e-06
Epoch 88/100: Training Loss: 1.7394547056452445e-07
Epoch 89/100: Training Loss: 3.064328247889808e-07
Epoch 90/100: Training Loss: 1.0887604418204972e-05
Epoch 91/100: Training Loss: 3.9380469410880215e-05
Epoch 92/100: Training Loss: 7.830606630654788e-06
Epoch 93/100: Training Loss: 1.4889783917303466e-05
Epoch 94/100: Training Loss: 5.767248182391828e-05
Epoch 95/100: Training Loss: 1.3415070509172382e-06
Epoch 96/100: Training Loss: 0.000166790719869678
Epoch 97/100: Training Loss: 2.3592400587409552e-06
Epoch 98/100: Training Loss: 0.0009031481355245859
Epoch 99/100: Training Loss: 6.264524157244736e-05
Epoch 0/100: Training Loss: 0.002127787086861265
Epoch 1/100: Training Loss: 0.0015088880171805071
Epoch 2/100: Training Loss: 0.0007243219968731418
Epoch 3/100: Training Loss: 0.0012426017069377781
Epoch 4/100: Training Loss: 0.0012209244483819036
Epoch 5/100: Training Loss: 0.0012477948073229175
Epoch 6/100: Training Loss: 0.0008248470129410913
Epoch 7/100: Training Loss: 0.0009590623203230782
Epoch 8/100: Training Loss: 0.0010036080161486666
Epoch 9/100: Training Loss: 0.0016814614731841292
Epoch 10/100: Training Loss: 0.001574454132033272
Epoch 11/100: Training Loss: 0.0013996592145755979
Epoch 12/100: Training Loss: 0.0013780501539721812
Epoch 13/100: Training Loss: 0.0006118847822850467
Epoch 14/100: Training Loss: 0.0008078285155852148
Epoch 15/100: Training Loss: 0.00040072234678853507
Epoch 16/100: Training Loss: 0.0005510301769145427
Epoch 17/100: Training Loss: 0.00020155290061710801
Epoch 18/100: Training Loss: 0.0008301189157860411
Epoch 19/100: Training Loss: 0.0003153255060772223
Epoch 20/100: Training Loss: 0.00027865374837916324
Epoch 21/100: Training Loss: 0.0002916049372199123
Epoch 22/100: Training Loss: 0.00031038042317870206
Epoch 23/100: Training Loss: 0.0002170011995394537
Epoch 24/100: Training Loss: 0.0003400769290382877
Epoch 25/100: Training Loss: 0.0002484584421467927
Epoch 26/100: Training Loss: 0.0002203106285969904
Epoch 27/100: Training Loss: 0.00014984551702906018
Epoch 28/100: Training Loss: 0.00023746328211269495
Epoch 29/100: Training Loss: 0.00021193032524337066
Epoch 30/100: Training Loss: 0.00022254609988510974
Epoch 31/100: Training Loss: 0.00030049306849029166
Epoch 32/100: Training Loss: 0.00020172074437141418
Epoch 33/100: Training Loss: 0.0004014554290683723
Epoch 34/100: Training Loss: 5.630307196656619e-05
Epoch 35/100: Training Loss: 1.5492852422997263e-05
Epoch 36/100: Training Loss: 6.25169704571092e-05
Epoch 37/100: Training Loss: 3.7262641162000184e-06
Epoch 38/100: Training Loss: 7.760708871657498e-06
Epoch 39/100: Training Loss: 0.00010996438745706359
Epoch 40/100: Training Loss: 5.511523001581613e-05
Epoch 41/100: Training Loss: 9.03737428455265e-05
Epoch 42/100: Training Loss: 1.3520282641784546e-05
Epoch 43/100: Training Loss: 2.8663003485809806e-05
Epoch 44/100: Training Loss: 0.00030300270286074446
Epoch 45/100: Training Loss: 5.320003084792681e-05
Epoch 46/100: Training Loss: 0.0001088736887358449
Epoch 47/100: Training Loss: 5.645746582307698e-05
Epoch 48/100: Training Loss: 2.9039852024038878e-05
Epoch 49/100: Training Loss: 0.0008426088314114904
Epoch 50/100: Training Loss: 0.0002187796714115728
Epoch 51/100: Training Loss: 0.0002954103098325203
Epoch 52/100: Training Loss: 0.0011145661762155638
Epoch 53/100: Training Loss: 0.0005874393816374563
Epoch 54/100: Training Loss: 0.00019522543790881618
Epoch 55/100: Training Loss: 0.00019988221076368555
Epoch 56/100: Training Loss: 0.00018389786999284123
Epoch 57/100: Training Loss: 0.0002069619764213913
Epoch 58/100: Training Loss: 0.00024590565840159457
Epoch 59/100: Training Loss: 7.99141732827286e-05
Epoch 60/100: Training Loss: 0.00021226843533340409
Epoch 61/100: Training Loss: 0.00015263594229894182
Epoch 62/100: Training Loss: 0.00032086642973262107
Epoch 63/100: Training Loss: 4.447010728570581e-05
Epoch 64/100: Training Loss: 0.00019612741525187815
Epoch 65/100: Training Loss: 1.8818482493787455e-05
Epoch 66/100: Training Loss: 7.812827939818973e-05
Epoch 67/100: Training Loss: 1.5865235755140065e-05
Epoch 68/100: Training Loss: 0.00013716277763521745
Epoch 69/100: Training Loss: 0.00014206255140480087
Epoch 70/100: Training Loss: 0.0001444982399055563
Epoch 71/100: Training Loss: 9.676266713010752e-05
Epoch 72/100: Training Loss: 3.0768221027097816e-05
Epoch 73/100: Training Loss: 1.6546469650294153e-05
Epoch 74/100: Training Loss: 7.790205371708957e-05
Epoch 75/100: Training Loss: 8.790100284743528e-06
Epoch 76/100: Training Loss: 8.57982993057352e-06
Epoch 77/100: Training Loss: 1.3452753184671782e-05
Epoch 78/100: Training Loss: 0.00012285135503561218
Epoch 79/100: Training Loss: 1.1459258642116208e-05
Epoch 80/100: Training Loss: 9.870885848496223e-06
Epoch 81/100: Training Loss: 7.514038374590362e-06
Epoch 82/100: Training Loss: 1.9406475215304667e-06
Epoch 83/100: Training Loss: 4.535865187187868e-06
Epoch 84/100: Training Loss: 9.200127189693275e-06
Epoch 85/100: Training Loss: 0.00012799986620987852
Epoch 86/100: Training Loss: 4.193718985088764e-05
Epoch 87/100: Training Loss: 2.4798536527490505e-06
Epoch 88/100: Training Loss: 2.9166980412291602e-05
Epoch 89/100: Training Loss: 5.77073571403608e-06
Epoch 90/100: Training Loss: 1.4619084726447709e-05
Epoch 91/100: Training Loss: 0.00010426781294536006
Epoch 92/100: Training Loss: 2.0629716351445466e-05
Epoch 93/100: Training Loss: 9.208160918205976e-07
Epoch 94/100: Training Loss: 1.4182583156093224e-06
Epoch 95/100: Training Loss: 3.2171592019224096e-06
Epoch 96/100: Training Loss: 0.0005299149115392767
Epoch 97/100: Training Loss: 0.00035622048597394324
Epoch 98/100: Training Loss: 6.3016542170676716e-06
Epoch 99/100: Training Loss: 9.284424024171259e-06
Epoch 0/100: Training Loss: 0.0023499871689849103
Epoch 1/100: Training Loss: 0.0014675576811187837
Epoch 2/100: Training Loss: 0.0009082520117788958
Epoch 3/100: Training Loss: 0.002493820307444941
Epoch 4/100: Training Loss: 0.0019764124981464784
Epoch 5/100: Training Loss: 0.0010334221314798834
Epoch 6/100: Training Loss: 0.0011514037664682587
Epoch 7/100: Training Loss: 0.0010916271641210544
Epoch 8/100: Training Loss: 0.0009178058501401562
Epoch 9/100: Training Loss: 0.0005151556313403544
Epoch 10/100: Training Loss: 0.0005067376637019994
Epoch 11/100: Training Loss: 0.0008511861409146362
Epoch 12/100: Training Loss: 0.0007355525815413773
Epoch 13/100: Training Loss: 0.0014335658469814465
Epoch 14/100: Training Loss: 0.001395321971068353
Epoch 15/100: Training Loss: 0.0015124496689603373
Epoch 16/100: Training Loss: 0.0009132374100889896
Epoch 17/100: Training Loss: 0.0013762148428548334
Epoch 18/100: Training Loss: 0.000594787391051193
Epoch 19/100: Training Loss: 0.0007089117279081988
Epoch 20/100: Training Loss: 0.00024446298831079635
Epoch 21/100: Training Loss: 0.0011021159360745203
Epoch 22/100: Training Loss: 0.0012462524000121042
Epoch 23/100: Training Loss: 0.0002271449136222067
Epoch 24/100: Training Loss: 0.00031434522907426753
Epoch 25/100: Training Loss: 0.00021871001076844573
Epoch 26/100: Training Loss: 0.00022017969492754322
Epoch 27/100: Training Loss: 0.0001756797653217257
Epoch 28/100: Training Loss: 0.000163489152774489
Epoch 29/100: Training Loss: 0.00017266086319838564
Epoch 30/100: Training Loss: 6.472790168106921e-05
Epoch 31/100: Training Loss: 0.0001374153660301782
Epoch 32/100: Training Loss: 3.001341264854911e-05
Epoch 33/100: Training Loss: 6.355788627285167e-05
Epoch 34/100: Training Loss: 0.00031274630248180927
Epoch 35/100: Training Loss: 0.00021756890635548924
Epoch 36/100: Training Loss: 0.00014912354205649323
Epoch 37/100: Training Loss: 4.929654368776485e-05
Epoch 38/100: Training Loss: 5.383194749889198e-05
Epoch 39/100: Training Loss: 0.00017135998268434606
Epoch 40/100: Training Loss: 0.0004382457561288143
Epoch 41/100: Training Loss: 0.0002780786824006976
Epoch 42/100: Training Loss: 0.00023154317875581285
Epoch 43/100: Training Loss: 0.00017144587005208606
Epoch 44/100: Training Loss: 0.00018615303046864236
Epoch 45/100: Training Loss: 0.0003101874394285167
Epoch 46/100: Training Loss: 0.00042153186410482675
Epoch 47/100: Training Loss: 0.00021471597391403525
Epoch 48/100: Training Loss: 0.0005176173854459283
Epoch 49/100: Training Loss: 0.00018758917558778283
Epoch 50/100: Training Loss: 0.00032836233088575257
Epoch 51/100: Training Loss: 0.00036699228857192527
Epoch 52/100: Training Loss: 0.00036409047026575707
Epoch 53/100: Training Loss: 0.00046347703304758833
Epoch 54/100: Training Loss: 0.0001644742063766608
Epoch 55/100: Training Loss: 0.00017181149701033633
Epoch 56/100: Training Loss: 0.00021519029707265047
Epoch 57/100: Training Loss: 2.0150887991296002e-05
Epoch 58/100: Training Loss: 4.176124416154586e-05
Epoch 59/100: Training Loss: 2.0457698429357605e-06
Epoch 60/100: Training Loss: 4.175610188966149e-05
Epoch 61/100: Training Loss: 7.352638029796215e-05
Epoch 62/100: Training Loss: 0.00022355432799257385
Epoch 63/100: Training Loss: 0.0003933571507594337
Epoch 64/100: Training Loss: 0.00023541284119424645
Epoch 65/100: Training Loss: 0.00016664257673032443
Epoch 66/100: Training Loss: 0.00013978357649653967
Epoch 67/100: Training Loss: 8.109641587076012e-05
Epoch 68/100: Training Loss: 0.0005185834469239404
Epoch 69/100: Training Loss: 0.00019883695829865392
Epoch 70/100: Training Loss: 2.3348382645589443e-05
Epoch 71/100: Training Loss: 1.6597675250991722e-05
Epoch 72/100: Training Loss: 6.168861902016072e-05
Epoch 73/100: Training Loss: 9.980942893979008e-05
Epoch 74/100: Training Loss: 0.0006036445772720992
Epoch 75/100: Training Loss: 0.00014579224120254167
Epoch 76/100: Training Loss: 1.0554579999354993e-06
Epoch 77/100: Training Loss: 9.17099264844612e-06
Epoch 78/100: Training Loss: 4.075093057715088e-05
Epoch 79/100: Training Loss: 1.0403181694767957e-05
Epoch 80/100: Training Loss: 1.7275118149039936e-05
Epoch 81/100: Training Loss: 3.050765282605872e-07
Epoch 82/100: Training Loss: 7.476106977398776e-06
Epoch 83/100: Training Loss: 0.00016731855693770333
Epoch 84/100: Training Loss: 8.483717298032315e-05
Epoch 85/100: Training Loss: 6.469735087244057e-05
Epoch 86/100: Training Loss: 6.643214200171956e-05
Epoch 87/100: Training Loss: 1.8818988150522753e-05
Epoch 88/100: Training Loss: 0.0002871824234175536
Epoch 89/100: Training Loss: 0.00032574681142356497
Epoch 90/100: Training Loss: 1.7342570472074433e-05
Epoch 91/100: Training Loss: 7.948679906641779e-05
Epoch 92/100: Training Loss: 4.358395099914147e-05
Epoch 93/100: Training Loss: 2.038228165563996e-05
Epoch 94/100: Training Loss: 6.21361557631382e-07
Epoch 95/100: Training Loss: 3.4870876947794956e-05
Epoch 96/100: Training Loss: 5.140720632361488e-05
Epoch 97/100: Training Loss: 1.0080470566414983e-05
Epoch 98/100: Training Loss: 3.3109820950662067e-06
Epoch 99/100: Training Loss: 0.00012969243928698674
Epoch 0/100: Training Loss: 0.0024596290662884713
Epoch 1/100: Training Loss: 0.0027001695707440376
Epoch 2/100: Training Loss: 0.002086051367223263
Epoch 3/100: Training Loss: 0.0019366616383194924
Epoch 4/100: Training Loss: 0.0010191529989242553
Epoch 5/100: Training Loss: 0.0007902610115706921
Epoch 6/100: Training Loss: 0.0006200938019901514
Epoch 7/100: Training Loss: 0.0011756971478462219
Epoch 8/100: Training Loss: 0.0010151383467018604
Epoch 9/100: Training Loss: 0.0007570367306470871
Epoch 10/100: Training Loss: 0.0010206525214016438
Epoch 11/100: Training Loss: 0.000584371155127883
Epoch 12/100: Training Loss: 0.0008759458549320697
Epoch 13/100: Training Loss: 0.0009143727831542492
Epoch 14/100: Training Loss: 0.0005599488969892264
Epoch 15/100: Training Loss: 0.0011679663322865963
Epoch 16/100: Training Loss: 0.0006514353211969137
Epoch 17/100: Training Loss: 0.0007616203743964434
Epoch 18/100: Training Loss: 0.0007126324344426394
Epoch 19/100: Training Loss: 0.0005465894006192684
Epoch 20/100: Training Loss: 0.0007698349189013242
Epoch 21/100: Training Loss: 0.00068955784663558
Epoch 22/100: Training Loss: 0.0005720719229429961
Epoch 23/100: Training Loss: 0.00045575574040412903
Epoch 24/100: Training Loss: 0.0003311581443995237
Epoch 25/100: Training Loss: 0.00029473162721842526
Epoch 26/100: Training Loss: 0.0007544205524027348
Epoch 27/100: Training Loss: 0.0004227918107062578
Epoch 28/100: Training Loss: 0.000427651172503829
Epoch 29/100: Training Loss: 0.0003125706221908331
Epoch 30/100: Training Loss: 0.00039097280241549013
Epoch 31/100: Training Loss: 0.0004387762863188982
Epoch 32/100: Training Loss: 0.0002966826781630516
Epoch 33/100: Training Loss: 0.0003917225170880556
Epoch 34/100: Training Loss: 0.0002009415766224265
Epoch 35/100: Training Loss: 0.00025971687864512205
Epoch 36/100: Training Loss: 0.0004240811336785555
Epoch 37/100: Training Loss: 0.00035341209731996057
Epoch 38/100: Training Loss: 0.00018259609350934625
Epoch 39/100: Training Loss: 0.0004148270469158888
Epoch 40/100: Training Loss: 0.0004644312895834446
Epoch 41/100: Training Loss: 0.00017769824480637909
Epoch 42/100: Training Loss: 0.0002248320262879133
Epoch 43/100: Training Loss: 6.566527299582958e-05
Epoch 44/100: Training Loss: 0.00020006911363452674
Epoch 45/100: Training Loss: 0.00010329462820664048
Epoch 46/100: Training Loss: 0.00010674309451133012
Epoch 47/100: Training Loss: 4.501130024436861e-05
Epoch 48/100: Training Loss: 0.0022069646045565607
Epoch 49/100: Training Loss: 0.0006995996925979852
Epoch 50/100: Training Loss: 4.339116567280144e-05
Epoch 51/100: Training Loss: 9.54403541982174e-05
Epoch 52/100: Training Loss: 8.710856782272458e-05
Epoch 53/100: Training Loss: 7.537306519225239e-05
Epoch 54/100: Training Loss: 8.30390490591526e-05
Epoch 55/100: Training Loss: 2.222458424512297e-05
Epoch 56/100: Training Loss: 3.2258269493468104e-05
Epoch 57/100: Training Loss: 3.888027567882091e-05
Epoch 58/100: Training Loss: 1.6866611258592456e-05
Epoch 59/100: Training Loss: 9.666442056186498e-05
Epoch 60/100: Training Loss: 8.614424586994573e-06
Epoch 61/100: Training Loss: 7.80851289164275e-05
Epoch 62/100: Training Loss: 3.936343637178652e-06
Epoch 63/100: Training Loss: 3.3476451790193094e-06
Epoch 64/100: Training Loss: 8.558104127587285e-07
Epoch 65/100: Training Loss: 5.847774809808471e-06
Epoch 66/100: Training Loss: 1.6701444110367447e-05
Epoch 67/100: Training Loss: 6.402451253961771e-06
Epoch 68/100: Training Loss: 5.416629846877186e-07
Epoch 69/100: Training Loss: 5.94190350966528e-07
Epoch 70/100: Training Loss: 1.4573042790289037e-06
Epoch 71/100: Training Loss: 4.117191201657988e-06
Epoch 72/100: Training Loss: 9.326620784122497e-06
Epoch 73/100: Training Loss: 3.561440507837688e-07
Epoch 74/100: Training Loss: 5.558261545957066e-06
Epoch 75/100: Training Loss: 1.4933983948139939e-06
Epoch 76/100: Training Loss: 1.5364983482868411e-06
Epoch 77/100: Training Loss: 1.4449598211285776e-07
Epoch 78/100: Training Loss: 3.2603963973087957e-07
Epoch 79/100: Training Loss: 4.206379817333073e-05
Epoch 80/100: Training Loss: 4.777804861078039e-06
Epoch 81/100: Training Loss: 8.665953714626084e-08
Epoch 82/100: Training Loss: 3.049053520953748e-06
Epoch 83/100: Training Loss: 2.509024052415043e-05
Epoch 84/100: Training Loss: 1.1496962542878464e-05
Epoch 85/100: Training Loss: 3.855053364532068e-06
Epoch 86/100: Training Loss: 9.806486923480407e-06
Epoch 87/100: Training Loss: 2.0508597663138063e-05
Epoch 88/100: Training Loss: 4.6539216782548463e-07
Epoch 89/100: Training Loss: 5.914299890719122e-07
Epoch 90/100: Training Loss: 2.2847123091196408e-07
Epoch 91/100: Training Loss: 1.4861894669593313e-06
Epoch 92/100: Training Loss: 2.4687974473636134e-07
Epoch 93/100: Training Loss: 5.361999342312629e-08
Epoch 94/100: Training Loss: 1.797653385438025e-06
Epoch 95/100: Training Loss: 3.1846644560573623e-06
Epoch 96/100: Training Loss: 1.064079606294399e-06
Epoch 97/100: Training Loss: 1.8943876057164743e-06
Epoch 98/100: Training Loss: 2.460312498442363e-06
Epoch 99/100: Training Loss: 1.9648268789751455e-06
Epoch 0/100: Training Loss: 0.002541716769337654
Epoch 1/100: Training Loss: 0.0017150359228253365
Epoch 2/100: Training Loss: 0.0014369949698448182
Epoch 3/100: Training Loss: 0.0013572650030255317
Epoch 4/100: Training Loss: 0.0015149141661822795
Epoch 5/100: Training Loss: 0.0009929032996296883
Epoch 6/100: Training Loss: 0.0009872195310890674
Epoch 7/100: Training Loss: 0.0012793129310011864
Epoch 8/100: Training Loss: 0.0008651994168758393
Epoch 9/100: Training Loss: 0.001032104529440403
Epoch 10/100: Training Loss: 0.0006969358772039413
Epoch 11/100: Training Loss: 0.0006325333379209042
Epoch 12/100: Training Loss: 0.0004882007371634245
Epoch 13/100: Training Loss: 0.0005792475305497647
Epoch 14/100: Training Loss: 0.0004635774064809084
Epoch 15/100: Training Loss: 0.0004911571741104126
Epoch 16/100: Training Loss: 0.0006719863507896662
Epoch 17/100: Training Loss: 0.0006570681929588318
Epoch 18/100: Training Loss: 0.0006352235097438097
Epoch 19/100: Training Loss: 0.0005499178078025579
Epoch 20/100: Training Loss: 0.0009509754367172718
Epoch 21/100: Training Loss: 0.0005373027175664902
Epoch 22/100: Training Loss: 0.000660774577409029
Epoch 23/100: Training Loss: 0.0006481994409114122
Epoch 24/100: Training Loss: 0.0005239417310804129
Epoch 25/100: Training Loss: 0.0006407937966287136
Epoch 26/100: Training Loss: 0.0004945368971675634
Epoch 27/100: Training Loss: 0.0003918513655662537
Epoch 28/100: Training Loss: 0.0003736739279702306
Epoch 29/100: Training Loss: 0.00027599488385021687
Epoch 30/100: Training Loss: 0.00030568160582333803
Epoch 31/100: Training Loss: 0.0003328882623463869
Epoch 32/100: Training Loss: 0.00034989379346370695
Epoch 33/100: Training Loss: 0.00023731582332402467
Epoch 34/100: Training Loss: 0.0003601473988965154
Epoch 35/100: Training Loss: 0.0003409188939258456
Epoch 36/100: Training Loss: 0.0002381983445957303
Epoch 37/100: Training Loss: 0.0002361965598538518
Epoch 38/100: Training Loss: 0.00027221080381423235
Epoch 39/100: Training Loss: 0.00041324957273900507
Epoch 40/100: Training Loss: 0.0002020575338974595
Epoch 41/100: Training Loss: 0.00027928694617003204
Epoch 42/100: Training Loss: 0.00014225757913663984
Epoch 43/100: Training Loss: 0.00012002649018540978
Epoch 44/100: Training Loss: 0.00012923193862661718
Epoch 45/100: Training Loss: 0.00022997199557721614
Epoch 46/100: Training Loss: 0.0001003914512693882
Epoch 47/100: Training Loss: 7.384638302028179e-05
Epoch 48/100: Training Loss: 0.00036715136375278237
Epoch 49/100: Training Loss: 5.589693901129067e-05
Epoch 50/100: Training Loss: 1.0818157898029313e-05
Epoch 51/100: Training Loss: 6.884752656333148e-05
Epoch 52/100: Training Loss: 7.99780071247369e-05
Epoch 53/100: Training Loss: 1.0968001879518851e-05
Epoch 54/100: Training Loss: 5.943482392467558e-06
Epoch 55/100: Training Loss: 1.9582463210099378e-06
Epoch 56/100: Training Loss: 0.000102797313593328
Epoch 57/100: Training Loss: 0.00019806574564427138
Epoch 58/100: Training Loss: 5.520034465007484e-05
Epoch 59/100: Training Loss: 2.6960455215885303e-06
Epoch 60/100: Training Loss: 2.6396382963866927e-06
Epoch 61/100: Training Loss: 3.0744220566703005e-06
Epoch 62/100: Training Loss: 1.0093993296322879e-06
Epoch 63/100: Training Loss: 4.839137545786798e-07
Epoch 64/100: Training Loss: 6.015448889229446e-07
Epoch 65/100: Training Loss: 0.0003689393401145935
Epoch 66/100: Training Loss: 3.371734928805381e-05
Epoch 67/100: Training Loss: 0.00021687201224267482
Epoch 68/100: Training Loss: 9.030279034050182e-06
Epoch 69/100: Training Loss: 2.202858740929514e-06
Epoch 70/100: Training Loss: 3.82591606467031e-06
Epoch 71/100: Training Loss: 4.98341159982374e-07
Epoch 72/100: Training Loss: 8.609386895841453e-07
Epoch 73/100: Training Loss: 0.0003902850206941366
Epoch 74/100: Training Loss: 0.0003054614411666989
Epoch 75/100: Training Loss: 3.144906659144908e-05
Epoch 76/100: Training Loss: 1.1409764738345984e-06
Epoch 77/100: Training Loss: 1.3402708282228559e-05
Epoch 78/100: Training Loss: 0.00019714361988008023
Epoch 79/100: Training Loss: 1.8701206499827094e-06
Epoch 80/100: Training Loss: 5.406042873801197e-07
Epoch 81/100: Training Loss: 4.5195894199423495e-05
Epoch 82/100: Training Loss: 3.407742769923061e-06
Epoch 83/100: Training Loss: 6.075810233596713e-07
Epoch 84/100: Training Loss: 5.493039680004585e-07
Epoch 85/100: Training Loss: 1.2122948646720034e-06
Epoch 86/100: Training Loss: 1.9025395158678293e-05
Epoch 87/100: Training Loss: 1.1006000022462104e-06
Epoch 88/100: Training Loss: 8.551747305318713e-05
Epoch 89/100: Training Loss: 3.820266101683956e-07
Epoch 90/100: Training Loss: 4.005540176876821e-06
Epoch 91/100: Training Loss: 4.251910286257043e-06
Epoch 92/100: Training Loss: 3.5290948289912192e-06
Epoch 93/100: Training Loss: 3.457827915553935e-06
Epoch 94/100: Training Loss: 7.516943151131273e-06
Epoch 95/100: Training Loss: 5.59196669200901e-06
Epoch 96/100: Training Loss: 3.32963652908802e-05
Epoch 97/100: Training Loss: 3.45834109793941e-07
Epoch 98/100: Training Loss: 1.1413879292376806e-06
Epoch 99/100: Training Loss: 2.758109440037515e-06
Epoch 0/100: Training Loss: 0.0023361433297395704
Epoch 1/100: Training Loss: 0.0016141746193170548
Epoch 2/100: Training Loss: 0.0015562077984213828
Epoch 3/100: Training Loss: 0.0009322455152869225
Epoch 4/100: Training Loss: 0.0009714074432849884
Epoch 5/100: Training Loss: 0.0006559582892805338
Epoch 6/100: Training Loss: 0.0005930238403379917
Epoch 7/100: Training Loss: 0.0007366858888417482
Epoch 8/100: Training Loss: 0.0005946735851466656
Epoch 9/100: Training Loss: 0.000592125067487359
Epoch 10/100: Training Loss: 0.0005848885979503393
Epoch 11/100: Training Loss: 0.000664799939841032
Epoch 12/100: Training Loss: 0.0006315300706773996
Epoch 13/100: Training Loss: 0.0006476226728409529
Epoch 14/100: Training Loss: 0.0004330468364059925
Epoch 15/100: Training Loss: 0.0004938490688800812
Epoch 16/100: Training Loss: 0.0005609046667814255
Epoch 17/100: Training Loss: 0.0004601377993822098
Epoch 18/100: Training Loss: 0.00041939252987504004
Epoch 19/100: Training Loss: 0.0004376519937068224
Epoch 20/100: Training Loss: 0.00044092149473726747
Epoch 21/100: Training Loss: 0.0004608267452567816
Epoch 22/100: Training Loss: 0.0007586207240819931
Epoch 23/100: Training Loss: 0.0004890908952802419
Epoch 24/100: Training Loss: 0.00041024438105523585
Epoch 25/100: Training Loss: 0.0006152474321424961
Epoch 26/100: Training Loss: 0.00046180500648915766
Epoch 27/100: Training Loss: 0.0005264195147901774
Epoch 28/100: Training Loss: 0.0004740841221064329
Epoch 29/100: Training Loss: 0.0005875407718122005
Epoch 30/100: Training Loss: 0.00043993345461785794
Epoch 31/100: Training Loss: 0.0002472991356626153
Epoch 32/100: Training Loss: 0.00047582508996129035
Epoch 33/100: Training Loss: 0.0003661356633529067
Epoch 34/100: Training Loss: 0.0005094437394291163
Epoch 35/100: Training Loss: 0.0003782663494348526
Epoch 36/100: Training Loss: 0.00038130227476358415
Epoch 37/100: Training Loss: 0.0007873551920056343
Epoch 38/100: Training Loss: 0.0003758544567972422
Epoch 39/100: Training Loss: 0.0005710090510547162
Epoch 40/100: Training Loss: 0.00030713558662682773
Epoch 41/100: Training Loss: 0.00039916718378663063
Epoch 42/100: Training Loss: 0.0005262191407382488
Epoch 43/100: Training Loss: 0.0002747514517977834
Epoch 44/100: Training Loss: 0.0002333275740966201
Epoch 45/100: Training Loss: 0.00017728812526911496
Epoch 46/100: Training Loss: 0.0002522218506783247
Epoch 47/100: Training Loss: 0.00021441325079649687
Epoch 48/100: Training Loss: 0.00020467513240873814
Epoch 49/100: Training Loss: 0.0001686066621914506
Epoch 50/100: Training Loss: 0.000200295215472579
Epoch 51/100: Training Loss: 0.00011790741700679064
Epoch 52/100: Training Loss: 6.706564454361796e-05
Epoch 53/100: Training Loss: 0.00010231940541416407
Epoch 54/100: Training Loss: 0.00011926532024517656
Epoch 55/100: Training Loss: 6.866438197903336e-05
Epoch 56/100: Training Loss: 5.034172791056335e-05
Epoch 57/100: Training Loss: 3.8378685712814334e-05
Epoch 58/100: Training Loss: 0.00013676258968189358
Epoch 59/100: Training Loss: 0.00012507460778579115
Epoch 60/100: Training Loss: 4.430545668583363e-05
Epoch 61/100: Training Loss: 3.732064797077328e-05
Epoch 62/100: Training Loss: 3.076430875808001e-05
Epoch 63/100: Training Loss: 6.633825832977892e-05
Epoch 64/100: Training Loss: 0.00013615896459668876
Epoch 65/100: Training Loss: 1.7100987315643577e-05
Epoch 66/100: Training Loss: 4.425258666742593e-05
Epoch 67/100: Training Loss: 1.758020807756111e-05
Epoch 68/100: Training Loss: 4.66647106804885e-06
Epoch 69/100: Training Loss: 2.9209820786491038e-05
Epoch 70/100: Training Loss: 2.9689163784496487e-05
Epoch 71/100: Training Loss: 1.991643657675013e-05
Epoch 72/100: Training Loss: 2.1703219681512563e-05
Epoch 73/100: Training Loss: 3.168859984725714e-05
Epoch 74/100: Training Loss: 1.3741481234319508e-05
Epoch 75/100: Training Loss: 1.3809722440782935e-05
Epoch 76/100: Training Loss: 1.8293806351721287e-05
Epoch 77/100: Training Loss: 3.5208999179303646e-05
Epoch 78/100: Training Loss: 1.1208430805709213e-06
Epoch 79/100: Training Loss: 8.13576771179214e-06
Epoch 80/100: Training Loss: 2.3524228890892118e-05
Epoch 81/100: Training Loss: 7.438085594912991e-06
Epoch 82/100: Training Loss: 1.2029444769723341e-05
Epoch 83/100: Training Loss: 9.617320029065012e-06
Epoch 84/100: Training Loss: 1.1328187974868343e-05
Epoch 85/100: Training Loss: 4.370457827462815e-06
Epoch 86/100: Training Loss: 1.1425873526604847e-05
Epoch 87/100: Training Loss: 7.771881064400077e-06
Epoch 88/100: Training Loss: 2.9886869015172124e-06
Epoch 89/100: Training Loss: 0.0011474759317934512
Epoch 90/100: Training Loss: 4.23872988903895e-05
Epoch 91/100: Training Loss: 1.901511313917581e-06
Epoch 92/100: Training Loss: 1.5235221326292959e-06
Epoch 93/100: Training Loss: 1.7792983726394595e-07
Epoch 94/100: Training Loss: 1.2988877642783336e-06
Epoch 95/100: Training Loss: 1.1215443009859882e-06
Epoch 96/100: Training Loss: 5.4782212828286e-07
Epoch 97/100: Training Loss: 2.3579311800858704e-07
Epoch 98/100: Training Loss: 2.5104498035943834e-07
Epoch 99/100: Training Loss: 2.321633445490079e-08
Epoch 0/100: Training Loss: 0.002230023122896814
Epoch 1/100: Training Loss: 0.001435452301031465
Epoch 2/100: Training Loss: 0.0013721775097452153
Epoch 3/100: Training Loss: 0.0012951910875405475
Epoch 4/100: Training Loss: 0.0013779698853280135
Epoch 5/100: Training Loss: 0.0010361220616443901
Epoch 6/100: Training Loss: 0.0015044788456266853
Epoch 7/100: Training Loss: 0.0011221777861285362
Epoch 8/100: Training Loss: 0.0011403813103961337
Epoch 9/100: Training Loss: 0.0014888828347443016
Epoch 10/100: Training Loss: 0.0009312429435693534
Epoch 11/100: Training Loss: 0.001449181205907445
Epoch 12/100: Training Loss: 0.0016610062426062906
Epoch 13/100: Training Loss: 0.0010923991917045253
Epoch 14/100: Training Loss: 0.0014980110772855723
Epoch 15/100: Training Loss: 0.0016892514411051562
Epoch 16/100: Training Loss: 0.0013317806515724035
Epoch 17/100: Training Loss: 0.0014279382244037214
Epoch 18/100: Training Loss: 0.001107584993550732
Epoch 19/100: Training Loss: 0.0009408399557611745
Epoch 20/100: Training Loss: 0.001314241605199826
Epoch 21/100: Training Loss: 0.0008294153365359944
Epoch 22/100: Training Loss: 0.0008171552875239378
Epoch 23/100: Training Loss: 0.0007842480661762748
Epoch 24/100: Training Loss: 0.0010873662058714848
Epoch 25/100: Training Loss: 0.0010045550431415533
Epoch 26/100: Training Loss: 0.0006825437970981477
Epoch 27/100: Training Loss: 0.0005688031862495811
Epoch 28/100: Training Loss: 0.000990259609404643
Epoch 29/100: Training Loss: 0.0007465520197418845
Epoch 30/100: Training Loss: 0.0007195704302210717
Epoch 31/100: Training Loss: 0.0007144725246793905
Epoch 32/100: Training Loss: 0.0007378996177843422
Epoch 33/100: Training Loss: 0.0008772980825156923
Epoch 34/100: Training Loss: 0.0008566500085174657
Epoch 35/100: Training Loss: 0.001154225628087475
Epoch 36/100: Training Loss: 0.0011669165769200415
Epoch 37/100: Training Loss: 0.000309762183078535
Epoch 38/100: Training Loss: 0.0008057263816238209
Epoch 39/100: Training Loss: 0.0007071228828399804
Epoch 40/100: Training Loss: 0.000735136543869213
Epoch 41/100: Training Loss: 0.000709266656902945
Epoch 42/100: Training Loss: 0.0006280388137337509
Epoch 43/100: Training Loss: 0.0008876638807308901
Epoch 44/100: Training Loss: 0.0009860496991758894
Epoch 45/100: Training Loss: 0.0007444041644691662
Epoch 46/100: Training Loss: 0.0028868034766737823
Epoch 47/100: Training Loss: 0.0007729949844870597
Epoch 48/100: Training Loss: 0.0006352109229488738
Epoch 49/100: Training Loss: 0.0006091377347897572
Epoch 50/100: Training Loss: 0.0007067916404669452
Epoch 51/100: Training Loss: 0.0005886457907925746
Epoch 52/100: Training Loss: 0.0005766675350772347
Epoch 53/100: Training Loss: 0.0006578843684712793
Epoch 54/100: Training Loss: 0.0010547883761156897
Epoch 55/100: Training Loss: 0.0007808334698342973
Epoch 56/100: Training Loss: 0.0004601336208878049
Epoch 57/100: Training Loss: 0.0008527214170261553
Epoch 58/100: Training Loss: 0.00043030144872179454
Epoch 59/100: Training Loss: 0.0003585722890629131
Epoch 60/100: Training Loss: 0.0003671299215334996
Epoch 61/100: Training Loss: 0.00040760536672203404
Epoch 62/100: Training Loss: 0.0009374623275866175
Epoch 63/100: Training Loss: 0.0004003087806094224
Epoch 64/100: Training Loss: 0.000285330210711546
Epoch 65/100: Training Loss: 0.00033079225356411784
Epoch 66/100: Training Loss: 0.00033531359331623003
Epoch 67/100: Training Loss: 0.0009221666178126244
Epoch 68/100: Training Loss: 0.00046177583325440714
Epoch 69/100: Training Loss: 0.00032123334848197405
Epoch 70/100: Training Loss: 0.00038016808165866096
Epoch 71/100: Training Loss: 0.00041656727623787655
Epoch 72/100: Training Loss: 0.0003085171293680835
Epoch 73/100: Training Loss: 0.0003259372037307472
Epoch 74/100: Training Loss: 0.00039650858112960863
Epoch 75/100: Training Loss: 0.0006908329239316807
Epoch 76/100: Training Loss: 0.00021668848623136047
Epoch 77/100: Training Loss: 0.00031073718883429364
Epoch 78/100: Training Loss: 0.0006983037207536636
Epoch 79/100: Training Loss: 0.0004704287572271505
Epoch 80/100: Training Loss: 0.00027973401793249096
Epoch 81/100: Training Loss: 0.0004241197447108615
Epoch 82/100: Training Loss: 0.0005552308859339185
Epoch 83/100: Training Loss: 0.0004379645369614765
Epoch 84/100: Training Loss: 0.0003268710414695132
Epoch 85/100: Training Loss: 0.0006986190653910303
Epoch 86/100: Training Loss: 0.0003086691544314099
Epoch 87/100: Training Loss: 0.00025269495928363433
Epoch 88/100: Training Loss: 0.0013208257354748478
Epoch 89/100: Training Loss: 0.00030796376952699797
Epoch 90/100: Training Loss: 0.00026431860058170973
Epoch 91/100: Training Loss: 0.0002498472714500063
Epoch 92/100: Training Loss: 0.0002668856103329142
Epoch 93/100: Training Loss: 0.00043957300816371944
Epoch 94/100: Training Loss: 0.0004676868486556278
Epoch 95/100: Training Loss: 0.0007636694676557165
Epoch 96/100: Training Loss: 0.00039433744872451585
Epoch 97/100: Training Loss: 0.00031259335624943876
Epoch 98/100: Training Loss: 0.00039586709563139895
Epoch 99/100: Training Loss: 0.0005389704446124423
Epoch 0/100: Training Loss: 0.0031474790755350876
Epoch 1/100: Training Loss: 0.00175769370832261
Epoch 2/100: Training Loss: 0.0021639487166313608
Epoch 3/100: Training Loss: 0.0015543140233701962
Epoch 4/100: Training Loss: 0.0012899000363744747
Epoch 5/100: Training Loss: 0.0011468005787794756
Epoch 6/100: Training Loss: 0.001284527171189618
Epoch 7/100: Training Loss: 0.0016827027129519517
Epoch 8/100: Training Loss: 0.0010516753621921417
Epoch 9/100: Training Loss: 0.0013166161099816584
Epoch 10/100: Training Loss: 0.0014674843876225174
Epoch 11/100: Training Loss: 0.001446795311703044
Epoch 12/100: Training Loss: 0.0012151525848230738
Epoch 13/100: Training Loss: 0.0012095033363172204
Epoch 14/100: Training Loss: 0.0010109668134883711
Epoch 15/100: Training Loss: 0.0011005082707496205
Epoch 16/100: Training Loss: 0.0010226537847215203
Epoch 17/100: Training Loss: 0.0008056981928029638
Epoch 18/100: Training Loss: 0.0006467417167250518
Epoch 19/100: Training Loss: 0.001027731948597416
Epoch 20/100: Training Loss: 0.0008401532841336196
Epoch 21/100: Training Loss: 0.0009929465640122724
Epoch 22/100: Training Loss: 0.0007913332835883852
Epoch 23/100: Training Loss: 0.000754721320358811
Epoch 24/100: Training Loss: 0.0009561604375292541
Epoch 25/100: Training Loss: 0.0007391990085316312
Epoch 26/100: Training Loss: 0.000735357925770389
Epoch 27/100: Training Loss: 0.0006456574911524536
Epoch 28/100: Training Loss: 0.0009334413868606471
Epoch 29/100: Training Loss: 0.0006082887007931995
Epoch 30/100: Training Loss: 0.0008745380457799146
Epoch 31/100: Training Loss: 0.0007003229704632121
Epoch 32/100: Training Loss: 0.0014919320679014656
Epoch 33/100: Training Loss: 0.0006240261303391427
Epoch 34/100: Training Loss: 0.0005721491613205831
Epoch 35/100: Training Loss: 0.000801427918634597
Epoch 36/100: Training Loss: 0.0017288101326887774
Epoch 37/100: Training Loss: 0.000602540032119508
Epoch 38/100: Training Loss: 0.0010579614692432864
Epoch 39/100: Training Loss: 0.0007711264548028351
Epoch 40/100: Training Loss: 0.0007736594149261524
Epoch 41/100: Training Loss: 0.0007152332431951147
Epoch 42/100: Training Loss: 0.0009591887900783758
Epoch 43/100: Training Loss: 0.0005437556155927621
Epoch 44/100: Training Loss: 0.000761294440858683
Epoch 45/100: Training Loss: 0.0009172350927522988
Epoch 46/100: Training Loss: 0.0010562466018518824
Epoch 47/100: Training Loss: 0.0005649829366404539
Epoch 48/100: Training Loss: 0.0006981209679773659
Epoch 49/100: Training Loss: 0.0007893960851772575
Epoch 50/100: Training Loss: 0.0011325351371886624
Epoch 51/100: Training Loss: 0.0005085786721508974
Epoch 52/100: Training Loss: 0.0011302834483468609
Epoch 53/100: Training Loss: 0.0006296918460517932
Epoch 54/100: Training Loss: 0.0009723441426161748
Epoch 55/100: Training Loss: 0.0010716866725569319
Epoch 56/100: Training Loss: 0.0008308544849893849
Epoch 57/100: Training Loss: 0.0005065285760885591
Epoch 58/100: Training Loss: 0.0007296728480393719
Epoch 59/100: Training Loss: 0.0007818414337316137
Epoch 60/100: Training Loss: 0.0004410053704194962
Epoch 61/100: Training Loss: 0.000608514638463403
Epoch 62/100: Training Loss: 0.0011606559062459665
Epoch 63/100: Training Loss: 0.0005468109705645567
Epoch 64/100: Training Loss: 0.00193206178154915
Epoch 65/100: Training Loss: 0.000667749791388299
Epoch 66/100: Training Loss: 0.001086434835840942
Epoch 67/100: Training Loss: 0.0005724360798574557
Epoch 68/100: Training Loss: 0.0004069960800705442
Epoch 69/100: Training Loss: 0.0008076297439587344
Epoch 70/100: Training Loss: 0.0008545994378958538
Epoch 71/100: Training Loss: 0.0004034217945329703
Epoch 72/100: Training Loss: 0.0005623344687899207
Epoch 73/100: Training Loss: 0.00030694187731499883
Epoch 74/100: Training Loss: 0.000725183374942488
Epoch 75/100: Training Loss: 0.00048333358992436886
Epoch 76/100: Training Loss: 0.00032865536061062173
Epoch 77/100: Training Loss: 0.0003904462999598995
Epoch 78/100: Training Loss: 0.000400784004266095
Epoch 79/100: Training Loss: 0.00044237860258977127
Epoch 80/100: Training Loss: 0.0010093047170882012
Epoch 81/100: Training Loss: 0.0003558042085474464
Epoch 82/100: Training Loss: 0.0014316109335346587
Epoch 83/100: Training Loss: 0.0004236691506804934
Epoch 84/100: Training Loss: 0.0003603670722360064
Epoch 85/100: Training Loss: 0.00035217399619946814
Epoch 86/100: Training Loss: 0.0003439992856068216
Epoch 87/100: Training Loss: 0.0003330661755078917
Epoch 88/100: Training Loss: 0.000377237891695302
Epoch 89/100: Training Loss: 0.0005167762090446084
Epoch 90/100: Training Loss: 0.0003096563326325386
Epoch 91/100: Training Loss: 0.00036040199979855
Epoch 92/100: Training Loss: 0.00035979143183702115
Epoch 93/100: Training Loss: 0.00020702021896459494
Epoch 94/100: Training Loss: 0.00018101928245489764
Epoch 95/100: Training Loss: 0.00037346505055761643
Epoch 96/100: Training Loss: 0.0003813974986410445
Epoch 97/100: Training Loss: 0.00031357678543230533
Epoch 98/100: Training Loss: 0.0002965810145162473
Epoch 99/100: Training Loss: 0.00030873613847289113
Epoch 0/100: Training Loss: 0.0019697229953328514
Epoch 1/100: Training Loss: 0.0019211309730626975
Epoch 2/100: Training Loss: 0.0018020266560232563
Epoch 3/100: Training Loss: 0.0015566203814403267
Epoch 4/100: Training Loss: 0.0014454249743443386
Epoch 5/100: Training Loss: 0.0018161252425734405
Epoch 6/100: Training Loss: 0.0014441686261231733
Epoch 7/100: Training Loss: 0.0014649702675023656
Epoch 8/100: Training Loss: 0.0012051989887930025
Epoch 9/100: Training Loss: 0.0014475135097078457
Epoch 10/100: Training Loss: 0.001065996232306122
Epoch 11/100: Training Loss: 0.0011715379300390838
Epoch 12/100: Training Loss: 0.0013852276999479645
Epoch 13/100: Training Loss: 0.0013817228898880588
Epoch 14/100: Training Loss: 0.0012396909059232968
Epoch 15/100: Training Loss: 0.0011233616216926817
Epoch 16/100: Training Loss: 0.0011764098504546342
Epoch 17/100: Training Loss: 0.0009148262298790512
Epoch 18/100: Training Loss: 0.0009221636755451276
Epoch 19/100: Training Loss: 0.0010743015890668152
Epoch 20/100: Training Loss: 0.0009032192693394461
Epoch 21/100: Training Loss: 0.0008616605002409334
Epoch 22/100: Training Loss: 0.0008227419891175191
Epoch 23/100: Training Loss: 0.000857253553001744
Epoch 24/100: Training Loss: 0.0007409365598563176
Epoch 25/100: Training Loss: 0.000845566107209321
Epoch 26/100: Training Loss: 0.000885401182113939
Epoch 27/100: Training Loss: 0.0008734103980337738
Epoch 28/100: Training Loss: 0.001007854558859661
Epoch 29/100: Training Loss: 0.0009024337788296353
Epoch 30/100: Training Loss: 0.0010170695508361623
Epoch 31/100: Training Loss: 0.0008373514861817572
Epoch 32/100: Training Loss: 0.0011484398963345084
Epoch 33/100: Training Loss: 0.00095712512162081
Epoch 34/100: Training Loss: 0.0007163698126556008
Epoch 35/100: Training Loss: 0.0006845950795586702
Epoch 36/100: Training Loss: 0.0007306736935475829
Epoch 37/100: Training Loss: 0.0006327026873637157
Epoch 38/100: Training Loss: 0.0009814014860019561
Epoch 39/100: Training Loss: 0.0009097391442888102
Epoch 40/100: Training Loss: 0.0006490699045217721
Epoch 41/100: Training Loss: 0.0007211692678700587
Epoch 42/100: Training Loss: 0.0006670654294597115
Epoch 43/100: Training Loss: 0.0004828954768028988
Epoch 44/100: Training Loss: 0.0007637304959783129
Epoch 45/100: Training Loss: 0.000623118583184139
Epoch 46/100: Training Loss: 0.0006016900964603303
Epoch 47/100: Training Loss: 0.0005092249744257349
Epoch 48/100: Training Loss: 0.0004727226818443104
Epoch 49/100: Training Loss: 0.0010053657802047244
Epoch 50/100: Training Loss: 0.001023705028424597
Epoch 51/100: Training Loss: 0.0009210852870515957
Epoch 52/100: Training Loss: 0.0007415247760760557
Epoch 53/100: Training Loss: 0.0007113276678285781
Epoch 54/100: Training Loss: 0.0007054675726374243
Epoch 55/100: Training Loss: 0.0007934992670253583
Epoch 56/100: Training Loss: 0.0011207310447267666
Epoch 57/100: Training Loss: 0.0005678068490544702
Epoch 58/100: Training Loss: 0.0005750812732490005
Epoch 59/100: Training Loss: 0.0006912333570468198
Epoch 60/100: Training Loss: 0.0006225643454083971
Epoch 61/100: Training Loss: 0.0004403923822056716
Epoch 62/100: Training Loss: 0.0006187326114648466
Epoch 63/100: Training Loss: 0.00044891674807117244
Epoch 64/100: Training Loss: 0.0003620769804830004
Epoch 65/100: Training Loss: 0.0005775255856999926
Epoch 66/100: Training Loss: 0.0003234108399813342
Epoch 67/100: Training Loss: 0.0004137627732981542
Epoch 68/100: Training Loss: 0.0005324679859884225
Epoch 69/100: Training Loss: 0.00041716175664002726
Epoch 70/100: Training Loss: 0.0006497598187938617
Epoch 71/100: Training Loss: 0.000664577837202959
Epoch 72/100: Training Loss: 0.0002960922421923109
Epoch 73/100: Training Loss: 0.0006341436865982736
Epoch 74/100: Training Loss: 0.0006510715480822667
Epoch 75/100: Training Loss: 0.0008245815706860488
Epoch 76/100: Training Loss: 0.0006352790222046482
Epoch 77/100: Training Loss: 0.00041031272737843214
Epoch 78/100: Training Loss: 0.000177122438978997
Epoch 79/100: Training Loss: 0.0003260514776038516
Epoch 80/100: Training Loss: 0.0006636351726617023
Epoch 81/100: Training Loss: 0.0003752428682366754
Epoch 82/100: Training Loss: 0.0003947345361967755
Epoch 83/100: Training Loss: 0.0005166293804053289
Epoch 84/100: Training Loss: 0.00041837809951442064
Epoch 85/100: Training Loss: 0.00034058981450500004
Epoch 86/100: Training Loss: 0.00038939669348631695
Epoch 87/100: Training Loss: 0.00048340244847498124
Epoch 88/100: Training Loss: 0.0003530703437556127
Epoch 89/100: Training Loss: 0.0005441381103673559
Epoch 90/100: Training Loss: 0.0003948368986321103
Epoch 91/100: Training Loss: 0.00033642408574462694
Epoch 92/100: Training Loss: 0.0005394472343147181
Epoch 93/100: Training Loss: 0.0003754619485253741
Epoch 94/100: Training Loss: 0.00036950286026972873
Epoch 95/100: Training Loss: 0.00031868947349536194
Epoch 96/100: Training Loss: 0.00038677192987150445
Epoch 97/100: Training Loss: 0.0002998586055959106
Epoch 98/100: Training Loss: 0.00037171667928148985
Epoch 99/100: Training Loss: 0.0005424825628851629
Epoch 0/100: Training Loss: 0.002023831700647114
Epoch 1/100: Training Loss: 0.0020524587062810433
Epoch 2/100: Training Loss: 0.0013559237615951639
Epoch 3/100: Training Loss: 0.001580116567232751
Epoch 4/100: Training Loss: 0.0016736818465176008
Epoch 5/100: Training Loss: 0.0018060270524182856
Epoch 6/100: Training Loss: 0.000885424136326013
Epoch 7/100: Training Loss: 0.000515089968577126
Epoch 8/100: Training Loss: 0.0019551091241520762
Epoch 9/100: Training Loss: 0.002047646716730484
Epoch 10/100: Training Loss: 0.0013664259223748517
Epoch 11/100: Training Loss: 0.0014905099639829422
Epoch 12/100: Training Loss: 0.0024477675655819723
Epoch 13/100: Training Loss: 0.0014887481730505331
Epoch 14/100: Training Loss: 0.0019836100126733843
Epoch 15/100: Training Loss: 0.0016103061224451128
Epoch 16/100: Training Loss: 0.0020343688939580854
Epoch 17/100: Training Loss: 0.0018898108542360218
Epoch 18/100: Training Loss: 0.0019259703475118474
Epoch 19/100: Training Loss: 0.0016263470744455096
Epoch 20/100: Training Loss: 0.0020268993661893124
Epoch 21/100: Training Loss: 0.0017559350721093993
Epoch 22/100: Training Loss: 0.0016300775949528675
Epoch 23/100: Training Loss: 0.001956468781098625
Epoch 24/100: Training Loss: 0.001726430772945581
Epoch 25/100: Training Loss: 0.0014591088752872897
Epoch 26/100: Training Loss: 0.0017870558018715965
Epoch 27/100: Training Loss: 0.0017382711764203002
Epoch 28/100: Training Loss: 0.001791389375332965
Epoch 29/100: Training Loss: 0.0023622195057521594
Epoch 30/100: Training Loss: 0.002310410635360819
Epoch 31/100: Training Loss: 0.001964073899565943
Epoch 32/100: Training Loss: 0.0020558954469415526
Epoch 33/100: Training Loss: 0.0018474487279424604
Epoch 34/100: Training Loss: 0.0015609313715372654
Epoch 35/100: Training Loss: 0.0018697479702778999
Epoch 36/100: Training Loss: 0.0017198166310392468
Epoch 37/100: Training Loss: 0.0013553150836995106
Epoch 38/100: Training Loss: 0.0013784397122086278
Epoch 39/100: Training Loss: 0.0006823380853956109
Epoch 40/100: Training Loss: 0.00118275016348883
Epoch 41/100: Training Loss: 0.0011389112433060906
Epoch 42/100: Training Loss: 0.0015976227671894807
Epoch 43/100: Training Loss: 0.0013283248374004238
Epoch 44/100: Training Loss: 0.0012014441142808522
Epoch 45/100: Training Loss: 0.0014325205656076899
Epoch 46/100: Training Loss: 0.0015721015188078218
Epoch 47/100: Training Loss: 0.0013639489743883246
Epoch 48/100: Training Loss: 0.001428588040617128
Epoch 49/100: Training Loss: 0.0014735562911886253
Epoch 50/100: Training Loss: 0.0015499920442404336
Epoch 51/100: Training Loss: 0.0010632695938577715
Epoch 52/100: Training Loss: 0.001168911030750401
Epoch 53/100: Training Loss: 0.0012850966674602584
Epoch 54/100: Training Loss: 0.001152464392169422
Epoch 55/100: Training Loss: 0.0013018402437500606
Epoch 56/100: Training Loss: 0.0015015657374400967
Epoch 57/100: Training Loss: 0.0014582371080158563
Epoch 58/100: Training Loss: 0.0015201498538453058
Epoch 59/100: Training Loss: 0.0013787087225756109
Epoch 60/100: Training Loss: 0.0013057561899652544
Epoch 61/100: Training Loss: 0.0011234559760188426
Epoch 62/100: Training Loss: 0.0012054163099124732
Epoch 63/100: Training Loss: 0.0012384528750615405
Epoch 64/100: Training Loss: 0.001000565408870874
Epoch 65/100: Training Loss: 0.0010957486976850902
Epoch 66/100: Training Loss: 0.0009660043858534452
Epoch 67/100: Training Loss: 0.0010318443277813742
Epoch 68/100: Training Loss: 0.0011498594520897266
Epoch 69/100: Training Loss: 0.0011222022061316383
Epoch 70/100: Training Loss: 0.0008233899114937182
Epoch 71/100: Training Loss: 0.0009654497863441114
Epoch 72/100: Training Loss: 0.0009120517219139251
Epoch 73/100: Training Loss: 0.0008068747867811595
Epoch 74/100: Training Loss: 0.0009725412588245822
Epoch 75/100: Training Loss: 0.000816576922966155
Epoch 76/100: Training Loss: 0.001011470394418729
Epoch 77/100: Training Loss: 0.001048769283768357
Epoch 78/100: Training Loss: 0.0013192416421625
Epoch 79/100: Training Loss: 0.0011030211551299948
Epoch 80/100: Training Loss: 0.0007698525064038915
Epoch 81/100: Training Loss: 0.0006772729241295366
Epoch 82/100: Training Loss: 0.0007460241680903151
Epoch 83/100: Training Loss: 0.0004255455850765405
Epoch 84/100: Training Loss: 0.0009156916512558791
Epoch 85/100: Training Loss: 0.0010869323417840415
Epoch 86/100: Training Loss: 0.0003583936501812461
Epoch 87/100: Training Loss: 0.000955252063195437
Epoch 88/100: Training Loss: 0.0008926991595337722
Epoch 89/100: Training Loss: 0.0008447171244400227
Epoch 90/100: Training Loss: 0.0006329390584238318
Epoch 91/100: Training Loss: 0.000990859226675223
Epoch 92/100: Training Loss: 0.0008174685748997114
Epoch 93/100: Training Loss: 0.0006015394006343867
Epoch 94/100: Training Loss: 0.0009795693766991823
Epoch 95/100: Training Loss: 0.0007406522501383396
Epoch 96/100: Training Loss: 0.0008227741284086215
Epoch 97/100: Training Loss: 0.0008189367340100522
Epoch 98/100: Training Loss: 0.0008284161422426337
Epoch 99/100: Training Loss: 0.0005804534187380052
Epoch 0/100: Training Loss: 0.002005667481201374
Epoch 1/100: Training Loss: 0.0017724487165741573
Epoch 2/100: Training Loss: 0.0014366892394640587
Epoch 3/100: Training Loss: 0.0015498299077646622
Epoch 4/100: Training Loss: 0.002984632719431492
Epoch 5/100: Training Loss: 0.001538151048666594
Epoch 6/100: Training Loss: 0.001656951888507565
Epoch 7/100: Training Loss: 0.003078928254298027
Epoch 8/100: Training Loss: 0.0012594423941429088
Epoch 9/100: Training Loss: 0.0024388621974465075
Epoch 10/100: Training Loss: 0.002198983896647068
Epoch 11/100: Training Loss: 0.002761345628081568
Epoch 12/100: Training Loss: 0.0019700359429744695
Epoch 13/100: Training Loss: 0.0027791451144692125
Epoch 14/100: Training Loss: 0.0020096280322169625
Epoch 15/100: Training Loss: 0.001494092657076602
Epoch 16/100: Training Loss: 0.0009451218393464752
Epoch 17/100: Training Loss: 0.0013426617281326395
Epoch 18/100: Training Loss: 0.0017374063169719367
Epoch 19/100: Training Loss: 0.0017560009924781244
Epoch 20/100: Training Loss: 0.001445860361421345
Epoch 21/100: Training Loss: 0.0021688511829502533
Epoch 22/100: Training Loss: 0.0016313600816474055
Epoch 23/100: Training Loss: 0.001549197743270571
Epoch 24/100: Training Loss: 0.002389961520567635
Epoch 25/100: Training Loss: 0.002048776639218362
Epoch 26/100: Training Loss: 0.0017025845729752092
Epoch 27/100: Training Loss: 0.0017398698440450706
Epoch 28/100: Training Loss: 0.002366193082948394
Epoch 29/100: Training Loss: 0.002323939310793845
Epoch 30/100: Training Loss: 0.002565366937624698
Epoch 31/100: Training Loss: 0.001960575185864177
Epoch 32/100: Training Loss: 0.002036425056836463
Epoch 33/100: Training Loss: 0.0019628312808788375
Epoch 34/100: Training Loss: 0.00226973421526271
Epoch 35/100: Training Loss: 0.002187671842954017
Epoch 36/100: Training Loss: 0.0027199075711483987
Epoch 37/100: Training Loss: 0.002324050822794832
Epoch 38/100: Training Loss: 0.0017333851744797057
Epoch 39/100: Training Loss: 0.0023026419001699284
Epoch 40/100: Training Loss: 0.0008928865589053425
Epoch 41/100: Training Loss: 0.0013363290306748143
Epoch 42/100: Training Loss: 0.0015651960641343073
Epoch 43/100: Training Loss: 0.0015979031261229358
Epoch 44/100: Training Loss: 0.0017432907953957059
Epoch 45/100: Training Loss: 0.0012782631528298585
Epoch 46/100: Training Loss: 0.0014412388304211447
Epoch 47/100: Training Loss: 0.0007888647104730669
Epoch 48/100: Training Loss: 0.0013692892150373647
Epoch 49/100: Training Loss: 0.0010748770063286586
Epoch 50/100: Training Loss: 0.0017045258686242514
Epoch 51/100: Training Loss: 0.0013338944177753878
Epoch 52/100: Training Loss: 0.001441257678909807
Epoch 53/100: Training Loss: 0.001158640676776305
Epoch 54/100: Training Loss: 0.001425268535582435
Epoch 55/100: Training Loss: 0.00099051363815535
Epoch 56/100: Training Loss: 0.001494074302003873
Epoch 57/100: Training Loss: 0.0014725948209004687
Epoch 58/100: Training Loss: 0.00126883802034997
Epoch 59/100: Training Loss: 0.0013806474524617985
Epoch 60/100: Training Loss: 0.0014133601393920697
Epoch 61/100: Training Loss: 0.001384493728347172
Epoch 62/100: Training Loss: 0.0013134898926248613
Epoch 63/100: Training Loss: 0.0012509380744782504
Epoch 64/100: Training Loss: 0.001306139968878386
Epoch 65/100: Training Loss: 0.001120777516965045
Epoch 66/100: Training Loss: 0.0008884108816551057
Epoch 67/100: Training Loss: 0.0012048294410010837
Epoch 68/100: Training Loss: 0.0015320443357063444
Epoch 69/100: Training Loss: 0.0013370381680545427
Epoch 70/100: Training Loss: 0.0014245623586983081
Epoch 71/100: Training Loss: 0.0014048489119043413
Epoch 72/100: Training Loss: 0.0011582416019692327
Epoch 73/100: Training Loss: 0.0012257746513316173
Epoch 74/100: Training Loss: 0.0013074251200189653
Epoch 75/100: Training Loss: 0.0010912528890647635
Epoch 76/100: Training Loss: 0.0011596480347462836
Epoch 77/100: Training Loss: 0.001099583822370365
Epoch 78/100: Training Loss: 0.0012472893623326788
Epoch 79/100: Training Loss: 0.001198289410167972
Epoch 80/100: Training Loss: 0.0009360115062322049
Epoch 81/100: Training Loss: 0.0007507107313105602
Epoch 82/100: Training Loss: 0.0007884667211810485
Epoch 83/100: Training Loss: 0.0010927915573120117
Epoch 84/100: Training Loss: 0.0013786096446561497
Epoch 85/100: Training Loss: 0.001142971563023447
Epoch 86/100: Training Loss: 0.0012133437276676002
Epoch 87/100: Training Loss: 0.0011474525691657666
Epoch 88/100: Training Loss: 0.0010845631558374063
Epoch 89/100: Training Loss: 0.0008734391619827573
Epoch 90/100: Training Loss: 0.0009411778671062545
Epoch 91/100: Training Loss: 0.0009290506902909437
Epoch 92/100: Training Loss: 0.0009397389675607744
Epoch 93/100: Training Loss: 0.0007532878427316021
Epoch 94/100: Training Loss: 0.001005708776562419
Epoch 95/100: Training Loss: 0.0007613921994405077
Epoch 96/100: Training Loss: 0.0010007876434073542
Epoch 97/100: Training Loss: 0.0007039519729993201
Epoch 98/100: Training Loss: 0.0010744522738930405
Epoch 99/100: Training Loss: 0.0007932103232832145
Epoch 0/100: Training Loss: 0.001778120631413744
Epoch 1/100: Training Loss: 0.002204422919166009
Epoch 2/100: Training Loss: 0.0012084595020243664
Epoch 3/100: Training Loss: 0.0008948486767067815
Epoch 4/100: Training Loss: 0.002081233934061417
Epoch 5/100: Training Loss: 0.0019101966295810725
Epoch 6/100: Training Loss: 0.0019526838861553873
Epoch 7/100: Training Loss: 0.0009986727640328818
Epoch 8/100: Training Loss: 0.0017284555545705833
Epoch 9/100: Training Loss: 0.0018659559701452192
Epoch 10/100: Training Loss: 0.0013784844156922093
Epoch 11/100: Training Loss: 0.0011204192969972724
Epoch 12/100: Training Loss: 0.0014445188621811519
Epoch 13/100: Training Loss: 0.0015955681832420905
Epoch 14/100: Training Loss: 0.0015167848558615374
Epoch 15/100: Training Loss: 0.0023145407240911823
Epoch 16/100: Training Loss: 0.0019379885780890257
Epoch 17/100: Training Loss: 0.0014087764040523808
Epoch 18/100: Training Loss: 0.0021968839184337893
Epoch 19/100: Training Loss: 0.0013843836965939857
Epoch 20/100: Training Loss: 0.0016417945457610074
Epoch 21/100: Training Loss: 0.0019113555649258444
Epoch 22/100: Training Loss: 0.001269230976799466
Epoch 23/100: Training Loss: 0.0021461998390046176
Epoch 24/100: Training Loss: 0.002347708340512206
Epoch 25/100: Training Loss: 0.0022981958278757058
Epoch 26/100: Training Loss: 0.0016265485855127802
Epoch 27/100: Training Loss: 0.0017197588026918323
Epoch 28/100: Training Loss: 0.0019576326506027322
Epoch 29/100: Training Loss: 0.0019558978001802964
Epoch 30/100: Training Loss: 0.002052944622292424
Epoch 31/100: Training Loss: 0.0018710549304027432
Epoch 32/100: Training Loss: 0.0018957993447385876
Epoch 33/100: Training Loss: 0.0020384411543410345
Epoch 34/100: Training Loss: 0.00153340438738564
Epoch 35/100: Training Loss: 0.0012245707164537038
Epoch 36/100: Training Loss: 0.0019276813166030984
Epoch 37/100: Training Loss: 0.002076662534120067
Epoch 38/100: Training Loss: 0.001899755158961214
Epoch 39/100: Training Loss: 0.0019901414580692518
Epoch 40/100: Training Loss: 0.0014175106555420832
Epoch 41/100: Training Loss: 0.0012954315602384655
Epoch 42/100: Training Loss: 0.0013042910406921083
Epoch 43/100: Training Loss: 0.0014212303208989024
Epoch 44/100: Training Loss: 0.0014860705034622293
Epoch 45/100: Training Loss: 0.0012577705035935964
Epoch 46/100: Training Loss: 0.0016155168907531839
Epoch 47/100: Training Loss: 0.0016019109463849604
Epoch 48/100: Training Loss: 0.0019003934418128816
Epoch 49/100: Training Loss: 0.0015796920321635064
Epoch 50/100: Training Loss: 0.0016500536377066807
Epoch 51/100: Training Loss: 0.0016558428868552707
Epoch 52/100: Training Loss: 0.0017189734818919605
Epoch 53/100: Training Loss: 0.002079748949467741
Epoch 54/100: Training Loss: 0.0012693211732321228
Epoch 55/100: Training Loss: 0.0015761194047548912
Epoch 56/100: Training Loss: 0.0016789690942953753
Epoch 57/100: Training Loss: 0.001702367075231691
Epoch 58/100: Training Loss: 0.0015349885485819634
Epoch 59/100: Training Loss: 0.001259920612865726
Epoch 60/100: Training Loss: 0.0013016230420561025
Epoch 61/100: Training Loss: 0.001025445019172517
Epoch 62/100: Training Loss: 0.0014345540313531232
Epoch 63/100: Training Loss: 0.0013447502590962592
Epoch 64/100: Training Loss: 0.001268067896760852
Epoch 65/100: Training Loss: 0.0013730207223765897
Epoch 66/100: Training Loss: 0.001186973113097892
Epoch 67/100: Training Loss: 0.001338504600209116
Epoch 68/100: Training Loss: 0.0012148232846860064
Epoch 69/100: Training Loss: 0.001228078706375021
Epoch 70/100: Training Loss: 0.0011345682949419843
Epoch 71/100: Training Loss: 0.00020079979586680203
Epoch 72/100: Training Loss: 0.0010752585155284957
Epoch 73/100: Training Loss: 0.001191191128547618
Epoch 74/100: Training Loss: 0.001304348178257216
Epoch 75/100: Training Loss: 0.0011002805256685674
Epoch 76/100: Training Loss: 0.00119156197996329
Epoch 77/100: Training Loss: 0.001092288667792516
Epoch 78/100: Training Loss: 0.0010835356664973378
Epoch 79/100: Training Loss: 0.0010660134798643605
Epoch 80/100: Training Loss: 0.0009385588153308591
Epoch 81/100: Training Loss: 0.00111050262356436
Epoch 82/100: Training Loss: 0.0008777278345941708
Epoch 83/100: Training Loss: 0.0009639172364544395
Epoch 84/100: Training Loss: 0.0005385777512133517
Epoch 85/100: Training Loss: 0.0008876821063212211
Epoch 86/100: Training Loss: 0.0010631648909966676
Epoch 87/100: Training Loss: 0.0006062973611402196
Epoch 88/100: Training Loss: 0.0007995422806171392
Epoch 89/100: Training Loss: 0.0007690214459469776
Epoch 90/100: Training Loss: 0.0008079306968790017
Epoch 91/100: Training Loss: 0.0010513299150972178
Epoch 92/100: Training Loss: 0.0008842137870409631
Epoch 93/100: Training Loss: 0.0009369363650580905
Epoch 94/100: Training Loss: 0.00102187545094269
Epoch 95/100: Training Loss: 0.0008551416215517663
Epoch 96/100: Training Loss: 0.0009359308820686593
Epoch 97/100: Training Loss: 0.0007739613289075182
Epoch 98/100: Training Loss: 0.0009464047207737601
Epoch 99/100: Training Loss: 0.0007171348625460998
Epoch 0/100: Training Loss: 0.0007563598892268012
Epoch 1/100: Training Loss: 0.0002861118272823446
Epoch 2/100: Training Loss: 0.0002151544260628083
Epoch 3/100: Training Loss: 0.00015880816123064827
Epoch 4/100: Training Loss: 0.0011539440821198856
Epoch 5/100: Training Loss: 7.297986132257124e-05
Epoch 6/100: Training Loss: 0.0001518675619188477
Epoch 7/100: Training Loss: 0.000150127533604117
Epoch 8/100: Training Loss: 0.00010682067231220357
Epoch 9/100: Training Loss: 0.0002646037980037577
Epoch 10/100: Training Loss: 6.216873469598153e-05
Epoch 11/100: Training Loss: 0.0001311182537499596
Epoch 12/100: Training Loss: 0.0007969852756051456
Epoch 13/100: Training Loss: 0.0009072263451183544
Epoch 14/100: Training Loss: 6.909002823864713e-05
Epoch 15/100: Training Loss: 0.0008891113540705512
Epoch 16/100: Training Loss: 0.0001835068906931316
Epoch 17/100: Training Loss: 0.0004964693065951853
Epoch 18/100: Training Loss: 0.0001173169187763158
Epoch 19/100: Training Loss: 0.000816551289137672
Epoch 20/100: Training Loss: 0.0009460606119211983
Epoch 21/100: Training Loss: 0.0008721820571843316
Epoch 22/100: Training Loss: 0.0010174470789292278
Epoch 23/100: Training Loss: 0.0004846492672667784
Epoch 24/100: Training Loss: 0.0002896932337213965
Epoch 25/100: Training Loss: 0.0005716295803294462
Epoch 26/100: Training Loss: 0.0002677644000333898
Epoch 27/100: Training Loss: 0.0007251637823441449
Epoch 28/100: Training Loss: 0.0005617605850977057
Epoch 29/100: Training Loss: 0.0008785113692283631
Epoch 30/100: Training Loss: 0.0006513059577521156
Epoch 31/100: Training Loss: 0.0004105217316571404
Epoch 32/100: Training Loss: 6.066760568715193e-06
Epoch 33/100: Training Loss: 0.00019546346191097707
Epoch 34/100: Training Loss: 0.00023452792974079358
Epoch 35/100: Training Loss: 0.0006814821678049424
Epoch 36/100: Training Loss: 0.0005539778839139377
Epoch 37/100: Training Loss: 0.0008399947601206162
Epoch 38/100: Training Loss: 0.00015414550023920396
Epoch 39/100: Training Loss: 0.00041122953681384814
Epoch 40/100: Training Loss: 4.775003146599321e-05
Epoch 41/100: Training Loss: 8.182821329683065e-06
Epoch 42/100: Training Loss: 0.00015314295887947083
Epoch 43/100: Training Loss: 4.205206299529356e-05
Epoch 44/100: Training Loss: 0.0008216597578104805
Epoch 45/100: Training Loss: 0.0004804069943287793
Epoch 46/100: Training Loss: 0.0005525654291405397
Epoch 47/100: Training Loss: 0.0008578638820087209
Epoch 48/100: Training Loss: 0.0008598907028927522
Epoch 49/100: Training Loss: 0.0008428162511657266
Epoch 50/100: Training Loss: 0.0008359614540548886
Epoch 51/100: Training Loss: 0.0005724244257983039
Epoch 52/100: Training Loss: 0.0008218382211292491
Epoch 53/100: Training Loss: 0.0007917004473069135
Epoch 54/100: Training Loss: 0.0007782333037432502
Epoch 55/100: Training Loss: 0.0009861683144288904
Epoch 56/100: Training Loss: 0.0009038762134664199
Epoch 57/100: Training Loss: 0.0007630208835882299
Epoch 58/100: Training Loss: 0.000764997215831981
Epoch 59/100: Training Loss: 0.0007637991624719956
Epoch 60/100: Training Loss: 0.0002726932878003401
Epoch 61/100: Training Loss: 3.3792909508680597e-06
Epoch 62/100: Training Loss: 2.5877230526769863e-05
Epoch 63/100: Training Loss: 0.00035944694981855505
Epoch 64/100: Training Loss: 0.0004700941636281855
Epoch 65/100: Training Loss: 0.00045653726248180167
Epoch 66/100: Training Loss: 0.00047175415298518014
Epoch 67/100: Training Loss: 0.0006180600646664115
Epoch 68/100: Training Loss: 0.0006294148371500127
Epoch 69/100: Training Loss: 0.0005034902954802793
Epoch 70/100: Training Loss: 6.761504337191582e-05
Epoch 71/100: Training Loss: 8.958104230901773e-06
Epoch 72/100: Training Loss: 0.00021100099034169142
Epoch 73/100: Training Loss: 0.0001142803908270948
Epoch 74/100: Training Loss: 0.0006096376653979806
Epoch 75/100: Training Loss: 3.074725322863635e-05
Epoch 76/100: Training Loss: 0.0005422096042072071
Epoch 77/100: Training Loss: 0.0003667502937948003
Epoch 78/100: Training Loss: 9.117115918985185e-06
Epoch 79/100: Training Loss: 0.0002732265302363564
Epoch 80/100: Training Loss: 0.0008762509507291458
Epoch 81/100: Training Loss: 0.0005470226792728199
Epoch 82/100: Training Loss: 0.0007685751599424026
Epoch 83/100: Training Loss: 2.9540179050801433e-06
Epoch 84/100: Training Loss: 5.443933803369017e-05
Epoch 85/100: Training Loss: 2.2464513997821248e-05
Epoch 86/100: Training Loss: 0.0003677461953724132
Epoch 87/100: Training Loss: 3.011725185548558e-05
Epoch 88/100: Training Loss: 0.000984958077178282
Epoch 89/100: Training Loss: 0.0005183565265992108
Epoch 90/100: Training Loss: 1.3779064037782304e-05
Epoch 91/100: Training Loss: 0.0005610295516603133
Epoch 92/100: Training Loss: 0.0006882066235822789
Epoch 93/100: Training Loss: 0.000550993882557925
Epoch 94/100: Training Loss: 0.000839855828705956
Epoch 95/100: Training Loss: 5.45792665113421e-05
Epoch 96/100: Training Loss: 1.6188973163747611e-06
Epoch 97/100: Training Loss: 0.0003524428781341104
Epoch 98/100: Training Loss: 7.623929311247433e-05
Epoch 99/100: Training Loss: 0.0005032770773943732
Epoch 0/100: Training Loss: 0.001260070678065805
Epoch 1/100: Training Loss: 0.0012253210825078627
Epoch 2/100: Training Loss: 0.0003302518935764537
Epoch 3/100: Training Loss: 0.0001395128996056669
Epoch 4/100: Training Loss: 0.0015701446463080014
Epoch 5/100: Training Loss: 0.0005379431387957405
Epoch 6/100: Training Loss: 0.00012297357487327912
Epoch 7/100: Training Loss: 0.0004695071017040926
Epoch 8/100: Training Loss: 0.00023211795179282918
Epoch 9/100: Training Loss: 0.00028626552837736466
Epoch 10/100: Training Loss: 0.0015466179917840396
Epoch 11/100: Training Loss: 0.0009718287517042721
Epoch 12/100: Training Loss: 0.0009649609818178065
Epoch 13/100: Training Loss: 4.713595776325639e-06
Epoch 14/100: Training Loss: 0.0011363671106450698
Epoch 15/100: Training Loss: 0.0005298164399231181
Epoch 16/100: Training Loss: 0.0005767079398912542
Epoch 17/100: Training Loss: 0.0008507590960053836
Epoch 18/100: Training Loss: 7.958479554337613e-05
Epoch 19/100: Training Loss: 0.000961749956888311
Epoch 20/100: Training Loss: 0.00032206072526819564
Epoch 21/100: Training Loss: 0.0002913618131595499
Epoch 22/100: Training Loss: 0.0009098777876180761
Epoch 23/100: Training Loss: 0.0005726084989659926
Epoch 24/100: Training Loss: 0.0007273771745317123
Epoch 25/100: Training Loss: 0.0010134841589366688
Epoch 26/100: Training Loss: 0.0005105970098691828
Epoch 27/100: Training Loss: 0.00013349427677252713
Epoch 28/100: Training Loss: 0.0001009408274994177
Epoch 29/100: Training Loss: 0.0007698698955423692
Epoch 30/100: Training Loss: 3.1655914533664197e-06
Epoch 31/100: Training Loss: 0.000360208421069033
Epoch 32/100: Training Loss: 0.0006841280881096335
Epoch 33/100: Training Loss: 0.00036490226493162266
Epoch 34/100: Training Loss: 0.0002271814162240309
Epoch 35/100: Training Loss: 7.478231016327353e-05
Epoch 36/100: Training Loss: 3.485681543893674e-06
Epoch 37/100: Training Loss: 0.00026831887662410737
Epoch 38/100: Training Loss: 5.7800251114017827e-05
Epoch 39/100: Training Loss: 2.2551594028139816e-05
Epoch 40/100: Training Loss: 0.0006004425970947042
Epoch 41/100: Training Loss: 0.0009000017362482408
Epoch 42/100: Training Loss: 0.0008428157252423904
Epoch 43/100: Training Loss: 0.00089750877198051
Epoch 44/100: Training Loss: 0.0008524282013668734
Epoch 45/100: Training Loss: 0.00082217638983446
Epoch 46/100: Training Loss: 0.0008624958641388837
Epoch 47/100: Training Loss: 0.0010030749089577618
Epoch 48/100: Training Loss: 0.0007976217304959017
Epoch 49/100: Training Loss: 0.00047862227348720326
Epoch 50/100: Training Loss: 1.382626428761903e-05
Epoch 51/100: Training Loss: 7.765333113424918e-05
Epoch 52/100: Training Loss: 0.0007659829714718987
Epoch 53/100: Training Loss: 0.0002718224464093938
Epoch 54/100: Training Loss: 1.2892850345986731e-05
Epoch 55/100: Training Loss: 0.0007299742277930765
Epoch 56/100: Training Loss: 0.0003270960905972649
Epoch 57/100: Training Loss: 0.001039717039641212
Epoch 58/100: Training Loss: 0.0008984124835799722
Epoch 59/100: Training Loss: 8.341702906524434e-05
Epoch 60/100: Training Loss: 2.6300015366252732e-06
Epoch 61/100: Training Loss: 0.0009380763944457559
Epoch 62/100: Training Loss: 1.9205482128788444e-05
Epoch 63/100: Training Loss: 0.0007632884032586041
Epoch 64/100: Training Loss: 0.00016305447720429476
Epoch 65/100: Training Loss: 0.0009624493472716387
Epoch 66/100: Training Loss: 0.0008787014028605293
Epoch 67/100: Training Loss: 0.0011098826632780186
Epoch 68/100: Training Loss: 2.145706949865117e-05
Epoch 69/100: Training Loss: 8.14860686659813e-06
Epoch 70/100: Training Loss: 0.00034197474665501537
Epoch 71/100: Training Loss: 0.0014499503900023067
Epoch 72/100: Training Loss: 0.00010051503777503967
Epoch 73/100: Training Loss: 4.9404843765146595e-05
Epoch 74/100: Training Loss: 0.0003444770460619646
Epoch 75/100: Training Loss: 1.7668442417155293e-05
Epoch 76/100: Training Loss: 0.0006736146614832036
Epoch 77/100: Training Loss: 7.849465507794829e-05
Epoch 78/100: Training Loss: 0.0009761099429691539
Epoch 79/100: Training Loss: 0.0008233532309532166
Epoch 80/100: Training Loss: 0.0008152801324339474
Epoch 81/100: Training Loss: 0.0008318947518573087
Epoch 82/100: Training Loss: 0.0008460824103916392
Epoch 83/100: Training Loss: 6.554501049001428e-06
Epoch 84/100: Training Loss: 6.69861157589099e-05
Epoch 85/100: Training Loss: 0.0008828862625009874
Epoch 86/100: Training Loss: 0.000879059118383071
Epoch 87/100: Training Loss: 0.0006245389142457177
Epoch 88/100: Training Loss: 0.0006124331670648911
Epoch 89/100: Training Loss: 0.0009307560675284441
Epoch 90/100: Training Loss: 1.9591719405177763e-05
Epoch 91/100: Training Loss: 0.00010015370652956122
Epoch 92/100: Training Loss: 0.0008516273077796488
Epoch 93/100: Training Loss: 0.0006971591097467086
Epoch 94/100: Training Loss: 6.426607861238368e-05
Epoch 95/100: Training Loss: 7.832260555861628e-06
Epoch 96/100: Training Loss: 0.0007687930675113903
Epoch 97/100: Training Loss: 0.0003951258957386017
Epoch 98/100: Training Loss: 0.0006286206052583806
Epoch 99/100: Training Loss: 7.379112546058262e-05
Epoch 0/100: Training Loss: 0.000778225327239317
Epoch 1/100: Training Loss: 0.0006672642248518327
Epoch 2/100: Training Loss: 0.0002997495453147327
Epoch 3/100: Training Loss: 0.0005644081708262948
Epoch 4/100: Training Loss: 0.00013729987994712942
Epoch 5/100: Training Loss: 2.1410448586239535e-05
Epoch 6/100: Training Loss: 0.000983517660814173
Epoch 7/100: Training Loss: 0.0017413234009462245
Epoch 8/100: Training Loss: 8.166687124792267e-05
Epoch 9/100: Training Loss: 0.0011389429954921499
Epoch 10/100: Training Loss: 0.0013966087909305796
Epoch 11/100: Training Loss: 0.0008278275237363927
Epoch 12/100: Training Loss: 0.0006774997448219973
Epoch 13/100: Training Loss: 0.00033020708052551047
Epoch 14/100: Training Loss: 6.776494247948422e-05
Epoch 15/100: Training Loss: 0.0006624635528115666
Epoch 16/100: Training Loss: 0.00031847044387284446
Epoch 17/100: Training Loss: 0.0010389248237890356
Epoch 18/100: Training Loss: 0.0007437371155794929
Epoch 19/100: Training Loss: 0.0010471658671603484
Epoch 20/100: Training Loss: 0.0005720354616641999
Epoch 21/100: Training Loss: 6.177904741729007e-05
Epoch 22/100: Training Loss: 0.00011328203494057936
Epoch 23/100: Training Loss: 0.0009541670189184301
Epoch 24/100: Training Loss: 0.0005355191143120037
Epoch 25/100: Training Loss: 0.0001667917103451841
Epoch 26/100: Training Loss: 1.6916892491281033e-05
Epoch 27/100: Training Loss: 1.1669130831518594e-05
Epoch 28/100: Training Loss: 0.00030393567593658673
Epoch 29/100: Training Loss: 0.000794621162554797
Epoch 30/100: Training Loss: 0.00033701805069166074
Epoch 31/100: Training Loss: 9.165025480529841e-05
Epoch 32/100: Training Loss: 0.00023924649200018715
Epoch 33/100: Training Loss: 0.0010100911645328297
Epoch 34/100: Training Loss: 0.0005561893915428835
Epoch 35/100: Training Loss: 0.0006190328037037569
Epoch 36/100: Training Loss: 0.0008692897417966058
Epoch 37/100: Training Loss: 0.0006657594705329222
Epoch 38/100: Training Loss: 0.0008461402619586271
Epoch 39/100: Training Loss: 0.0008243689642233007
Epoch 40/100: Training Loss: 0.00048580743810709785
Epoch 41/100: Training Loss: 0.0002864069798413445
Epoch 42/100: Training Loss: 0.00029656551778316497
Epoch 43/100: Training Loss: 1.7056829186485093e-05
Epoch 44/100: Training Loss: 0.0005673331372878131
Epoch 45/100: Training Loss: 5.896412082673872e-06
Epoch 46/100: Training Loss: 0.0003187324194347157
Epoch 47/100: Training Loss: 0.002380509937510771
Epoch 48/100: Training Loss: 0.0003537900307599236
Epoch 49/100: Training Loss: 3.5863780580899294e-06
Epoch 50/100: Training Loss: 0.0009471000117414138
Epoch 51/100: Training Loss: 0.0009071691071285921
Epoch 52/100: Training Loss: 3.3556910998681014e-05
Epoch 53/100: Training Loss: 0.001044747671660255
Epoch 54/100: Training Loss: 0.0010353410068680258
Epoch 55/100: Training Loss: 0.00038149720605681924
Epoch 56/100: Training Loss: 0.00032199491911074696
Epoch 57/100: Training Loss: 0.00021729283034801483
Epoch 58/100: Training Loss: 3.583707079729613e-05
Epoch 59/100: Training Loss: 0.00017496456994729883
Epoch 60/100: Training Loss: 5.341297604472322e-06
Epoch 61/100: Training Loss: 0.000633209987598307
Epoch 62/100: Training Loss: 0.0006710939547594855
Epoch 63/100: Training Loss: 0.000266740405384232
Epoch 64/100: Training Loss: 3.883073873379651e-05
Epoch 65/100: Training Loss: 0.00037414089721791885
Epoch 66/100: Training Loss: 0.0005980726988876567
Epoch 67/100: Training Loss: 0.00010178268832318923
Epoch 68/100: Training Loss: 7.4747484177351e-05
Epoch 69/100: Training Loss: 0.00015109289875801871
Epoch 70/100: Training Loss: 9.318974745624206e-05
Epoch 71/100: Training Loss: 0.00021536264787702
Epoch 72/100: Training Loss: 0.0006857929422574885
Epoch 73/100: Training Loss: 0.0004394089912666994
Epoch 74/100: Training Loss: 0.0007137409466154435
Epoch 75/100: Training Loss: 1.2669224730309318e-05
Epoch 76/100: Training Loss: 0.0004754031405729406
Epoch 77/100: Training Loss: 0.000597284164498834
Epoch 78/100: Training Loss: 0.00033322666936060963
Epoch 79/100: Training Loss: 0.0003350277814794989
Epoch 80/100: Training Loss: 0.000920315262149362
Epoch 81/100: Training Loss: 0.0015821646241580738
Epoch 82/100: Training Loss: 0.0004893477348720326
Epoch 83/100: Training Loss: 7.402421906590461e-05
Epoch 84/100: Training Loss: 7.762242902946824e-06
Epoch 85/100: Training Loss: 5.400378037901486e-05
Epoch 86/100: Training Loss: 0.0002932648448383107
Epoch 87/100: Training Loss: 9.058313444256782e-05
Epoch 88/100: Training Loss: 0.0004486988134243909
Epoch 89/100: Training Loss: 0.0012759751256774454
Epoch 90/100: Training Loss: 0.00019737039418781506
Epoch 91/100: Training Loss: 2.995801213033059e-05
Epoch 92/100: Training Loss: 0.0008175432682037354
Epoch 93/100: Training Loss: 1.7080647761330884e-05
Epoch 94/100: Training Loss: 6.32118050228147e-05
Epoch 95/100: Training Loss: 0.0007329623488818898
Epoch 96/100: Training Loss: 0.0006144542904461132
Epoch 97/100: Training Loss: 3.717109725317534e-05
Epoch 98/100: Training Loss: 7.044760072055986e-05
Epoch 99/100: Training Loss: 0.0012670545017018037
dataset: capitals layer_num_from_end:-1 Avg_acc:tensor(513.9420) Avg_AUC:0.8960725022470353 Avg_threshold:0.8352186481157938
dataset: inventions layer_num_from_end:-1 Avg_acc:tensor(475.9524) Avg_AUC:0.6811268971096975 Avg_threshold:0.501533567905426
dataset: elements layer_num_from_end:-1 Avg_acc:tensor(497.4222) Avg_AUC:0.6356819670867537 Avg_threshold:0.665930837392807
dataset: animals layer_num_from_end:-1 Avg_acc:tensor(500.8125) Avg_AUC:0.634672619047619 Avg_threshold:0.638284315665563
dataset: companies layer_num_from_end:-1 Avg_acc:tensor(504.5614) Avg_AUC:0.8014050925925926 Avg_threshold:0.5906268159548441
dataset: facts layer_num_from_end:-1 Avg_acc:tensor(490.4000) Avg_AUC:0.7977255898728409 Avg_threshold:0.9389748573303223
Epoch 0/100: Training Loss: 0.002033166952066488
Epoch 1/100: Training Loss: 0.0016866014762358232
Epoch 2/100: Training Loss: 0.0018648940783280593
Epoch 3/100: Training Loss: 0.001852281652130447
Epoch 4/100: Training Loss: 0.0022620548318316052
Epoch 5/100: Training Loss: 0.0019220832761351046
Epoch 6/100: Training Loss: 0.0014218424375240619
Epoch 7/100: Training Loss: 0.0015813246681973651
Epoch 8/100: Training Loss: 0.0014564036489366652
Epoch 9/100: Training Loss: 0.001948513976343862
Epoch 10/100: Training Loss: 0.0023140038226867887
Epoch 11/100: Training Loss: 0.0015849446083282257
Epoch 12/100: Training Loss: 0.0014679454840146578
Epoch 13/100: Training Loss: 0.001223138683325761
Epoch 14/100: Training Loss: 0.0013122243897898214
Epoch 15/100: Training Loss: 0.0015269037518467936
Epoch 16/100: Training Loss: 0.0012004113905913346
Epoch 17/100: Training Loss: 0.0015213498910823901
Epoch 18/100: Training Loss: 0.0016980533833270306
Epoch 19/100: Training Loss: 0.0013459517613991158
Epoch 20/100: Training Loss: 0.0013363332181543738
Epoch 21/100: Training Loss: 0.001504391014992774
Epoch 22/100: Training Loss: 0.0010625362604648084
Epoch 23/100: Training Loss: 0.000911517472533913
Epoch 24/100: Training Loss: 0.0016081222704240493
Epoch 25/100: Training Loss: 0.0016481871163094794
Epoch 26/100: Training Loss: 0.0015029928067347386
Epoch 27/100: Training Loss: 0.0013457508562328099
Epoch 28/100: Training Loss: 0.0015195909288379696
Epoch 29/100: Training Loss: 0.00041742417049574687
Epoch 30/100: Training Loss: 0.0013034765745376373
Epoch 31/100: Training Loss: 0.0009313075692503602
Epoch 32/100: Training Loss: 0.0013963124760380992
Epoch 33/100: Training Loss: 0.00112646401345313
Epoch 34/100: Training Loss: 0.001320067610774007
Epoch 35/100: Training Loss: 0.001492400477816175
Epoch 36/100: Training Loss: 0.0013821582485745837
Epoch 37/100: Training Loss: 0.0008555139069790607
Epoch 38/100: Training Loss: 0.001322762220055907
Epoch 39/100: Training Loss: 0.0010662400847548372
Epoch 40/100: Training Loss: 0.0008383464667346928
Epoch 41/100: Training Loss: 0.00104957975290872
Epoch 42/100: Training Loss: 0.0012906152051645559
Epoch 43/100: Training Loss: 0.0013477331274872892
Epoch 44/100: Training Loss: 0.0011506611025416768
Epoch 45/100: Training Loss: 0.0010677373909450077
Epoch 46/100: Training Loss: 0.0009429782003789515
Epoch 47/100: Training Loss: 0.0010788139555004093
Epoch 48/100: Training Loss: 0.0005834018225436444
Epoch 49/100: Training Loss: 0.0010198252601223393
Epoch 50/100: Training Loss: 0.0010654873156047367
Epoch 51/100: Training Loss: 0.0011906461282209916
Epoch 52/100: Training Loss: 0.0010242733088406649
Epoch 53/100: Training Loss: 0.0006268816394405765
Epoch 54/100: Training Loss: 0.0008869202403755454
Epoch 55/100: Training Loss: 0.0009691226524072927
Epoch 56/100: Training Loss: 0.0008324108548931309
Epoch 57/100: Training Loss: 0.0010888169070223828
Epoch 58/100: Training Loss: 0.0008506565452455641
Epoch 59/100: Training Loss: 0.0007812601703030246
Epoch 60/100: Training Loss: 0.0008490311724322659
Epoch 61/100: Training Loss: 0.0009199082851409912
Epoch 62/100: Training Loss: 0.0008740967491289953
Epoch 63/100: Training Loss: 0.0008241366464774926
Epoch 64/100: Training Loss: 0.0008813633576973335
Epoch 65/100: Training Loss: 0.0004424086504882866
Epoch 66/100: Training Loss: 0.0009895904914482491
Epoch 67/100: Training Loss: 0.0009186217834899475
Epoch 68/100: Training Loss: 0.0007792022991013693
Epoch 69/100: Training Loss: 0.0009802443372619735
Epoch 70/100: Training Loss: 0.0008248459625911045
Epoch 71/100: Training Loss: 0.0005913370555931038
Epoch 72/100: Training Loss: 0.0007467675771746602
Epoch 73/100: Training Loss: 0.0005609048725841762
Epoch 74/100: Training Loss: 0.0009415867653760043
Epoch 75/100: Training Loss: 0.0008987385284650576
Epoch 76/100: Training Loss: 0.0005645687867711474
Epoch 77/100: Training Loss: 0.0009476807150807414
Epoch 78/100: Training Loss: 0.0006993854275116554
Epoch 79/100: Training Loss: 0.0006311158096040045
Epoch 80/100: Training Loss: 0.0008640700391122511
Epoch 81/100: Training Loss: 0.00042330043820234446
Epoch 82/100: Training Loss: 0.000707785253758197
Epoch 83/100: Training Loss: 0.0004469809102845359
Epoch 84/100: Training Loss: 0.0009113217775638287
Epoch 85/100: Training Loss: 0.0004385372662877703
Epoch 86/100: Training Loss: 0.0006014800571895146
Epoch 87/100: Training Loss: 0.0008096345863142214
Epoch 88/100: Training Loss: 0.00043085855724928263
Epoch 89/100: Training Loss: 0.0006568273464282909
Epoch 90/100: Training Loss: 0.000822409987449646
Epoch 91/100: Training Loss: 0.0006193907840268595
Epoch 92/100: Training Loss: 0.0004341316285666886
Epoch 93/100: Training Loss: 0.0003684696357150178
Epoch 94/100: Training Loss: 0.0004794280845802147
Epoch 95/100: Training Loss: 0.0006753306288819213
Epoch 96/100: Training Loss: 0.0008543819397479504
Epoch 97/100: Training Loss: 0.0006603636108078323
Epoch 98/100: Training Loss: 0.0005298186015415859
Epoch 99/100: Training Loss: 0.0009027047382368075
Epoch 0/100: Training Loss: 0.0022033167468917952
Epoch 1/100: Training Loss: 0.0021523466477027307
Epoch 2/100: Training Loss: 0.00152958252213218
Epoch 3/100: Training Loss: 0.0017626944121780929
Epoch 4/100: Training Loss: 0.0015412231425305347
Epoch 5/100: Training Loss: 0.00211502059356316
Epoch 6/100: Training Loss: 0.002086676500893973
Epoch 7/100: Training Loss: 0.00204837030464119
Epoch 8/100: Training Loss: 0.0014114156886414215
Epoch 9/100: Training Loss: 0.002241925968156828
Epoch 10/100: Training Loss: 0.0015766874893561942
Epoch 11/100: Training Loss: 0.0017482980147941964
Epoch 12/100: Training Loss: 0.002336749872127613
Epoch 13/100: Training Loss: 0.001980252407647513
Epoch 14/100: Training Loss: 0.0010187911403762712
Epoch 15/100: Training Loss: 0.0017926434536913892
Epoch 16/100: Training Loss: 0.002066208557649092
Epoch 17/100: Training Loss: 0.00047417771774572093
Epoch 18/100: Training Loss: 0.0019495210030695774
Epoch 19/100: Training Loss: 0.0018804300498295498
Epoch 20/100: Training Loss: 0.0013964014661895646
Epoch 21/100: Training Loss: 0.0013911853303442468
Epoch 22/100: Training Loss: 0.0017662281756634479
Epoch 23/100: Training Loss: 0.0013985710961001735
Epoch 24/100: Training Loss: 0.0016421331809117245
Epoch 25/100: Training Loss: 0.0016285669761937815
Epoch 26/100: Training Loss: 0.0017732019191021686
Epoch 27/100: Training Loss: 0.0014417364255531685
Epoch 28/100: Training Loss: 0.0012517088985109662
Epoch 29/100: Training Loss: 0.0012641559530805042
Epoch 30/100: Training Loss: 0.0008258687241094096
Epoch 31/100: Training Loss: 0.0009618600556900452
Epoch 32/100: Training Loss: 0.0016746687722372841
Epoch 33/100: Training Loss: 0.001043658573310692
Epoch 34/100: Training Loss: 0.0017507841120233069
Epoch 35/100: Training Loss: 0.0014519411158728432
Epoch 36/100: Training Loss: 0.0010929110792133358
Epoch 37/100: Training Loss: 0.0007992606688212681
Epoch 38/100: Training Loss: 0.0016936336780761505
Epoch 39/100: Training Loss: 0.0006530007699152807
Epoch 40/100: Training Loss: 0.001012101873651251
Epoch 41/100: Training Loss: 0.0015993024502600824
Epoch 42/100: Training Loss: 0.0016715532833046012
Epoch 43/100: Training Loss: 0.001454559968901681
Epoch 44/100: Training Loss: 0.0014335869492350759
Epoch 45/100: Training Loss: 0.0014012923815867283
Epoch 46/100: Training Loss: 0.0007232569314383127
Epoch 47/100: Training Loss: 0.0012490261684764516
Epoch 48/100: Training Loss: 0.001321526257308213
Epoch 49/100: Training Loss: 0.0010544318002420705
Epoch 50/100: Training Loss: 0.0007496828382665461
Epoch 51/100: Training Loss: 0.00135439561380373
Epoch 52/100: Training Loss: 0.0012486578076035826
Epoch 53/100: Training Loss: 0.0009710636589076969
Epoch 54/100: Training Loss: 0.0012083175507458773
Epoch 55/100: Training Loss: 0.0006976420437539374
Epoch 56/100: Training Loss: 0.0007876005101870823
Epoch 57/100: Training Loss: 0.0011993419457148838
Epoch 58/100: Training Loss: 0.0006598035668159699
Epoch 59/100: Training Loss: 0.001284962975895488
Epoch 60/100: Training Loss: 0.0010389812759586147
Epoch 61/100: Training Loss: 0.0007509749669295091
Epoch 62/100: Training Loss: 0.0005527720688939928
Epoch 63/100: Training Loss: 0.0008426544653785812
Epoch 64/100: Training Loss: 0.000824053648051682
Epoch 65/100: Training Loss: 0.0011431036087182851
Epoch 66/100: Training Loss: 0.0005764784617023868
Epoch 67/100: Training Loss: 0.0004664278113758647
Epoch 68/100: Training Loss: 0.0007940818900828595
Epoch 69/100: Training Loss: 0.0007032257589426907
Epoch 70/100: Training Loss: 0.0006834678612388931
Epoch 71/100: Training Loss: 0.0013603147093232694
Epoch 72/100: Training Loss: 0.0010511582339560236
Epoch 73/100: Training Loss: 0.0007096893199673899
Epoch 74/100: Training Loss: 0.0002396320598525601
Epoch 75/100: Training Loss: 0.0009607330902473076
Epoch 76/100: Training Loss: 0.000935150401575582
Epoch 77/100: Training Loss: 0.00079964226359254
Epoch 78/100: Training Loss: 0.0005262234098427779
Epoch 79/100: Training Loss: 0.0006876807738017369
Epoch 80/100: Training Loss: 0.0003028133740791908
Epoch 81/100: Training Loss: 0.00012469015546611971
Epoch 82/100: Training Loss: 0.00048407083833134257
Epoch 83/100: Training Loss: 0.000861332289405636
Epoch 84/100: Training Loss: 0.0007209846606621376
Epoch 85/100: Training Loss: 0.0005464875302114687
Epoch 86/100: Training Loss: 0.0004715795491958832
Epoch 87/100: Training Loss: 0.00031536200142406916
Epoch 88/100: Training Loss: 0.00017978620904308932
Epoch 89/100: Training Loss: 0.0005573389621881339
Epoch 90/100: Training Loss: 0.0009766821261052484
Epoch 91/100: Training Loss: 0.0007157747249503236
Epoch 92/100: Training Loss: 0.0007692937563349317
Epoch 93/100: Training Loss: 0.0009130957451733676
Epoch 94/100: Training Loss: 0.00045981935479424215
Epoch 95/100: Training Loss: 0.0005201860949709698
Epoch 96/100: Training Loss: 0.0006228101837051498
Epoch 97/100: Training Loss: 0.00028860691439855347
Epoch 98/100: Training Loss: 0.0010537565588117478
Epoch 99/100: Training Loss: 0.0005089974590948412
Epoch 0/100: Training Loss: 0.002576073566516796
Epoch 1/100: Training Loss: 0.002047621912055916
Epoch 2/100: Training Loss: 0.0018200347056755652
Epoch 3/100: Training Loss: 0.0010045398990591089
Epoch 4/100: Training Loss: 0.0024024837917381234
Epoch 5/100: Training Loss: 0.0018405309923878916
Epoch 6/100: Training Loss: 0.0022142621187063363
Epoch 7/100: Training Loss: 0.0023936950243436373
Epoch 8/100: Training Loss: 0.0025496816301679276
Epoch 9/100: Training Loss: 0.0023472071527601123
Epoch 10/100: Training Loss: 0.0020314084066377653
Epoch 11/100: Training Loss: 0.0018896529307732214
Epoch 12/100: Training Loss: 0.0016890294276751005
Epoch 13/100: Training Loss: 0.0014433832643748997
Epoch 14/100: Training Loss: 0.001124612413919889
Epoch 15/100: Training Loss: 0.0017031874064798956
Epoch 16/100: Training Loss: 0.0012233501130884345
Epoch 17/100: Training Loss: 0.0016278426547150513
Epoch 18/100: Training Loss: 0.0016089431889407286
Epoch 19/100: Training Loss: 0.001775983121845272
Epoch 20/100: Training Loss: 0.0002863049715548962
Epoch 21/100: Training Loss: 0.0012987564493726184
Epoch 22/100: Training Loss: 0.0015404702691765098
Epoch 23/100: Training Loss: 0.0015951931685000867
Epoch 24/100: Training Loss: 0.0015899849521530257
Epoch 25/100: Training Loss: 0.001581881221357759
Epoch 26/100: Training Loss: 0.0015382448901663293
Epoch 27/100: Training Loss: 0.0014552038449507493
Epoch 28/100: Training Loss: 0.0015872802350904557
Epoch 29/100: Training Loss: 0.0015195378890404333
Epoch 30/100: Training Loss: 0.0013024542298350301
Epoch 31/100: Training Loss: 0.0003242965240578551
Epoch 32/100: Training Loss: 0.001082014891651127
Epoch 33/100: Training Loss: 0.0015546152224907507
Epoch 34/100: Training Loss: 0.00127236451302375
Epoch 35/100: Training Loss: 0.0012400809909913924
Epoch 36/100: Training Loss: 0.001374511347784029
Epoch 37/100: Training Loss: 0.0005010032466241529
Epoch 38/100: Training Loss: 0.0011480523572935091
Epoch 39/100: Training Loss: 0.0004241524615904668
Epoch 40/100: Training Loss: 0.001122456538927305
Epoch 41/100: Training Loss: 0.0015014645519790116
Epoch 42/100: Training Loss: 0.0015767669969505363
Epoch 43/100: Training Loss: 0.0015290390986662644
Epoch 44/100: Training Loss: 0.001142825801055748
Epoch 45/100: Training Loss: 0.0014577502762521063
Epoch 46/100: Training Loss: 0.0011933009316037585
Epoch 47/100: Training Loss: 0.0013388702711025317
Epoch 48/100: Training Loss: 0.0013118617601327962
Epoch 49/100: Training Loss: 0.0011275809753191221
Epoch 50/100: Training Loss: 0.0013981186426602877
Epoch 51/100: Training Loss: 0.0011162531751019139
Epoch 52/100: Training Loss: 0.0005290770343133619
Epoch 53/100: Training Loss: 0.001087452565039788
Epoch 54/100: Training Loss: 0.0010566697879271073
Epoch 55/100: Training Loss: 0.00098178645113965
Epoch 56/100: Training Loss: 0.0005171321905576265
Epoch 57/100: Training Loss: 0.0010276240902347164
Epoch 58/100: Training Loss: 0.0008830493771946514
Epoch 59/100: Training Loss: 0.0009836936955685382
Epoch 60/100: Training Loss: 0.0010166766343416868
Epoch 61/100: Training Loss: 0.000776186689630255
Epoch 62/100: Training Loss: 0.0009219220259806493
Epoch 63/100: Training Loss: 0.0003903588162852334
Epoch 64/100: Training Loss: 0.0009411291017398967
Epoch 65/100: Training Loss: 0.000912648918745401
Epoch 66/100: Training Loss: 0.0009600515965815191
Epoch 67/100: Training Loss: 0.0005092804248516376
Epoch 68/100: Training Loss: 0.00020497819812564583
Epoch 69/100: Training Loss: 0.0007466372180651951
Epoch 70/100: Training Loss: 0.00013943166322224625
